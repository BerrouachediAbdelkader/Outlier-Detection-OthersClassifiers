{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Imports \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt \n",
    "from pprint import pprint\n",
    "from numpy import array\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LB</th>\n",
       "      <th>AC</th>\n",
       "      <th>FM</th>\n",
       "      <th>UC</th>\n",
       "      <th>ASTV</th>\n",
       "      <th>MSTV</th>\n",
       "      <th>ALTV</th>\n",
       "      <th>MLTV</th>\n",
       "      <th>DL</th>\n",
       "      <th>DS</th>\n",
       "      <th>...</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "      <th>Nmax</th>\n",
       "      <th>Nzeros</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>Variance</th>\n",
       "      <th>Tendency</th>\n",
       "      <th>outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>146.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>33.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>134.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>79.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>114.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>149.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>34.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>148.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>122.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>62.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>134.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>42.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>128.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LB   AC   FM   UC  ASTV  MSTV  ALTV  MLTV   DL   DS   ...       Min  \\\n",
       "0  146.0  0.0  0.0  5.0  65.0   0.4  33.0   7.4  0.0  0.0   ...     134.0   \n",
       "1  128.0  0.0  0.0  2.0  86.0   0.3  79.0   2.9  0.0  0.0   ...     114.0   \n",
       "2  149.0  0.0  0.0  5.0  61.0   0.4  34.0   5.6  0.0  0.0   ...     148.0   \n",
       "3  122.0  0.0  0.0  0.0  83.0   0.5   6.0  15.6  0.0  0.0   ...      62.0   \n",
       "4  134.0  0.0  4.0  0.0  79.0   0.2  42.0   5.5  0.0  0.0   ...     128.0   \n",
       "\n",
       "     Max  Nmax  Nzeros   Mode   Mean  Median  Variance  Tendency  outlier  \n",
       "0  164.0   1.0     0.0  150.0  149.0   151.0       1.0       0.0        1  \n",
       "1  130.0   0.0     0.0  128.0  126.0   129.0       0.0       1.0        1  \n",
       "2  160.0   1.0     0.0  154.0  153.0   155.0       0.0       0.0        1  \n",
       "3  130.0   0.0     0.0  122.0  122.0   123.0       3.0       1.0        1  \n",
       "4  145.0   2.0     0.0  135.0  135.0   136.0       1.0       0.0        1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "df=pd.read_csv('Cardiotocography_02_v10.csv')  \n",
    "\n",
    "del df['id']\n",
    "del df['Unnamed: 0']\n",
    "df['outlier'] = df.outlier.apply(lambda label: 1 if label == \"'yes'\" else 0)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df to values\n",
    "df = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GC Forest\n",
    "import argparse\n",
    "import sys\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score\n",
    "sys.path.insert(0, \"lib\")\n",
    "from gcforest.gcforest import GCForest\n",
    "from gcforest.gcforest import GCForest\n",
    "from gcforest.utils.config_utils import load_json\n",
    "config = load_json(\"./examples/Cardiotocography.json\")   \n",
    "gc = GCForest(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test \n",
    "from sklearn.cross_validation import train_test_split\n",
    "y = df[:,21]\n",
    "X = df[:,0:21]\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of class\n",
    "len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-04-26 22:50:59,404][cascade_classifier.fit_transform] X_groups_train.shape=[(1181, 21)],y_train.shape=(1181,),X_groups_test.shape=[(507, 21)],y_test.shape=(507,)\n",
      "[ 2018-04-26 22:50:59,405][cascade_classifier.fit_transform] group_dims=[21]\n",
      "[ 2018-04-26 22:50:59,407][cascade_classifier.fit_transform] group_starts=[0]\n",
      "[ 2018-04-26 22:50:59,408][cascade_classifier.fit_transform] group_ends=[21]\n",
      "[ 2018-04-26 22:50:59,410][cascade_classifier.fit_transform] X_train.shape=(1181, 21),X_test.shape=(507, 21)\n",
      "[ 2018-04-26 22:50:59,411][cascade_classifier.fit_transform] [layer=0] look_indexs=[0], X_cur_train.shape=(1181, 21), X_cur_test.shape=(507, 21)\n",
      "[ 2018-04-26 22:51:00,210][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_0.predict)=98.32%\n",
      "[ 2018-04-26 22:51:01,279][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_1.predict)=98.31%\n",
      "[ 2018-04-26 22:51:02,245][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_2.predict)=99.15%\n",
      "[ 2018-04-26 22:51:03,157][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_3.predict)=98.31%\n",
      "[ 2018-04-26 22:51:04,265][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_4.predict)=99.15%\n",
      "[ 2018-04-26 22:51:05,392][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_5.predict)=98.31%\n",
      "[ 2018-04-26 22:51:06,616][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_6.predict)=98.31%\n",
      "[ 2018-04-26 22:51:07,714][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_7.predict)=98.31%\n",
      "[ 2018-04-26 22:51:08,823][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_8.predict)=98.31%\n",
      "[ 2018-04-26 22:51:09,911][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_9.predict)=99.15%\n",
      "[ 2018-04-26 22:51:10,242][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_cv.predict)=98.56%\n",
      "[ 2018-04-26 22:51:10,244][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.test.predict)=97.44%\n",
      "[ 2018-04-26 22:51:10,953][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_0.predict)=98.32%\n",
      "[ 2018-04-26 22:51:11,930][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_1.predict)=98.31%\n",
      "[ 2018-04-26 22:51:12,873][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_2.predict)=98.31%\n",
      "[ 2018-04-26 22:51:14,008][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_3.predict)=98.31%\n",
      "[ 2018-04-26 22:51:15,069][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_4.predict)=98.31%\n",
      "[ 2018-04-26 22:51:16,286][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_5.predict)=98.31%\n",
      "[ 2018-04-26 22:51:17,218][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_6.predict)=98.31%\n",
      "[ 2018-04-26 22:51:18,255][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_7.predict)=99.15%\n",
      "[ 2018-04-26 22:51:19,355][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_8.predict)=98.31%\n",
      "[ 2018-04-26 22:51:20,436][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_9.predict)=98.31%\n",
      "[ 2018-04-26 22:51:20,692][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_cv.predict)=98.39%\n",
      "[ 2018-04-26 22:51:20,694][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.test.predict)=97.63%\n",
      "[ 2018-04-26 22:51:20,772][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_0.predict)=99.16%\n",
      "[ 2018-04-26 22:51:20,813][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_1.predict)=98.31%\n",
      "[ 2018-04-26 22:51:20,850][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_2.predict)=98.31%\n",
      "[ 2018-04-26 22:51:20,879][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_3.predict)=98.31%\n",
      "[ 2018-04-26 22:51:20,909][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_4.predict)=99.15%\n",
      "[ 2018-04-26 22:51:20,935][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_5.predict)=98.31%\n",
      "[ 2018-04-26 22:51:20,964][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_6.predict)=97.46%\n",
      "[ 2018-04-26 22:51:20,989][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_7.predict)=97.46%\n",
      "[ 2018-04-26 22:51:21,010][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_8.predict)=98.31%\n",
      "[ 2018-04-26 22:51:21,033][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_9.predict)=98.31%\n",
      "[ 2018-04-26 22:51:21,035][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_cv.predict)=98.31%\n",
      "[ 2018-04-26 22:51:21,036][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.test.predict)=97.83%\n",
      "[ 2018-04-26 22:51:21,037][cascade_classifier.calc_accuracy] Accuracy(layer_0 - train.classifier_average)=98.56%\n",
      "[ 2018-04-26 22:51:21,039][cascade_classifier.calc_accuracy] Accuracy(layer_0 - test.classifier_average)=97.63%\n",
      "[ 2018-04-26 22:51:21,040][cascade_classifier.fit_transform] [layer=1] look_indexs=[0], X_cur_train.shape=(1181, 27), X_cur_test.shape=(507, 27)\n",
      "[ 2018-04-26 22:51:21,841][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_0.predict)=99.16%\n",
      "[ 2018-04-26 22:51:22,925][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_1.predict)=99.15%\n",
      "[ 2018-04-26 22:51:24,102][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_2.predict)=99.15%\n",
      "[ 2018-04-26 22:51:25,080][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_3.predict)=99.15%\n",
      "[ 2018-04-26 22:51:26,148][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_4.predict)=98.31%\n",
      "[ 2018-04-26 22:51:27,218][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_5.predict)=98.31%\n",
      "[ 2018-04-26 22:51:28,400][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_6.predict)=98.31%\n",
      "[ 2018-04-26 22:51:29,600][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_7.predict)=98.31%\n",
      "[ 2018-04-26 22:51:30,734][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_8.predict)=98.31%\n",
      "[ 2018-04-26 22:51:31,896][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_9.predict)=98.31%\n",
      "[ 2018-04-26 22:51:32,147][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_cv.predict)=98.65%\n",
      "[ 2018-04-26 22:51:32,149][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.test.predict)=97.63%\n",
      "[ 2018-04-26 22:51:33,060][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_0.predict)=99.16%\n",
      "[ 2018-04-26 22:51:34,294][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_1.predict)=99.15%\n",
      "[ 2018-04-26 22:51:35,285][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_2.predict)=98.31%\n",
      "[ 2018-04-26 22:51:36,385][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_3.predict)=99.15%\n",
      "[ 2018-04-26 22:51:37,325][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_4.predict)=98.31%\n",
      "[ 2018-04-26 22:51:38,539][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_5.predict)=99.15%\n",
      "[ 2018-04-26 22:51:39,661][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_6.predict)=99.15%\n",
      "[ 2018-04-26 22:51:40,705][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_7.predict)=99.15%\n",
      "[ 2018-04-26 22:51:41,765][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_8.predict)=98.31%\n",
      "[ 2018-04-26 22:51:42,722][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_9.predict)=98.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-04-26 22:51:42,983][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_cv.predict)=98.81%\n",
      "[ 2018-04-26 22:51:42,985][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.test.predict)=97.63%\n",
      "[ 2018-04-26 22:51:43,040][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_0.predict)=98.32%\n",
      "[ 2018-04-26 22:51:43,082][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_1.predict)=98.31%\n",
      "[ 2018-04-26 22:51:43,114][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_2.predict)=98.31%\n",
      "[ 2018-04-26 22:51:43,146][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_3.predict)=98.31%\n",
      "[ 2018-04-26 22:51:43,183][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_4.predict)=98.31%\n",
      "[ 2018-04-26 22:51:43,211][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_5.predict)=98.31%\n",
      "[ 2018-04-26 22:51:43,243][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_6.predict)=98.31%\n",
      "[ 2018-04-26 22:51:43,277][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_7.predict)=99.15%\n",
      "[ 2018-04-26 22:51:43,308][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_8.predict)=99.15%\n",
      "[ 2018-04-26 22:51:43,337][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_9.predict)=98.31%\n",
      "[ 2018-04-26 22:51:43,338][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_cv.predict)=98.48%\n",
      "[ 2018-04-26 22:51:43,339][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.test.predict)=97.83%\n",
      "[ 2018-04-26 22:51:43,340][cascade_classifier.calc_accuracy] Accuracy(layer_1 - train.classifier_average)=98.56%\n",
      "[ 2018-04-26 22:51:43,341][cascade_classifier.calc_accuracy] Accuracy(layer_1 - test.classifier_average)=97.63%\n",
      "[ 2018-04-26 22:51:43,342][cascade_classifier.fit_transform] [layer=2] look_indexs=[0], X_cur_train.shape=(1181, 27), X_cur_test.shape=(507, 27)\n",
      "[ 2018-04-26 22:51:44,294][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_0.predict)=100.00%\n",
      "[ 2018-04-26 22:51:45,381][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_1.predict)=98.31%\n",
      "[ 2018-04-26 22:51:46,491][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_2.predict)=98.31%\n",
      "[ 2018-04-26 22:51:47,610][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_3.predict)=97.46%\n",
      "[ 2018-04-26 22:51:48,736][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_4.predict)=99.15%\n",
      "[ 2018-04-26 22:51:49,735][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_5.predict)=98.31%\n",
      "[ 2018-04-26 22:51:50,823][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_6.predict)=99.15%\n",
      "[ 2018-04-26 22:51:51,989][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_7.predict)=98.31%\n",
      "[ 2018-04-26 22:51:53,101][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_8.predict)=98.31%\n",
      "[ 2018-04-26 22:51:54,301][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_9.predict)=99.15%\n",
      "[ 2018-04-26 22:51:54,563][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_cv.predict)=98.65%\n",
      "[ 2018-04-26 22:51:54,565][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.test.predict)=97.63%\n",
      "[ 2018-04-26 22:51:55,408][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_0.predict)=97.48%\n",
      "[ 2018-04-26 22:51:56,350][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_1.predict)=99.15%\n",
      "[ 2018-04-26 22:51:57,276][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_2.predict)=98.31%\n",
      "[ 2018-04-26 22:51:58,231][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_3.predict)=99.15%\n",
      "[ 2018-04-26 22:51:59,139][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_4.predict)=98.31%\n",
      "[ 2018-04-26 22:51:59,959][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_5.predict)=99.15%\n",
      "[ 2018-04-26 22:52:00,743][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_6.predict)=99.15%\n",
      "[ 2018-04-26 22:52:01,697][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_7.predict)=98.31%\n",
      "[ 2018-04-26 22:52:02,577][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_8.predict)=98.31%\n",
      "[ 2018-04-26 22:52:03,583][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_9.predict)=99.15%\n",
      "[ 2018-04-26 22:52:03,841][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_cv.predict)=98.65%\n",
      "[ 2018-04-26 22:52:03,843][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.test.predict)=97.83%\n",
      "[ 2018-04-26 22:52:03,902][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_0.predict)=99.16%\n",
      "[ 2018-04-26 22:52:03,948][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_1.predict)=98.31%\n",
      "[ 2018-04-26 22:52:03,988][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_2.predict)=98.31%\n",
      "[ 2018-04-26 22:52:04,026][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_3.predict)=98.31%\n",
      "[ 2018-04-26 22:52:04,058][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_4.predict)=99.15%\n",
      "[ 2018-04-26 22:52:04,092][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_5.predict)=98.31%\n",
      "[ 2018-04-26 22:52:04,121][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_6.predict)=98.31%\n",
      "[ 2018-04-26 22:52:04,159][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_7.predict)=98.31%\n",
      "[ 2018-04-26 22:52:04,191][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_8.predict)=98.31%\n",
      "[ 2018-04-26 22:52:04,225][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_9.predict)=98.31%\n",
      "[ 2018-04-26 22:52:04,227][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_cv.predict)=98.48%\n",
      "[ 2018-04-26 22:52:04,228][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.test.predict)=97.63%\n",
      "[ 2018-04-26 22:52:04,229][cascade_classifier.calc_accuracy] Accuracy(layer_2 - train.classifier_average)=98.65%\n",
      "[ 2018-04-26 22:52:04,230][cascade_classifier.calc_accuracy] Accuracy(layer_2 - test.classifier_average)=97.83%\n",
      "[ 2018-04-26 22:52:04,231][cascade_classifier.fit_transform] [layer=3] look_indexs=[0], X_cur_train.shape=(1181, 27), X_cur_test.shape=(507, 27)\n",
      "[ 2018-04-26 22:52:05,050][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_0.predict)=99.16%\n",
      "[ 2018-04-26 22:52:06,139][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_1.predict)=99.15%\n",
      "[ 2018-04-26 22:52:07,392][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_2.predict)=98.31%\n",
      "[ 2018-04-26 22:52:08,495][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_3.predict)=99.15%\n",
      "[ 2018-04-26 22:52:09,607][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_4.predict)=98.31%\n",
      "[ 2018-04-26 22:52:10,718][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_5.predict)=98.31%\n",
      "[ 2018-04-26 22:52:11,846][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_6.predict)=96.61%\n",
      "[ 2018-04-26 22:52:13,026][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_7.predict)=98.31%\n",
      "[ 2018-04-26 22:52:14,098][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_8.predict)=99.15%\n",
      "[ 2018-04-26 22:52:15,198][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_9.predict)=99.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-04-26 22:52:15,481][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_cv.predict)=98.56%\n",
      "[ 2018-04-26 22:52:15,483][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.test.predict)=97.83%\n",
      "[ 2018-04-26 22:52:16,295][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_0.predict)=99.16%\n",
      "[ 2018-04-26 22:52:17,195][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_1.predict)=98.31%\n",
      "[ 2018-04-26 22:52:18,317][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_2.predict)=98.31%\n",
      "[ 2018-04-26 22:52:19,291][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_3.predict)=99.15%\n",
      "[ 2018-04-26 22:52:20,252][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_4.predict)=98.31%\n",
      "[ 2018-04-26 22:52:21,345][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_5.predict)=99.15%\n",
      "[ 2018-04-26 22:52:22,454][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_6.predict)=98.31%\n",
      "[ 2018-04-26 22:52:23,438][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_7.predict)=98.31%\n",
      "[ 2018-04-26 22:52:24,638][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_8.predict)=98.31%\n",
      "[ 2018-04-26 22:52:25,719][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_9.predict)=99.15%\n",
      "[ 2018-04-26 22:52:25,974][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_cv.predict)=98.65%\n",
      "[ 2018-04-26 22:52:25,975][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.test.predict)=97.63%\n",
      "[ 2018-04-26 22:52:26,037][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_0.predict)=98.32%\n",
      "[ 2018-04-26 22:52:26,083][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_1.predict)=99.15%\n",
      "[ 2018-04-26 22:52:26,127][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_2.predict)=98.31%\n",
      "[ 2018-04-26 22:52:26,161][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_3.predict)=98.31%\n",
      "[ 2018-04-26 22:52:26,194][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_4.predict)=97.46%\n",
      "[ 2018-04-26 22:52:26,229][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_5.predict)=98.31%\n",
      "[ 2018-04-26 22:52:26,263][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_6.predict)=99.15%\n",
      "[ 2018-04-26 22:52:26,292][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_7.predict)=99.15%\n",
      "[ 2018-04-26 22:52:26,324][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_8.predict)=97.46%\n",
      "[ 2018-04-26 22:52:26,358][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_9.predict)=99.15%\n",
      "[ 2018-04-26 22:52:26,360][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_cv.predict)=98.48%\n",
      "[ 2018-04-26 22:52:26,361][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.test.predict)=97.83%\n",
      "[ 2018-04-26 22:52:26,362][cascade_classifier.calc_accuracy] Accuracy(layer_3 - train.classifier_average)=98.48%\n",
      "[ 2018-04-26 22:52:26,363][cascade_classifier.calc_accuracy] Accuracy(layer_3 - test.classifier_average)=97.63%\n",
      "[ 2018-04-26 22:52:26,365][cascade_classifier.fit_transform] [layer=4] look_indexs=[0], X_cur_train.shape=(1181, 27), X_cur_test.shape=(507, 27)\n",
      "[ 2018-04-26 22:52:27,157][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_0.predict)=99.16%\n",
      "[ 2018-04-26 22:52:28,303][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_1.predict)=99.15%\n",
      "[ 2018-04-26 22:52:29,346][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_2.predict)=97.46%\n",
      "[ 2018-04-26 22:52:30,483][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_3.predict)=99.15%\n",
      "[ 2018-04-26 22:52:31,467][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_4.predict)=99.15%\n",
      "[ 2018-04-26 22:52:32,551][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_5.predict)=99.15%\n",
      "[ 2018-04-26 22:52:33,745][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_6.predict)=98.31%\n",
      "[ 2018-04-26 22:52:34,851][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_7.predict)=97.46%\n",
      "[ 2018-04-26 22:52:35,918][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_8.predict)=98.31%\n",
      "[ 2018-04-26 22:52:36,993][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_9.predict)=98.31%\n",
      "[ 2018-04-26 22:52:37,272][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_cv.predict)=98.56%\n",
      "[ 2018-04-26 22:52:37,274][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.test.predict)=97.63%\n",
      "[ 2018-04-26 22:52:38,001][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_0.predict)=98.32%\n",
      "[ 2018-04-26 22:52:38,982][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_1.predict)=98.31%\n",
      "[ 2018-04-26 22:52:40,036][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_2.predict)=98.31%\n",
      "[ 2018-04-26 22:52:41,080][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_3.predict)=98.31%\n",
      "[ 2018-04-26 22:52:42,150][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_4.predict)=100.00%\n",
      "[ 2018-04-26 22:52:43,068][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_5.predict)=99.15%\n",
      "[ 2018-04-26 22:52:44,159][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_6.predict)=97.46%\n",
      "[ 2018-04-26 22:52:45,266][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_7.predict)=99.15%\n",
      "[ 2018-04-26 22:52:46,209][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_8.predict)=98.31%\n",
      "[ 2018-04-26 22:52:47,154][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_9.predict)=99.15%\n",
      "[ 2018-04-26 22:52:47,418][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_cv.predict)=98.65%\n",
      "[ 2018-04-26 22:52:47,419][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.test.predict)=97.83%\n",
      "[ 2018-04-26 22:52:47,474][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_0.predict)=99.16%\n",
      "[ 2018-04-26 22:52:47,532][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_1.predict)=98.31%\n",
      "[ 2018-04-26 22:52:47,569][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_2.predict)=98.31%\n",
      "[ 2018-04-26 22:52:47,612][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_3.predict)=98.31%\n",
      "[ 2018-04-26 22:52:47,648][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_4.predict)=98.31%\n",
      "[ 2018-04-26 22:52:47,682][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_5.predict)=98.31%\n",
      "[ 2018-04-26 22:52:47,715][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_6.predict)=99.15%\n",
      "[ 2018-04-26 22:52:47,748][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_7.predict)=99.15%\n",
      "[ 2018-04-26 22:52:47,780][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_8.predict)=97.46%\n",
      "[ 2018-04-26 22:52:47,822][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_9.predict)=99.15%\n",
      "[ 2018-04-26 22:52:47,824][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_cv.predict)=98.56%\n",
      "[ 2018-04-26 22:52:47,825][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.test.predict)=97.63%\n",
      "[ 2018-04-26 22:52:47,826][cascade_classifier.calc_accuracy] Accuracy(layer_4 - train.classifier_average)=98.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-04-26 22:52:47,827][cascade_classifier.calc_accuracy] Accuracy(layer_4 - test.classifier_average)=97.63%\n",
      "[ 2018-04-26 22:52:47,829][cascade_classifier.fit_transform] [layer=5] look_indexs=[0], X_cur_train.shape=(1181, 27), X_cur_test.shape=(507, 27)\n",
      "[ 2018-04-26 22:52:48,609][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_0.predict)=98.32%\n",
      "[ 2018-04-26 22:52:49,670][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_1.predict)=99.15%\n",
      "[ 2018-04-26 22:52:50,900][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_2.predict)=99.15%\n",
      "[ 2018-04-26 22:52:51,989][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_3.predict)=98.31%\n",
      "[ 2018-04-26 22:52:53,077][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_4.predict)=98.31%\n",
      "[ 2018-04-26 22:52:54,147][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_5.predict)=98.31%\n",
      "[ 2018-04-26 22:52:55,347][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_6.predict)=97.46%\n",
      "[ 2018-04-26 22:52:56,441][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_7.predict)=98.31%\n",
      "[ 2018-04-26 22:52:57,536][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_8.predict)=98.31%\n",
      "[ 2018-04-26 22:52:58,615][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_9.predict)=99.15%\n",
      "[ 2018-04-26 22:52:58,875][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_cv.predict)=98.48%\n",
      "[ 2018-04-26 22:52:58,877][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.test.predict)=97.63%\n",
      "[ 2018-04-26 22:52:59,589][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_0.predict)=98.32%\n",
      "[ 2018-04-26 22:53:00,557][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_1.predict)=98.31%\n",
      "[ 2018-04-26 22:53:01,642][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_2.predict)=98.31%\n",
      "[ 2018-04-26 22:53:02,555][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_3.predict)=97.46%\n",
      "[ 2018-04-26 22:53:03,445][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_4.predict)=99.15%\n",
      "[ 2018-04-26 22:53:04,436][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_5.predict)=98.31%\n",
      "[ 2018-04-26 22:53:05,381][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_6.predict)=98.31%\n",
      "[ 2018-04-26 22:53:06,460][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_7.predict)=98.31%\n",
      "[ 2018-04-26 22:53:07,558][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_8.predict)=98.31%\n",
      "[ 2018-04-26 22:53:08,662][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_9.predict)=99.15%\n",
      "[ 2018-04-26 22:53:08,898][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_cv.predict)=98.39%\n",
      "[ 2018-04-26 22:53:08,900][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.test.predict)=97.83%\n",
      "[ 2018-04-26 22:53:08,956][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_0.predict)=98.32%\n",
      "[ 2018-04-26 22:53:08,998][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_1.predict)=97.46%\n",
      "[ 2018-04-26 22:53:09,052][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_2.predict)=99.15%\n",
      "[ 2018-04-26 22:53:09,102][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_3.predict)=97.46%\n",
      "[ 2018-04-26 22:53:09,141][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_4.predict)=98.31%\n",
      "[ 2018-04-26 22:53:09,175][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_5.predict)=98.31%\n",
      "[ 2018-04-26 22:53:09,211][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_6.predict)=98.31%\n",
      "[ 2018-04-26 22:53:09,246][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_7.predict)=98.31%\n",
      "[ 2018-04-26 22:53:09,283][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_8.predict)=98.31%\n",
      "[ 2018-04-26 22:53:09,320][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_9.predict)=99.15%\n",
      "[ 2018-04-26 22:53:09,321][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_cv.predict)=98.31%\n",
      "[ 2018-04-26 22:53:09,322][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.test.predict)=97.83%\n",
      "[ 2018-04-26 22:53:09,323][cascade_classifier.calc_accuracy] Accuracy(layer_5 - train.classifier_average)=98.39%\n",
      "[ 2018-04-26 22:53:09,324][cascade_classifier.calc_accuracy] Accuracy(layer_5 - test.classifier_average)=97.83%\n",
      "[ 2018-04-26 22:53:09,325][cascade_classifier.fit_transform] [Result][Optimal Level Detected] opt_layer_num=3, accuracy_train=98.65%, accuracy_test=97.83%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(' Time ', '129.942', ' seconds')\n"
     ]
    }
   ],
   "source": [
    "t0 = time()  \n",
    "    # X_enc is the concatenated predict_proba result of each estimators of the last layer of the GCForest model\n",
    "    # X_enc.shape =\n",
    "    #   (n_datas, n_estimators * n_classes): If cascade is provided\n",
    "    #   (n_datas, n_estimators * n_classes, dimX, dimY): If only finegrained part is provided\n",
    "    # You can also pass X_test, y_test to fit_transform method, then the accracy on test data will be logged when training.\n",
    "X_train_enc, X_test_enc = gc.fit_transform(X_train, y_train, X_test=X_test, y_test=y_test)\n",
    "    # WARNING: if you set gc.set_keep_model_in_mem(True), you would have to use\n",
    "    # gc.fit_transform(X_train, y_train, X_test=X_test, y_test=y_test) to evaluate your model. \n",
    "tt = time() - t0  \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-04-26 22:53:09,352][cascade_classifier.transform] X_groups_test.shape=[(507, 21)]\n",
      "[ 2018-04-26 22:53:09,354][cascade_classifier.transform] group_dims=[21]\n",
      "[ 2018-04-26 22:53:09,355][cascade_classifier.transform] X_test.shape=(507, 21)\n",
      "[ 2018-04-26 22:53:09,358][cascade_classifier.transform] [layer=0] look_indexs=[0], X_cur_test.shape=(507, 21)\n",
      "[ 2018-04-26 22:53:14,567][cascade_classifier.transform] [layer=1] look_indexs=[0], X_cur_test.shape=(507, 27)\n",
      "[ 2018-04-26 22:53:19,698][cascade_classifier.transform] [layer=2] look_indexs=[0], X_cur_test.shape=(507, 27)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of GCForest = 97.830375 %\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "y_pred = gc.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy of GCForest = {:.6f} %\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of DecisionTreeClassifier = 97.633136 %\n",
      "(' Time ', '0.016', ' seconds')\n"
     ]
    }
   ],
   "source": [
    "t0 = time()  \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of DecisionTreeClassifier = {:.6f} %\".format(acc * 100))\n",
    "tt = time() - t0  \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of RandomForestClassifier = 97.435897 %\n",
      "(' Time ', '0.465', ' seconds')\n"
     ]
    }
   ],
   "source": [
    "t0 = time()  \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of RandomForestClassifier = {:.6f} %\".format(acc * 100))\n",
    "tt = time() - t0  \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of ExtraTreesClassifier = 97.830375 %\n",
      "(' Time ', '0.405', ' seconds')\n"
     ]
    }
   ],
   "source": [
    "t0 = time()  \n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "clf = ExtraTreesClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of ExtraTreesClassifier = {:.6f} %\".format(acc * 100))\n",
    "tt = time() - t0  \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of AdaBoostClassifier = 97.238659 %\n",
      "(' Time ', '0.326', ' seconds')\n"
     ]
    }
   ],
   "source": [
    "t0 = time()  \n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of AdaBoostClassifier = {:.6f} %\".format(acc * 100))\n",
    "tt = time() - t0  \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Naive_bayes  GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of GaussianNB = 93.293886 %\n",
      "(' Time ', '0.005', ' seconds')\n"
     ]
    }
   ],
   "source": [
    "t0 = time()  \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb = gnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred= gnb.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of GaussianNB = {:.6f} %\".format(acc * 100))\n",
    "tt = time() - t0  \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1062/1062 [==============================] - 1s 622us/step - loss: 0.6368 - acc: 0.9831\n",
      "Epoch 2/100\n",
      "1062/1062 [==============================] - 0s 70us/step - loss: 0.1987 - acc: 0.9831\n",
      "Epoch 3/100\n",
      "1062/1062 [==============================] - 0s 67us/step - loss: 0.0902 - acc: 0.9831\n",
      "Epoch 4/100\n",
      "1062/1062 [==============================] - 0s 71us/step - loss: 0.0879 - acc: 0.9831\n",
      "Epoch 5/100\n",
      "1062/1062 [==============================] - 0s 70us/step - loss: 0.0864 - acc: 0.9831\n",
      "Epoch 6/100\n",
      "1062/1062 [==============================] - 0s 68us/step - loss: 0.0855 - acc: 0.9831\n",
      "Epoch 7/100\n",
      "1062/1062 [==============================] - 0s 72us/step - loss: 0.0852 - acc: 0.9831\n",
      "Epoch 8/100\n",
      "1062/1062 [==============================] - 0s 71us/step - loss: 0.0851 - acc: 0.9831\n",
      "Epoch 9/100\n",
      "1062/1062 [==============================] - 0s 71us/step - loss: 0.0848 - acc: 0.9831\n",
      "Epoch 10/100\n",
      "1062/1062 [==============================] - 0s 68us/step - loss: 0.0842 - acc: 0.9831\n",
      "Epoch 11/100\n",
      "1062/1062 [==============================] - 0s 69us/step - loss: 0.0830 - acc: 0.9831\n",
      "Epoch 12/100\n",
      "1062/1062 [==============================] - 0s 68us/step - loss: 0.0824 - acc: 0.9831\n",
      "Epoch 13/100\n",
      "1062/1062 [==============================] - 0s 73us/step - loss: 0.0827 - acc: 0.9831\n",
      "Epoch 14/100\n",
      "1062/1062 [==============================] - 0s 73us/step - loss: 0.0822 - acc: 0.9831\n",
      "Epoch 15/100\n",
      "1062/1062 [==============================] - 0s 71us/step - loss: 0.0810 - acc: 0.9831\n",
      "Epoch 16/100\n",
      "1062/1062 [==============================] - 0s 72us/step - loss: 0.0804 - acc: 0.9831\n",
      "Epoch 17/100\n",
      "1062/1062 [==============================] - 0s 72us/step - loss: 0.0800 - acc: 0.9831\n",
      "Epoch 18/100\n",
      "1062/1062 [==============================] - 0s 71us/step - loss: 0.0786 - acc: 0.9831\n",
      "Epoch 19/100\n",
      "1062/1062 [==============================] - 0s 69us/step - loss: 0.0775 - acc: 0.9831\n",
      "Epoch 20/100\n",
      "1062/1062 [==============================] - 0s 71us/step - loss: 0.0775 - acc: 0.9831\n",
      "Epoch 21/100\n",
      "1062/1062 [==============================] - 0s 72us/step - loss: 0.0785 - acc: 0.9831\n",
      "Epoch 22/100\n",
      "1062/1062 [==============================] - 0s 70us/step - loss: 0.0766 - acc: 0.9831\n",
      "Epoch 23/100\n",
      "1062/1062 [==============================] - 0s 70us/step - loss: 0.0745 - acc: 0.9831\n",
      "Epoch 24/100\n",
      "1062/1062 [==============================] - 0s 70us/step - loss: 0.0736 - acc: 0.9831\n",
      "Epoch 25/100\n",
      "1062/1062 [==============================] - 0s 72us/step - loss: 0.0722 - acc: 0.9831\n",
      "Epoch 26/100\n",
      "1062/1062 [==============================] - 0s 71us/step - loss: 0.0736 - acc: 0.9831\n",
      "Epoch 27/100\n",
      "1062/1062 [==============================] - 0s 71us/step - loss: 0.0716 - acc: 0.9831\n",
      "Epoch 28/100\n",
      "1062/1062 [==============================] - 0s 73us/step - loss: 0.0703 - acc: 0.9831\n",
      "Epoch 29/100\n",
      "1062/1062 [==============================] - 0s 72us/step - loss: 0.0694 - acc: 0.9831\n",
      "Epoch 30/100\n",
      "1062/1062 [==============================] - 0s 70us/step - loss: 0.0681 - acc: 0.9831\n",
      "Epoch 31/100\n",
      "1062/1062 [==============================] - 0s 73us/step - loss: 0.0717 - acc: 0.9831\n",
      "Epoch 32/100\n",
      "1062/1062 [==============================] - 0s 71us/step - loss: 0.0679 - acc: 0.9831\n",
      "Epoch 33/100\n",
      "1062/1062 [==============================] - 0s 67us/step - loss: 0.0672 - acc: 0.9831\n",
      "Epoch 34/100\n",
      "1062/1062 [==============================] - 0s 69us/step - loss: 0.0671 - acc: 0.9831\n",
      "Epoch 35/100\n",
      "1062/1062 [==============================] - 0s 72us/step - loss: 0.0635 - acc: 0.9831\n",
      "Epoch 36/100\n",
      "1062/1062 [==============================] - 0s 72us/step - loss: 0.0631 - acc: 0.9831\n",
      "Epoch 37/100\n",
      "1062/1062 [==============================] - 0s 69us/step - loss: 0.0630 - acc: 0.9831\n",
      "Epoch 38/100\n",
      "1062/1062 [==============================] - 0s 67us/step - loss: 0.0611 - acc: 0.9831\n",
      "Epoch 39/100\n",
      "1062/1062 [==============================] - 0s 70us/step - loss: 0.0620 - acc: 0.9831\n",
      "Epoch 40/100\n",
      "1062/1062 [==============================] - 0s 70us/step - loss: 0.0602 - acc: 0.9831\n",
      "Epoch 41/100\n",
      "1062/1062 [==============================] - 0s 71us/step - loss: 0.0597 - acc: 0.9831\n",
      "Epoch 42/100\n",
      "1062/1062 [==============================] - 0s 70us/step - loss: 0.0605 - acc: 0.9831\n",
      "Epoch 43/100\n",
      "1062/1062 [==============================] - 0s 68us/step - loss: 0.0613 - acc: 0.9831\n",
      "Epoch 44/100\n",
      "1062/1062 [==============================] - 0s 71us/step - loss: 0.0582 - acc: 0.9831\n",
      "Epoch 45/100\n",
      "1062/1062 [==============================] - 0s 71us/step - loss: 0.0589 - acc: 0.9831\n",
      "Epoch 46/100\n",
      "1062/1062 [==============================] - 0s 71us/step - loss: 0.0586 - acc: 0.9831\n",
      "Epoch 47/100\n",
      "1062/1062 [==============================] - 0s 70us/step - loss: 0.0583 - acc: 0.9831\n",
      "Epoch 48/100\n",
      "1062/1062 [==============================] - 0s 72us/step - loss: 0.0575 - acc: 0.9831\n",
      "Epoch 49/100\n",
      "1062/1062 [==============================] - 0s 70us/step - loss: 0.0582 - acc: 0.9831\n",
      "Epoch 50/100\n",
      "1062/1062 [==============================] - 0s 71us/step - loss: 0.0574 - acc: 0.9831\n",
      "Epoch 51/100\n",
      "1062/1062 [==============================] - 0s 70us/step - loss: 0.0570 - acc: 0.9831\n",
      "Epoch 52/100\n",
      "1062/1062 [==============================] - 0s 69us/step - loss: 0.0567 - acc: 0.9831\n",
      "Epoch 53/100\n",
      "1062/1062 [==============================] - 0s 70us/step - loss: 0.0563 - acc: 0.9831\n",
      "Epoch 54/100\n",
      "1062/1062 [==============================] - 0s 72us/step - loss: 0.0561 - acc: 0.9831\n",
      "Epoch 55/100\n",
      "1062/1062 [==============================] - 0s 67us/step - loss: 0.0562 - acc: 0.9831\n",
      "Epoch 56/100\n",
      "1062/1062 [==============================] - 0s 57us/step - loss: 0.0561 - acc: 0.9831\n",
      "Epoch 57/100\n",
      "1062/1062 [==============================] - 0s 67us/step - loss: 0.0565 - acc: 0.9831\n",
      "Epoch 58/100\n",
      "1062/1062 [==============================] - 0s 69us/step - loss: 0.0561 - acc: 0.9831\n",
      "Epoch 59/100\n",
      "1062/1062 [==============================] - 0s 68us/step - loss: 0.0555 - acc: 0.9831\n",
      "Epoch 60/100\n",
      "1062/1062 [==============================] - 0s 68us/step - loss: 0.0551 - acc: 0.9831\n",
      "Epoch 61/100\n",
      "1062/1062 [==============================] - 0s 71us/step - loss: 0.0548 - acc: 0.9831\n",
      "Epoch 62/100\n",
      "1062/1062 [==============================] - 0s 66us/step - loss: 0.0543 - acc: 0.9831\n",
      "Epoch 63/100\n",
      "1062/1062 [==============================] - 0s 73us/step - loss: 0.0559 - acc: 0.9831\n",
      "Epoch 64/100\n",
      "1062/1062 [==============================] - 0s 70us/step - loss: 0.0553 - acc: 0.9831\n",
      "Epoch 65/100\n",
      "1062/1062 [==============================] - 0s 68us/step - loss: 0.0544 - acc: 0.9831\n",
      "Epoch 66/100\n",
      "1062/1062 [==============================] - 0s 65us/step - loss: 0.0542 - acc: 0.9831\n",
      "Epoch 67/100\n",
      "1062/1062 [==============================] - 0s 68us/step - loss: 0.0538 - acc: 0.9849: 0s - loss: 0.0575 - acc: 0.984\n",
      "Epoch 68/100\n",
      "1062/1062 [==============================] - 0s 72us/step - loss: 0.0577 - acc: 0.9849\n",
      "Epoch 69/100\n",
      "1062/1062 [==============================] - 0s 73us/step - loss: 0.0527 - acc: 0.9859\n",
      "Epoch 70/100\n",
      "1062/1062 [==============================] - 0s 70us/step - loss: 0.0511 - acc: 0.9868\n",
      "Epoch 71/100\n",
      "1062/1062 [==============================] - 0s 71us/step - loss: 0.0502 - acc: 0.9887\n",
      "Epoch 72/100\n",
      "1062/1062 [==============================] - 0s 70us/step - loss: 0.0501 - acc: 0.9915\n",
      "Epoch 73/100\n",
      "1062/1062 [==============================] - 0s 72us/step - loss: 0.0463 - acc: 0.9906\n",
      "Epoch 74/100\n",
      "1062/1062 [==============================] - 0s 68us/step - loss: 0.0476 - acc: 0.9896\n",
      "Epoch 75/100\n",
      "1062/1062 [==============================] - 0s 69us/step - loss: 0.0461 - acc: 0.9896\n",
      "Epoch 76/100\n",
      "1062/1062 [==============================] - 0s 68us/step - loss: 0.0449 - acc: 0.9915\n",
      "Epoch 77/100\n",
      "1062/1062 [==============================] - 0s 70us/step - loss: 0.0448 - acc: 0.9906\n",
      "Epoch 78/100\n",
      "1062/1062 [==============================] - 0s 72us/step - loss: 0.0468 - acc: 0.9887\n",
      "Epoch 79/100\n",
      "1062/1062 [==============================] - 0s 70us/step - loss: 0.0435 - acc: 0.9915\n",
      "Epoch 80/100\n",
      "1062/1062 [==============================] - 0s 72us/step - loss: 0.0440 - acc: 0.9906\n",
      "Epoch 81/100\n",
      "1062/1062 [==============================] - 0s 70us/step - loss: 0.0431 - acc: 0.9915\n",
      "Epoch 82/100\n",
      "1062/1062 [==============================] - 0s 70us/step - loss: 0.0431 - acc: 0.9915\n",
      "Epoch 83/100\n",
      "1062/1062 [==============================] - 0s 66us/step - loss: 0.0426 - acc: 0.9915\n",
      "Epoch 84/100\n",
      "1062/1062 [==============================] - 0s 69us/step - loss: 0.0423 - acc: 0.9915\n",
      "Epoch 85/100\n",
      "1062/1062 [==============================] - 0s 69us/step - loss: 0.0428 - acc: 0.9915\n",
      "Epoch 86/100\n",
      "1062/1062 [==============================] - 0s 69us/step - loss: 0.0455 - acc: 0.9906\n",
      "Epoch 87/100\n",
      "1062/1062 [==============================] - 0s 65us/step - loss: 0.0420 - acc: 0.9915\n",
      "Epoch 88/100\n",
      "1062/1062 [==============================] - 0s 65us/step - loss: 0.0422 - acc: 0.9915\n",
      "Epoch 89/100\n",
      "1062/1062 [==============================] - 0s 67us/step - loss: 0.0432 - acc: 0.9915\n",
      "Epoch 90/100\n",
      "1062/1062 [==============================] - 0s 70us/step - loss: 0.0444 - acc: 0.9915\n",
      "Epoch 91/100\n",
      "1062/1062 [==============================] - 0s 69us/step - loss: 0.0419 - acc: 0.9915\n",
      "Epoch 92/100\n",
      "1062/1062 [==============================] - 0s 69us/step - loss: 0.0429 - acc: 0.9915\n",
      "Epoch 93/100\n",
      "1062/1062 [==============================] - 0s 67us/step - loss: 0.0423 - acc: 0.9906\n",
      "Epoch 94/100\n",
      "1062/1062 [==============================] - 0s 68us/step - loss: 0.0414 - acc: 0.9915\n",
      "Epoch 95/100\n",
      "1062/1062 [==============================] - 0s 70us/step - loss: 0.0412 - acc: 0.9915\n",
      "Epoch 96/100\n",
      "1062/1062 [==============================] - 0s 68us/step - loss: 0.0409 - acc: 0.9915\n",
      "Epoch 97/100\n",
      "1062/1062 [==============================] - 0s 70us/step - loss: 0.0422 - acc: 0.9915\n",
      "Epoch 98/100\n",
      "1062/1062 [==============================] - 0s 69us/step - loss: 0.0421 - acc: 0.9915\n",
      "Epoch 99/100\n",
      "1062/1062 [==============================] - 0s 69us/step - loss: 0.0409 - acc: 0.9915\n",
      "Epoch 100/100\n",
      "1062/1062 [==============================] - 0s 62us/step - loss: 0.0405 - acc: 0.9915\n",
      "119/119 [==============================] - 0s 195us/step\n",
      "Epoch 1/100\n",
      "1063/1063 [==============================] - 1s 595us/step - loss: 0.6634 - acc: 0.9567\n",
      "Epoch 2/100\n",
      "1063/1063 [==============================] - 0s 67us/step - loss: 0.2604 - acc: 0.9831\n",
      "Epoch 3/100\n",
      "1063/1063 [==============================] - 0s 70us/step - loss: 0.0934 - acc: 0.9831\n",
      "Epoch 4/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.0875 - acc: 0.9831\n",
      "Epoch 5/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.0873 - acc: 0.9831\n",
      "Epoch 6/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0868 - acc: 0.9831\n",
      "Epoch 7/100\n",
      "1063/1063 [==============================] - 0s 65us/step - loss: 0.0873 - acc: 0.9831\n",
      "Epoch 8/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.0863 - acc: 0.9831\n",
      "Epoch 9/100\n",
      "1063/1063 [==============================] - 0s 67us/step - loss: 0.0854 - acc: 0.9831\n",
      "Epoch 10/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.0852 - acc: 0.9831\n",
      "Epoch 11/100\n",
      "1063/1063 [==============================] - 0s 70us/step - loss: 0.0852 - acc: 0.9831\n",
      "Epoch 12/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0851 - acc: 0.9831\n",
      "Epoch 13/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.0846 - acc: 0.9831\n",
      "Epoch 14/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.0844 - acc: 0.9831\n",
      "Epoch 15/100\n",
      "1063/1063 [==============================] - 0s 68us/step - loss: 0.0845 - acc: 0.9831\n",
      "Epoch 16/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.0833 - acc: 0.9831\n",
      "Epoch 17/100\n",
      "1063/1063 [==============================] - 0s 70us/step - loss: 0.0835 - acc: 0.9831\n",
      "Epoch 18/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.0827 - acc: 0.9831\n",
      "Epoch 19/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.0815 - acc: 0.9831\n",
      "Epoch 20/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.0818 - acc: 0.9831\n",
      "Epoch 21/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0816 - acc: 0.9831\n",
      "Epoch 22/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0815 - acc: 0.9831\n",
      "Epoch 23/100\n",
      "1063/1063 [==============================] - 0s 70us/step - loss: 0.0806 - acc: 0.9831\n",
      "Epoch 24/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.0796 - acc: 0.9831\n",
      "Epoch 25/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0801 - acc: 0.9831\n",
      "Epoch 26/100\n",
      "1063/1063 [==============================] - 0s 68us/step - loss: 0.0812 - acc: 0.9831\n",
      "Epoch 27/100\n",
      "1063/1063 [==============================] - 0s 70us/step - loss: 0.0782 - acc: 0.9831\n",
      "Epoch 28/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.0778 - acc: 0.9831\n",
      "Epoch 29/100\n",
      "1063/1063 [==============================] - 0s 70us/step - loss: 0.0784 - acc: 0.9831\n",
      "Epoch 30/100\n",
      "1063/1063 [==============================] - 0s 70us/step - loss: 0.0774 - acc: 0.9831\n",
      "Epoch 31/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.0757 - acc: 0.9831\n",
      "Epoch 32/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.0751 - acc: 0.9831\n",
      "Epoch 33/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.0777 - acc: 0.9831\n",
      "Epoch 34/100\n",
      "1063/1063 [==============================] - 0s 68us/step - loss: 0.0738 - acc: 0.9831\n",
      "Epoch 35/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.0732 - acc: 0.9831\n",
      "Epoch 36/100\n",
      "1063/1063 [==============================] - 0s 63us/step - loss: 0.0727 - acc: 0.9831\n",
      "Epoch 37/100\n",
      "1063/1063 [==============================] - 0s 65us/step - loss: 0.0716 - acc: 0.9831\n",
      "Epoch 38/100\n",
      "1063/1063 [==============================] - 0s 65us/step - loss: 0.0721 - acc: 0.9831\n",
      "Epoch 39/100\n",
      "1063/1063 [==============================] - 0s 68us/step - loss: 0.0757 - acc: 0.9831\n",
      "Epoch 40/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.0709 - acc: 0.9831\n",
      "Epoch 41/100\n",
      "1063/1063 [==============================] - 0s 63us/step - loss: 0.0716 - acc: 0.9831\n",
      "Epoch 42/100\n",
      "1063/1063 [==============================] - 0s 67us/step - loss: 0.0708 - acc: 0.9831\n",
      "Epoch 43/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.0693 - acc: 0.9831\n",
      "Epoch 44/100\n",
      "1063/1063 [==============================] - 0s 64us/step - loss: 0.0683 - acc: 0.9831\n",
      "Epoch 45/100\n",
      "1063/1063 [==============================] - 0s 68us/step - loss: 0.0680 - acc: 0.9831\n",
      "Epoch 46/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.0699 - acc: 0.9831\n",
      "Epoch 47/100\n",
      "1063/1063 [==============================] - 0s 70us/step - loss: 0.0680 - acc: 0.9831\n",
      "Epoch 48/100\n",
      "1063/1063 [==============================] - 0s 66us/step - loss: 0.0671 - acc: 0.9831\n",
      "Epoch 49/100\n",
      "1063/1063 [==============================] - 0s 68us/step - loss: 0.0670 - acc: 0.9831\n",
      "Epoch 50/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.0680 - acc: 0.9831\n",
      "Epoch 51/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.0671 - acc: 0.9831\n",
      "Epoch 52/100\n",
      "1063/1063 [==============================] - 0s 68us/step - loss: 0.0672 - acc: 0.9831\n",
      "Epoch 53/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.0653 - acc: 0.9831\n",
      "Epoch 54/100\n",
      "1063/1063 [==============================] - 0s 70us/step - loss: 0.0670 - acc: 0.9831\n",
      "Epoch 55/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.0674 - acc: 0.9831\n",
      "Epoch 56/100\n",
      "1063/1063 [==============================] - 0s 70us/step - loss: 0.0665 - acc: 0.9831\n",
      "Epoch 57/100\n",
      "1063/1063 [==============================] - 0s 68us/step - loss: 0.0655 - acc: 0.9831\n",
      "Epoch 58/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0646 - acc: 0.9831\n",
      "Epoch 59/100\n",
      "1063/1063 [==============================] - 0s 70us/step - loss: 0.0638 - acc: 0.9831\n",
      "Epoch 60/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0640 - acc: 0.9831\n",
      "Epoch 61/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.0641 - acc: 0.9831\n",
      "Epoch 62/100\n",
      "1063/1063 [==============================] - 0s 68us/step - loss: 0.0642 - acc: 0.9831\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1063/1063 [==============================] - 0s 70us/step - loss: 0.0631 - acc: 0.9831\n",
      "Epoch 64/100\n",
      "1063/1063 [==============================] - 0s 67us/step - loss: 0.0633 - acc: 0.9831\n",
      "Epoch 65/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.0632 - acc: 0.9831\n",
      "Epoch 66/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.0635 - acc: 0.9831\n",
      "Epoch 67/100\n",
      "1063/1063 [==============================] - 0s 61us/step - loss: 0.0628 - acc: 0.9831\n",
      "Epoch 68/100\n",
      "1063/1063 [==============================] - 0s 67us/step - loss: 0.0637 - acc: 0.9831\n",
      "Epoch 69/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0634 - acc: 0.9831\n",
      "Epoch 70/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0617 - acc: 0.9831\n",
      "Epoch 71/100\n",
      "1063/1063 [==============================] - 0s 66us/step - loss: 0.0623 - acc: 0.9831\n",
      "Epoch 72/100\n",
      "1063/1063 [==============================] - 0s 67us/step - loss: 0.0620 - acc: 0.9831\n",
      "Epoch 73/100\n",
      "1063/1063 [==============================] - 0s 68us/step - loss: 0.0615 - acc: 0.9831\n",
      "Epoch 74/100\n",
      "1063/1063 [==============================] - 0s 65us/step - loss: 0.0609 - acc: 0.9831\n",
      "Epoch 75/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.0617 - acc: 0.9831\n",
      "Epoch 76/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.0630 - acc: 0.9831\n",
      "Epoch 77/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.0621 - acc: 0.9831\n",
      "Epoch 78/100\n",
      "1063/1063 [==============================] - 0s 68us/step - loss: 0.0608 - acc: 0.9831\n",
      "Epoch 79/100\n",
      "1063/1063 [==============================] - 0s 68us/step - loss: 0.0609 - acc: 0.9831\n",
      "Epoch 80/100\n",
      "1063/1063 [==============================] - 0s 65us/step - loss: 0.0631 - acc: 0.9831\n",
      "Epoch 81/100\n",
      "1063/1063 [==============================] - 0s 66us/step - loss: 0.0609 - acc: 0.9831\n",
      "Epoch 82/100\n",
      "1063/1063 [==============================] - 0s 70us/step - loss: 0.0606 - acc: 0.9831\n",
      "Epoch 83/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.0608 - acc: 0.9831: 0s - loss: 0.0659 - acc: 0.983\n",
      "Epoch 84/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.0615 - acc: 0.9831\n",
      "Epoch 85/100\n",
      "1063/1063 [==============================] - 0s 68us/step - loss: 0.0619 - acc: 0.9831\n",
      "Epoch 86/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0600 - acc: 0.9831\n",
      "Epoch 87/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0596 - acc: 0.9831\n",
      "Epoch 88/100\n",
      "1063/1063 [==============================] - 0s 80us/step - loss: 0.0600 - acc: 0.9831\n",
      "Epoch 89/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.0605 - acc: 0.9831\n",
      "Epoch 90/100\n",
      "1063/1063 [==============================] - 0s 70us/step - loss: 0.0590 - acc: 0.9831\n",
      "Epoch 91/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.0610 - acc: 0.9831\n",
      "Epoch 92/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0595 - acc: 0.9831\n",
      "Epoch 93/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.0599 - acc: 0.9831\n",
      "Epoch 94/100\n",
      "1063/1063 [==============================] - 0s 70us/step - loss: 0.0601 - acc: 0.9831\n",
      "Epoch 95/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.0592 - acc: 0.9831\n",
      "Epoch 96/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.0587 - acc: 0.9831\n",
      "Epoch 97/100\n",
      "1063/1063 [==============================] - 0s 70us/step - loss: 0.0631 - acc: 0.9831\n",
      "Epoch 98/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.0598 - acc: 0.9831\n",
      "Epoch 99/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.0589 - acc: 0.9831\n",
      "Epoch 100/100\n",
      "1063/1063 [==============================] - 0s 68us/step - loss: 0.0590 - acc: 0.9831\n",
      "118/118 [==============================] - 0s 466us/step\n",
      "Epoch 1/100\n",
      "1063/1063 [==============================] - 1s 646us/step - loss: 0.6855 - acc: 0.9539\n",
      "Epoch 2/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.6694 - acc: 0.9821\n",
      "Epoch 3/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.6538 - acc: 0.9821\n",
      "Epoch 4/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.6386 - acc: 0.9821\n",
      "Epoch 5/100\n",
      "1063/1063 [==============================] - 0s 70us/step - loss: 0.6238 - acc: 0.9821\n",
      "Epoch 6/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.6095 - acc: 0.9821\n",
      "Epoch 7/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.5955 - acc: 0.9821\n",
      "Epoch 8/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.5819 - acc: 0.9821\n",
      "Epoch 9/100\n",
      "1063/1063 [==============================] - 0s 70us/step - loss: 0.5686 - acc: 0.9821\n",
      "Epoch 10/100\n",
      "1063/1063 [==============================] - 0s 70us/step - loss: 0.5557 - acc: 0.9821\n",
      "Epoch 11/100\n",
      "1063/1063 [==============================] - 0s 68us/step - loss: 0.5432 - acc: 0.9821\n",
      "Epoch 12/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.5310 - acc: 0.9821\n",
      "Epoch 13/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.5193 - acc: 0.9821\n",
      "Epoch 14/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.5078 - acc: 0.9821\n",
      "Epoch 15/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.4966 - acc: 0.9821\n",
      "Epoch 16/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.4857 - acc: 0.9821\n",
      "Epoch 17/100\n",
      "1063/1063 [==============================] - 0s 64us/step - loss: 0.4752 - acc: 0.9821\n",
      "Epoch 18/100\n",
      "1063/1063 [==============================] - 0s 70us/step - loss: 0.4650 - acc: 0.9821\n",
      "Epoch 19/100\n",
      "1063/1063 [==============================] - 0s 67us/step - loss: 0.4550 - acc: 0.9821\n",
      "Epoch 20/100\n",
      "1063/1063 [==============================] - 0s 70us/step - loss: 0.4453 - acc: 0.9821\n",
      "Epoch 21/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.4359 - acc: 0.9821\n",
      "Epoch 22/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.4267 - acc: 0.9821\n",
      "Epoch 23/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.4178 - acc: 0.9821\n",
      "Epoch 24/100\n",
      "1063/1063 [==============================] - 0s 66us/step - loss: 0.4092 - acc: 0.9821\n",
      "Epoch 25/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.4007 - acc: 0.9821\n",
      "Epoch 26/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.3926 - acc: 0.9821\n",
      "Epoch 27/100\n",
      "1063/1063 [==============================] - 0s 70us/step - loss: 0.3846 - acc: 0.9821\n",
      "Epoch 28/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.3769 - acc: 0.9821\n",
      "Epoch 29/100\n",
      "1063/1063 [==============================] - 0s 70us/step - loss: 0.3694 - acc: 0.9821\n",
      "Epoch 30/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.3622 - acc: 0.9821\n",
      "Epoch 31/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.3550 - acc: 0.9821\n",
      "Epoch 32/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.3482 - acc: 0.9821\n",
      "Epoch 33/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.3415 - acc: 0.9821\n",
      "Epoch 34/100\n",
      "1063/1063 [==============================] - 0s 68us/step - loss: 0.3350 - acc: 0.9821\n",
      "Epoch 35/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.3286 - acc: 0.9821\n",
      "Epoch 36/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.3225 - acc: 0.9821\n",
      "Epoch 37/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.3165 - acc: 0.9821\n",
      "Epoch 38/100\n",
      "1063/1063 [==============================] - 0s 67us/step - loss: 0.3107 - acc: 0.9821\n",
      "Epoch 39/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.3050 - acc: 0.9821\n",
      "Epoch 40/100\n",
      "1063/1063 [==============================] - 0s 70us/step - loss: 0.2995 - acc: 0.9821\n",
      "Epoch 41/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.2942 - acc: 0.9821\n",
      "Epoch 42/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.2889 - acc: 0.9821\n",
      "Epoch 43/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.2839 - acc: 0.9821\n",
      "Epoch 44/100\n",
      "1063/1063 [==============================] - 0s 70us/step - loss: 0.2789 - acc: 0.9821\n",
      "Epoch 45/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.2741 - acc: 0.9821\n",
      "Epoch 46/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.2694 - acc: 0.9821\n",
      "Epoch 47/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.2649 - acc: 0.9821\n",
      "Epoch 48/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.2605 - acc: 0.9821\n",
      "Epoch 49/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.2562 - acc: 0.9821\n",
      "Epoch 50/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.2520 - acc: 0.9821\n",
      "Epoch 51/100\n",
      "1063/1063 [==============================] - 0s 70us/step - loss: 0.2479 - acc: 0.9821\n",
      "Epoch 52/100\n",
      "1063/1063 [==============================] - 0s 70us/step - loss: 0.2440 - acc: 0.9821\n",
      "Epoch 53/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.2401 - acc: 0.9821\n",
      "Epoch 54/100\n",
      "1063/1063 [==============================] - 0s 68us/step - loss: 0.2364 - acc: 0.9821\n",
      "Epoch 55/100\n",
      "1063/1063 [==============================] - 0s 68us/step - loss: 0.2328 - acc: 0.9821\n",
      "Epoch 56/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.2292 - acc: 0.9821\n",
      "Epoch 57/100\n",
      "1063/1063 [==============================] - 0s 70us/step - loss: 0.2257 - acc: 0.9821\n",
      "Epoch 58/100\n",
      "1063/1063 [==============================] - 0s 70us/step - loss: 0.2223 - acc: 0.9821\n",
      "Epoch 59/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.2190 - acc: 0.9821\n",
      "Epoch 60/100\n",
      "1063/1063 [==============================] - 0s 67us/step - loss: 0.2158 - acc: 0.9821\n",
      "Epoch 61/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.2127 - acc: 0.9821\n",
      "Epoch 62/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.2097 - acc: 0.9821\n",
      "Epoch 63/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.2067 - acc: 0.9821\n",
      "Epoch 64/100\n",
      "1063/1063 [==============================] - 0s 70us/step - loss: 0.2038 - acc: 0.9821\n",
      "Epoch 65/100\n",
      "1063/1063 [==============================] - 0s 70us/step - loss: 0.2010 - acc: 0.9821\n",
      "Epoch 66/100\n",
      "1063/1063 [==============================] - 0s 66us/step - loss: 0.1982 - acc: 0.9821\n",
      "Epoch 67/100\n",
      "1063/1063 [==============================] - 0s 67us/step - loss: 0.1956 - acc: 0.9821: 0s - loss: 0.2003 - acc: 0.979\n",
      "Epoch 68/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.1929 - acc: 0.9821\n",
      "Epoch 69/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.1904 - acc: 0.9821\n",
      "Epoch 70/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.1879 - acc: 0.9821\n",
      "Epoch 71/100\n",
      "1063/1063 [==============================] - 0s 84us/step - loss: 0.1855 - acc: 0.9821\n",
      "Epoch 72/100\n",
      "1063/1063 [==============================] - 0s 76us/step - loss: 0.1831 - acc: 0.9821\n",
      "Epoch 73/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.1808 - acc: 0.9821\n",
      "Epoch 74/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.1786 - acc: 0.9821\n",
      "Epoch 75/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.1764 - acc: 0.9821\n",
      "Epoch 76/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.1743 - acc: 0.9821\n",
      "Epoch 77/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.1722 - acc: 0.9821\n",
      "Epoch 78/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.1702 - acc: 0.9821\n",
      "Epoch 79/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.1682 - acc: 0.9821\n",
      "Epoch 80/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.1662 - acc: 0.9821\n",
      "Epoch 81/100\n",
      "1063/1063 [==============================] - 0s 70us/step - loss: 0.1644 - acc: 0.9821\n",
      "Epoch 82/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.1625 - acc: 0.9821\n",
      "Epoch 83/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.1607 - acc: 0.9821\n",
      "Epoch 84/100\n",
      "1063/1063 [==============================] - 0s 70us/step - loss: 0.1590 - acc: 0.9821\n",
      "Epoch 85/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.1572 - acc: 0.9821\n",
      "Epoch 86/100\n",
      "1063/1063 [==============================] - 0s 70us/step - loss: 0.1556 - acc: 0.9821\n",
      "Epoch 87/100\n",
      "1063/1063 [==============================] - 0s 67us/step - loss: 0.1539 - acc: 0.9821\n",
      "Epoch 88/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.1523 - acc: 0.9821\n",
      "Epoch 89/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.1508 - acc: 0.9821\n",
      "Epoch 90/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.1492 - acc: 0.9821\n",
      "Epoch 91/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.1478 - acc: 0.9821\n",
      "Epoch 92/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.1463 - acc: 0.9821\n",
      "Epoch 93/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.1449 - acc: 0.9821\n",
      "Epoch 94/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.1435 - acc: 0.9821\n",
      "Epoch 95/100\n",
      "1063/1063 [==============================] - 0s 67us/step - loss: 0.1422 - acc: 0.9821\n",
      "Epoch 96/100\n",
      "1063/1063 [==============================] - 0s 70us/step - loss: 0.1408 - acc: 0.9821\n",
      "Epoch 97/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.1396 - acc: 0.9821\n",
      "Epoch 98/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.1383 - acc: 0.9821\n",
      "Epoch 99/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.1371 - acc: 0.9821\n",
      "Epoch 100/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.1359 - acc: 0.9821\n",
      "118/118 [==============================] - 0s 580us/step\n",
      "Epoch 1/100\n",
      "1063/1063 [==============================] - 0s 460us/step - loss: 0.6532 - acc: 0.9821\n",
      "Epoch 2/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.2706 - acc: 0.9831\n",
      "Epoch 3/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.0879 - acc: 0.9831\n",
      "Epoch 4/100\n",
      "1063/1063 [==============================] - 0s 68us/step - loss: 0.0868 - acc: 0.9831\n",
      "Epoch 5/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.0875 - acc: 0.9831\n",
      "Epoch 6/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.0865 - acc: 0.9831\n",
      "Epoch 7/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0864 - acc: 0.9831\n",
      "Epoch 8/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0858 - acc: 0.9831\n",
      "Epoch 9/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0861 - acc: 0.9831\n",
      "Epoch 10/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0855 - acc: 0.9831\n",
      "Epoch 11/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0850 - acc: 0.9831\n",
      "Epoch 12/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.0844 - acc: 0.9831\n",
      "Epoch 13/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.0846 - acc: 0.9831\n",
      "Epoch 14/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0841 - acc: 0.9831\n",
      "Epoch 15/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0834 - acc: 0.9831\n",
      "Epoch 16/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.0826 - acc: 0.9831\n",
      "Epoch 17/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0822 - acc: 0.9831\n",
      "Epoch 18/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0838 - acc: 0.9831\n",
      "Epoch 19/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0811 - acc: 0.9831\n",
      "Epoch 20/100\n",
      "1063/1063 [==============================] - 0s 70us/step - loss: 0.0809 - acc: 0.9831\n",
      "Epoch 21/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0807 - acc: 0.9831\n",
      "Epoch 22/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0802 - acc: 0.9831\n",
      "Epoch 23/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0797 - acc: 0.9831\n",
      "Epoch 24/100\n",
      "1063/1063 [==============================] - 0s 70us/step - loss: 0.0792 - acc: 0.9831\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1063/1063 [==============================] - 0s 68us/step - loss: 0.0784 - acc: 0.9831\n",
      "Epoch 26/100\n",
      "1063/1063 [==============================] - 0s 70us/step - loss: 0.0777 - acc: 0.9831\n",
      "Epoch 27/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.0775 - acc: 0.9831\n",
      "Epoch 28/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0763 - acc: 0.9831\n",
      "Epoch 29/100\n",
      "1063/1063 [==============================] - 0s 53us/step - loss: 0.0763 - acc: 0.9831\n",
      "Epoch 30/100\n",
      "1063/1063 [==============================] - 0s 56us/step - loss: 0.0750 - acc: 0.9831\n",
      "Epoch 31/100\n",
      "1063/1063 [==============================] - 0s 62us/step - loss: 0.0745 - acc: 0.9831\n",
      "Epoch 32/100\n",
      "1063/1063 [==============================] - 0s 59us/step - loss: 0.0743 - acc: 0.9831\n",
      "Epoch 33/100\n",
      "1063/1063 [==============================] - 0s 57us/step - loss: 0.0742 - acc: 0.9831\n",
      "Epoch 34/100\n",
      "1063/1063 [==============================] - 0s 53us/step - loss: 0.0726 - acc: 0.9831\n",
      "Epoch 35/100\n",
      "1063/1063 [==============================] - 0s 62us/step - loss: 0.0717 - acc: 0.9831\n",
      "Epoch 36/100\n",
      "1063/1063 [==============================] - 0s 60us/step - loss: 0.0719 - acc: 0.9831\n",
      "Epoch 37/100\n",
      "1063/1063 [==============================] - 0s 59us/step - loss: 0.0704 - acc: 0.9831\n",
      "Epoch 38/100\n",
      "1063/1063 [==============================] - 0s 62us/step - loss: 0.0698 - acc: 0.9831\n",
      "Epoch 39/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0696 - acc: 0.9831\n",
      "Epoch 40/100\n",
      "1063/1063 [==============================] - 0s 70us/step - loss: 0.0688 - acc: 0.9831\n",
      "Epoch 41/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0694 - acc: 0.9831\n",
      "Epoch 42/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0706 - acc: 0.9831\n",
      "Epoch 43/100\n",
      "1063/1063 [==============================] - 0s 70us/step - loss: 0.0671 - acc: 0.9831\n",
      "Epoch 44/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.0676 - acc: 0.9831\n",
      "Epoch 45/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.0666 - acc: 0.9831\n",
      "Epoch 46/100\n",
      "1063/1063 [==============================] - 0s 70us/step - loss: 0.0663 - acc: 0.9831\n",
      "Epoch 47/100\n",
      "1063/1063 [==============================] - 0s 70us/step - loss: 0.0668 - acc: 0.9831\n",
      "Epoch 48/100\n",
      "1063/1063 [==============================] - 0s 67us/step - loss: 0.0650 - acc: 0.9831\n",
      "Epoch 49/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.0654 - acc: 0.9831\n",
      "Epoch 50/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.0661 - acc: 0.9831\n",
      "Epoch 51/100\n",
      "1063/1063 [==============================] - 0s 70us/step - loss: 0.0647 - acc: 0.9831\n",
      "Epoch 52/100\n",
      "1063/1063 [==============================] - 0s 70us/step - loss: 0.0646 - acc: 0.9831\n",
      "Epoch 53/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.0652 - acc: 0.9831\n",
      "Epoch 54/100\n",
      "1063/1063 [==============================] - 0s 70us/step - loss: 0.0642 - acc: 0.9831\n",
      "Epoch 55/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.0640 - acc: 0.9831\n",
      "Epoch 56/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0639 - acc: 0.9831\n",
      "Epoch 57/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.0656 - acc: 0.9831\n",
      "Epoch 58/100\n",
      "1063/1063 [==============================] - 0s 66us/step - loss: 0.0658 - acc: 0.9831\n",
      "Epoch 59/100\n",
      "1063/1063 [==============================] - 0s 61us/step - loss: 0.0639 - acc: 0.9831\n",
      "Epoch 60/100\n",
      "1063/1063 [==============================] - 0s 70us/step - loss: 0.0632 - acc: 0.9831\n",
      "Epoch 61/100\n",
      "1063/1063 [==============================] - 0s 67us/step - loss: 0.0643 - acc: 0.9831\n",
      "Epoch 62/100\n",
      "1063/1063 [==============================] - 0s 66us/step - loss: 0.0639 - acc: 0.9831\n",
      "Epoch 63/100\n",
      "1063/1063 [==============================] - 0s 63us/step - loss: 0.0624 - acc: 0.9831\n",
      "Epoch 64/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0652 - acc: 0.9831\n",
      "Epoch 65/100\n",
      "1063/1063 [==============================] - 0s 70us/step - loss: 0.0646 - acc: 0.9831\n",
      "Epoch 66/100\n",
      "1063/1063 [==============================] - 0s 67us/step - loss: 0.0634 - acc: 0.9831\n",
      "Epoch 67/100\n",
      "1063/1063 [==============================] - 0s 70us/step - loss: 0.0634 - acc: 0.9831\n",
      "Epoch 68/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.0636 - acc: 0.9831\n",
      "Epoch 69/100\n",
      "1063/1063 [==============================] - 0s 67us/step - loss: 0.0627 - acc: 0.9831\n",
      "Epoch 70/100\n",
      "1063/1063 [==============================] - 0s 62us/step - loss: 0.0632 - acc: 0.9831\n",
      "Epoch 71/100\n",
      "1063/1063 [==============================] - 0s 59us/step - loss: 0.0624 - acc: 0.9831\n",
      "Epoch 72/100\n",
      "1063/1063 [==============================] - 0s 67us/step - loss: 0.0639 - acc: 0.9831\n",
      "Epoch 73/100\n",
      "1063/1063 [==============================] - 0s 65us/step - loss: 0.0613 - acc: 0.9831\n",
      "Epoch 74/100\n",
      "1063/1063 [==============================] - 0s 61us/step - loss: 0.0643 - acc: 0.9831\n",
      "Epoch 75/100\n",
      "1063/1063 [==============================] - 0s 54us/step - loss: 0.0620 - acc: 0.9831\n",
      "Epoch 76/100\n",
      "1063/1063 [==============================] - 0s 62us/step - loss: 0.0607 - acc: 0.9831\n",
      "Epoch 77/100\n",
      "1063/1063 [==============================] - 0s 60us/step - loss: 0.0611 - acc: 0.9831\n",
      "Epoch 78/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.0618 - acc: 0.9831\n",
      "Epoch 79/100\n",
      "1063/1063 [==============================] - 0s 48us/step - loss: 0.0632 - acc: 0.9831\n",
      "Epoch 80/100\n",
      "1063/1063 [==============================] - 0s 42us/step - loss: 0.0605 - acc: 0.9831\n",
      "Epoch 81/100\n",
      "1063/1063 [==============================] - 0s 66us/step - loss: 0.0607 - acc: 0.9831\n",
      "Epoch 82/100\n",
      "1063/1063 [==============================] - 0s 55us/step - loss: 0.0601 - acc: 0.9831\n",
      "Epoch 83/100\n",
      "1063/1063 [==============================] - 0s 66us/step - loss: 0.0597 - acc: 0.9831\n",
      "Epoch 84/100\n",
      "1063/1063 [==============================] - 0s 64us/step - loss: 0.0587 - acc: 0.9831\n",
      "Epoch 85/100\n",
      "1063/1063 [==============================] - 0s 60us/step - loss: 0.0594 - acc: 0.9831\n",
      "Epoch 86/100\n",
      "1063/1063 [==============================] - 0s 57us/step - loss: 0.0585 - acc: 0.9831\n",
      "Epoch 87/100\n",
      "1063/1063 [==============================] - 0s 53us/step - loss: 0.0581 - acc: 0.9831\n",
      "Epoch 88/100\n",
      "1063/1063 [==============================] - 0s 55us/step - loss: 0.0576 - acc: 0.9831\n",
      "Epoch 89/100\n",
      "1063/1063 [==============================] - 0s 56us/step - loss: 0.0573 - acc: 0.9831\n",
      "Epoch 90/100\n",
      "1063/1063 [==============================] - 0s 59us/step - loss: 0.0570 - acc: 0.9831\n",
      "Epoch 91/100\n",
      "1063/1063 [==============================] - 0s 64us/step - loss: 0.0567 - acc: 0.9831\n",
      "Epoch 92/100\n",
      "1063/1063 [==============================] - 0s 60us/step - loss: 0.0560 - acc: 0.9831\n",
      "Epoch 93/100\n",
      "1063/1063 [==============================] - 0s 56us/step - loss: 0.0555 - acc: 0.9831\n",
      "Epoch 94/100\n",
      "1063/1063 [==============================] - 0s 49us/step - loss: 0.0581 - acc: 0.9831\n",
      "Epoch 95/100\n",
      "1063/1063 [==============================] - 0s 55us/step - loss: 0.0560 - acc: 0.9831\n",
      "Epoch 96/100\n",
      "1063/1063 [==============================] - 0s 60us/step - loss: 0.0567 - acc: 0.9831\n",
      "Epoch 97/100\n",
      "1063/1063 [==============================] - 0s 60us/step - loss: 0.0560 - acc: 0.9831\n",
      "Epoch 98/100\n",
      "1063/1063 [==============================] - 0s 56us/step - loss: 0.0561 - acc: 0.9831\n",
      "Epoch 99/100\n",
      "1063/1063 [==============================] - 0s 65us/step - loss: 0.0553 - acc: 0.9831\n",
      "Epoch 100/100\n",
      "1063/1063 [==============================] - 0s 56us/step - loss: 0.0565 - acc: 0.9831\n",
      "118/118 [==============================] - 0s 615us/step\n",
      "Epoch 1/100\n",
      "1063/1063 [==============================] - 1s 512us/step - loss: 0.6551 - acc: 0.9633\n",
      "Epoch 2/100\n",
      "1063/1063 [==============================] - 0s 64us/step - loss: 0.2797 - acc: 0.9831\n",
      "Epoch 3/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.0890 - acc: 0.9831\n",
      "Epoch 4/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0866 - acc: 0.9831\n",
      "Epoch 5/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.0860 - acc: 0.9831\n",
      "Epoch 6/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.0856 - acc: 0.9831\n",
      "Epoch 7/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0850 - acc: 0.9831\n",
      "Epoch 8/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0846 - acc: 0.9831\n",
      "Epoch 9/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.0848 - acc: 0.9831\n",
      "Epoch 10/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0838 - acc: 0.9831\n",
      "Epoch 11/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0832 - acc: 0.9831\n",
      "Epoch 12/100\n",
      "1063/1063 [==============================] - 0s 70us/step - loss: 0.0831 - acc: 0.9831\n",
      "Epoch 13/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0825 - acc: 0.9831\n",
      "Epoch 14/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0823 - acc: 0.9831\n",
      "Epoch 15/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0812 - acc: 0.9831\n",
      "Epoch 16/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.0812 - acc: 0.9831\n",
      "Epoch 17/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0802 - acc: 0.9831\n",
      "Epoch 18/100\n",
      "1063/1063 [==============================] - 0s 65us/step - loss: 0.0804 - acc: 0.9831\n",
      "Epoch 19/100\n",
      "1063/1063 [==============================] - 0s 55us/step - loss: 0.0798 - acc: 0.9831\n",
      "Epoch 20/100\n",
      "1063/1063 [==============================] - 0s 64us/step - loss: 0.0786 - acc: 0.9831\n",
      "Epoch 21/100\n",
      "1063/1063 [==============================] - 0s 66us/step - loss: 0.0807 - acc: 0.9831\n",
      "Epoch 22/100\n",
      "1063/1063 [==============================] - 0s 60us/step - loss: 0.0774 - acc: 0.9831\n",
      "Epoch 23/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.0769 - acc: 0.9831\n",
      "Epoch 24/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0767 - acc: 0.9831\n",
      "Epoch 25/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.0756 - acc: 0.9831\n",
      "Epoch 26/100\n",
      "1063/1063 [==============================] - 0s 76us/step - loss: 0.0752 - acc: 0.9831\n",
      "Epoch 27/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0751 - acc: 0.9831\n",
      "Epoch 28/100\n",
      "1063/1063 [==============================] - 0s 77us/step - loss: 0.0744 - acc: 0.9831\n",
      "Epoch 29/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0746 - acc: 0.9831\n",
      "Epoch 30/100\n",
      "1063/1063 [==============================] - 0s 78us/step - loss: 0.0737 - acc: 0.9831\n",
      "Epoch 31/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0728 - acc: 0.9831\n",
      "Epoch 32/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0724 - acc: 0.9831\n",
      "Epoch 33/100\n",
      "1063/1063 [==============================] - 0s 76us/step - loss: 0.0715 - acc: 0.9831\n",
      "Epoch 34/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0711 - acc: 0.9831\n",
      "Epoch 35/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0716 - acc: 0.9831\n",
      "Epoch 36/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.0708 - acc: 0.9831\n",
      "Epoch 37/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.0714 - acc: 0.9831\n",
      "Epoch 38/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0711 - acc: 0.9831\n",
      "Epoch 39/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.0687 - acc: 0.9831\n",
      "Epoch 40/100\n",
      "1063/1063 [==============================] - 0s 77us/step - loss: 0.0720 - acc: 0.9831\n",
      "Epoch 41/100\n",
      "1063/1063 [==============================] - 0s 76us/step - loss: 0.0681 - acc: 0.9831\n",
      "Epoch 42/100\n",
      "1063/1063 [==============================] - 0s 80us/step - loss: 0.0673 - acc: 0.9831\n",
      "Epoch 43/100\n",
      "1063/1063 [==============================] - 0s 77us/step - loss: 0.0683 - acc: 0.9831\n",
      "Epoch 44/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.0672 - acc: 0.9831\n",
      "Epoch 45/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0672 - acc: 0.9831\n",
      "Epoch 46/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0701 - acc: 0.9831\n",
      "Epoch 47/100\n",
      "1063/1063 [==============================] - 0s 79us/step - loss: 0.0682 - acc: 0.9831\n",
      "Epoch 48/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.0674 - acc: 0.9831\n",
      "Epoch 49/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.0663 - acc: 0.9831\n",
      "Epoch 50/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.0662 - acc: 0.9831\n",
      "Epoch 51/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0664 - acc: 0.9831\n",
      "Epoch 52/100\n",
      "1063/1063 [==============================] - 0s 67us/step - loss: 0.0665 - acc: 0.9831\n",
      "Epoch 53/100\n",
      "1063/1063 [==============================] - 0s 64us/step - loss: 0.0651 - acc: 0.9831\n",
      "Epoch 54/100\n",
      "1063/1063 [==============================] - 0s 60us/step - loss: 0.0649 - acc: 0.9831\n",
      "Epoch 55/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0640 - acc: 0.9831\n",
      "Epoch 56/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0635 - acc: 0.9831\n",
      "Epoch 57/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0632 - acc: 0.9831\n",
      "Epoch 58/100\n",
      "1063/1063 [==============================] - 0s 67us/step - loss: 0.0633 - acc: 0.9831\n",
      "Epoch 59/100\n",
      "1063/1063 [==============================] - 0s 68us/step - loss: 0.0641 - acc: 0.9831\n",
      "Epoch 60/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0634 - acc: 0.9831\n",
      "Epoch 61/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0632 - acc: 0.9831\n",
      "Epoch 62/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0631 - acc: 0.9831\n",
      "Epoch 63/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0623 - acc: 0.9831\n",
      "Epoch 64/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0625 - acc: 0.9831\n",
      "Epoch 65/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0622 - acc: 0.9831\n",
      "Epoch 66/100\n",
      "1063/1063 [==============================] - 0s 70us/step - loss: 0.0619 - acc: 0.9831\n",
      "Epoch 67/100\n",
      "1063/1063 [==============================] - 0s 70us/step - loss: 0.0628 - acc: 0.9831\n",
      "Epoch 68/100\n",
      "1063/1063 [==============================] - 0s 70us/step - loss: 0.0617 - acc: 0.9831\n",
      "Epoch 69/100\n",
      "1063/1063 [==============================] - 0s 68us/step - loss: 0.0634 - acc: 0.9831\n",
      "Epoch 70/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0611 - acc: 0.9831\n",
      "Epoch 71/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0613 - acc: 0.9831\n",
      "Epoch 72/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0608 - acc: 0.9831\n",
      "Epoch 73/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0613 - acc: 0.9831\n",
      "Epoch 74/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0611 - acc: 0.9831\n",
      "Epoch 75/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0622 - acc: 0.9831\n",
      "Epoch 76/100\n",
      "1063/1063 [==============================] - 0s 66us/step - loss: 0.0604 - acc: 0.9831\n",
      "Epoch 77/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0629 - acc: 0.9831\n",
      "Epoch 78/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0604 - acc: 0.9831\n",
      "Epoch 79/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0609 - acc: 0.9831\n",
      "Epoch 80/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0614 - acc: 0.9831\n",
      "Epoch 81/100\n",
      "1063/1063 [==============================] - 0s 78us/step - loss: 0.0607 - acc: 0.9831\n",
      "Epoch 82/100\n",
      "1063/1063 [==============================] - 0s 77us/step - loss: 0.0618 - acc: 0.9831\n",
      "Epoch 83/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.0597 - acc: 0.9831\n",
      "Epoch 84/100\n",
      "1063/1063 [==============================] - 0s 77us/step - loss: 0.0613 - acc: 0.9831\n",
      "Epoch 85/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.0603 - acc: 0.9831\n",
      "Epoch 86/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0614 - acc: 0.9831\n",
      "Epoch 87/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0607 - acc: 0.9831\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0596 - acc: 0.9831\n",
      "Epoch 89/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0599 - acc: 0.9831\n",
      "Epoch 90/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.0606 - acc: 0.9831\n",
      "Epoch 91/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0590 - acc: 0.9831\n",
      "Epoch 92/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0601 - acc: 0.9831\n",
      "Epoch 93/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0594 - acc: 0.9831\n",
      "Epoch 94/100\n",
      "1063/1063 [==============================] - 0s 79us/step - loss: 0.0596 - acc: 0.9831\n",
      "Epoch 95/100\n",
      "1063/1063 [==============================] - 0s 77us/step - loss: 0.0592 - acc: 0.9831\n",
      "Epoch 96/100\n",
      "1063/1063 [==============================] - 0s 78us/step - loss: 0.0592 - acc: 0.9831\n",
      "Epoch 97/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.0603 - acc: 0.9831\n",
      "Epoch 98/100\n",
      "1063/1063 [==============================] - 0s 76us/step - loss: 0.0599 - acc: 0.9831\n",
      "Epoch 99/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.0593 - acc: 0.9831\n",
      "Epoch 100/100\n",
      "1063/1063 [==============================] - 0s 77us/step - loss: 0.0582 - acc: 0.9831\n",
      "118/118 [==============================] - 0s 912us/step\n",
      "Epoch 1/100\n",
      "1063/1063 [==============================] - 1s 589us/step - loss: 0.6402 - acc: 0.9831\n",
      "Epoch 2/100\n",
      "1063/1063 [==============================] - 0s 63us/step - loss: 0.1920 - acc: 0.9831\n",
      "Epoch 3/100\n",
      "1063/1063 [==============================] - 0s 65us/step - loss: 0.0921 - acc: 0.9831\n",
      "Epoch 4/100\n",
      "1063/1063 [==============================] - 0s 63us/step - loss: 0.0873 - acc: 0.9831\n",
      "Epoch 5/100\n",
      "1063/1063 [==============================] - 0s 66us/step - loss: 0.0865 - acc: 0.9831\n",
      "Epoch 6/100\n",
      "1063/1063 [==============================] - 0s 60us/step - loss: 0.0868 - acc: 0.9831\n",
      "Epoch 7/100\n",
      "1063/1063 [==============================] - 0s 63us/step - loss: 0.0862 - acc: 0.9831\n",
      "Epoch 8/100\n",
      "1063/1063 [==============================] - 0s 60us/step - loss: 0.0859 - acc: 0.9831\n",
      "Epoch 9/100\n",
      "1063/1063 [==============================] - 0s 67us/step - loss: 0.0851 - acc: 0.9831\n",
      "Epoch 10/100\n",
      "1063/1063 [==============================] - 0s 68us/step - loss: 0.0850 - acc: 0.9831\n",
      "Epoch 11/100\n",
      "1063/1063 [==============================] - 0s 62us/step - loss: 0.0844 - acc: 0.9831\n",
      "Epoch 12/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.0836 - acc: 0.9831\n",
      "Epoch 13/100\n",
      "1063/1063 [==============================] - 0s 68us/step - loss: 0.0835 - acc: 0.9831\n",
      "Epoch 14/100\n",
      "1063/1063 [==============================] - 0s 64us/step - loss: 0.0830 - acc: 0.9831\n",
      "Epoch 15/100\n",
      "1063/1063 [==============================] - 0s 63us/step - loss: 0.0836 - acc: 0.9831: 0s - loss: 0.0747 - acc: 0.985\n",
      "Epoch 16/100\n",
      "1063/1063 [==============================] - 0s 60us/step - loss: 0.0819 - acc: 0.9831\n",
      "Epoch 17/100\n",
      "1063/1063 [==============================] - 0s 61us/step - loss: 0.0819 - acc: 0.9831\n",
      "Epoch 18/100\n",
      "1063/1063 [==============================] - 0s 63us/step - loss: 0.0814 - acc: 0.9831\n",
      "Epoch 19/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.0809 - acc: 0.9831\n",
      "Epoch 20/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.0798 - acc: 0.9831: 0s - loss: 0.0808 - acc: 0.983\n",
      "Epoch 21/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0801 - acc: 0.9831\n",
      "Epoch 22/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.0806 - acc: 0.9831\n",
      "Epoch 23/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.0792 - acc: 0.9831\n",
      "Epoch 24/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0777 - acc: 0.9831\n",
      "Epoch 25/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.0774 - acc: 0.9831\n",
      "Epoch 26/100\n",
      "1063/1063 [==============================] - 0s 67us/step - loss: 0.0767 - acc: 0.9831\n",
      "Epoch 27/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0770 - acc: 0.9831\n",
      "Epoch 28/100\n",
      "1063/1063 [==============================] - 0s 66us/step - loss: 0.0749 - acc: 0.9831\n",
      "Epoch 29/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0752 - acc: 0.9831\n",
      "Epoch 30/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.0751 - acc: 0.9831\n",
      "Epoch 31/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0732 - acc: 0.9831\n",
      "Epoch 32/100\n",
      "1063/1063 [==============================] - 0s 76us/step - loss: 0.0721 - acc: 0.9831\n",
      "Epoch 33/100\n",
      "1063/1063 [==============================] - 0s 76us/step - loss: 0.0716 - acc: 0.9831\n",
      "Epoch 34/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.0707 - acc: 0.9831\n",
      "Epoch 35/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0706 - acc: 0.9831\n",
      "Epoch 36/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0711 - acc: 0.9831\n",
      "Epoch 37/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0693 - acc: 0.9831\n",
      "Epoch 38/100\n",
      "1063/1063 [==============================] - 0s 76us/step - loss: 0.0706 - acc: 0.9831\n",
      "Epoch 39/100\n",
      "1063/1063 [==============================] - 0s 76us/step - loss: 0.0712 - acc: 0.9831\n",
      "Epoch 40/100\n",
      "1063/1063 [==============================] - 0s 76us/step - loss: 0.0688 - acc: 0.9831\n",
      "Epoch 41/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0683 - acc: 0.9831\n",
      "Epoch 42/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0675 - acc: 0.9831\n",
      "Epoch 43/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0678 - acc: 0.9831\n",
      "Epoch 44/100\n",
      "1063/1063 [==============================] - 0s 68us/step - loss: 0.0663 - acc: 0.9831\n",
      "Epoch 45/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0656 - acc: 0.9831\n",
      "Epoch 46/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.0693 - acc: 0.9831\n",
      "Epoch 47/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0676 - acc: 0.9831\n",
      "Epoch 48/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0715 - acc: 0.9831\n",
      "Epoch 49/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0653 - acc: 0.9831\n",
      "Epoch 50/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0646 - acc: 0.9831\n",
      "Epoch 51/100\n",
      "1063/1063 [==============================] - 0s 79us/step - loss: 0.0649 - acc: 0.9831\n",
      "Epoch 52/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0661 - acc: 0.9831\n",
      "Epoch 53/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0675 - acc: 0.9831\n",
      "Epoch 54/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0652 - acc: 0.9831\n",
      "Epoch 55/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0673 - acc: 0.9831\n",
      "Epoch 56/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0631 - acc: 0.9831\n",
      "Epoch 57/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.0628 - acc: 0.9831\n",
      "Epoch 58/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0652 - acc: 0.9831\n",
      "Epoch 59/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.0640 - acc: 0.9831\n",
      "Epoch 60/100\n",
      "1063/1063 [==============================] - 0s 81us/step - loss: 0.0633 - acc: 0.9831\n",
      "Epoch 61/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.0631 - acc: 0.9831\n",
      "Epoch 62/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0623 - acc: 0.9831\n",
      "Epoch 63/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0643 - acc: 0.9831\n",
      "Epoch 64/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0621 - acc: 0.9831\n",
      "Epoch 65/100\n",
      "1063/1063 [==============================] - 0s 76us/step - loss: 0.0633 - acc: 0.9831\n",
      "Epoch 66/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0624 - acc: 0.9831\n",
      "Epoch 67/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.0620 - acc: 0.9831\n",
      "Epoch 68/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.0620 - acc: 0.9831\n",
      "Epoch 69/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0619 - acc: 0.9831\n",
      "Epoch 70/100\n",
      "1063/1063 [==============================] - 0s 68us/step - loss: 0.0619 - acc: 0.9831\n",
      "Epoch 71/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0622 - acc: 0.9831\n",
      "Epoch 72/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0617 - acc: 0.9831\n",
      "Epoch 73/100\n",
      "1063/1063 [==============================] - 0s 70us/step - loss: 0.0613 - acc: 0.9831\n",
      "Epoch 74/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0624 - acc: 0.9831\n",
      "Epoch 75/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0616 - acc: 0.9831\n",
      "Epoch 76/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0614 - acc: 0.9831\n",
      "Epoch 77/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.0627 - acc: 0.9831\n",
      "Epoch 78/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0619 - acc: 0.9831\n",
      "Epoch 79/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.0612 - acc: 0.9831\n",
      "Epoch 80/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0608 - acc: 0.9831\n",
      "Epoch 81/100\n",
      "1063/1063 [==============================] - 0s 66us/step - loss: 0.0617 - acc: 0.9831\n",
      "Epoch 82/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.0657 - acc: 0.9831\n",
      "Epoch 83/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.0608 - acc: 0.9831\n",
      "Epoch 84/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.0608 - acc: 0.9831\n",
      "Epoch 85/100\n",
      "1063/1063 [==============================] - 0s 67us/step - loss: 0.0602 - acc: 0.9831\n",
      "Epoch 86/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0630 - acc: 0.9831\n",
      "Epoch 87/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.0615 - acc: 0.9831\n",
      "Epoch 88/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0596 - acc: 0.9831\n",
      "Epoch 89/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0605 - acc: 0.9831\n",
      "Epoch 90/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0612 - acc: 0.9831\n",
      "Epoch 91/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.0608 - acc: 0.9831\n",
      "Epoch 92/100\n",
      "1063/1063 [==============================] - 0s 59us/step - loss: 0.0602 - acc: 0.9831\n",
      "Epoch 93/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0610 - acc: 0.9831\n",
      "Epoch 94/100\n",
      "1063/1063 [==============================] - 0s 78us/step - loss: 0.0599 - acc: 0.9831\n",
      "Epoch 95/100\n",
      "1063/1063 [==============================] - 0s 77us/step - loss: 0.0610 - acc: 0.9831\n",
      "Epoch 96/100\n",
      "1063/1063 [==============================] - 0s 68us/step - loss: 0.0598 - acc: 0.9831\n",
      "Epoch 97/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.0608 - acc: 0.9831\n",
      "Epoch 98/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0596 - acc: 0.9831\n",
      "Epoch 99/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0603 - acc: 0.9831\n",
      "Epoch 100/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.0595 - acc: 0.9831\n",
      "118/118 [==============================] - 0s 1ms/step\n",
      "Epoch 1/100\n",
      "1063/1063 [==============================] - 1s 524us/step - loss: 0.6605 - acc: 0.9840\n",
      "Epoch 2/100\n",
      "1063/1063 [==============================] - 0s 70us/step - loss: 0.2723 - acc: 0.9840\n",
      "Epoch 3/100\n",
      "1063/1063 [==============================] - 0s 78us/step - loss: 0.0895 - acc: 0.9840\n",
      "Epoch 4/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0844 - acc: 0.9840\n",
      "Epoch 5/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.0835 - acc: 0.9840\n",
      "Epoch 6/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.0834 - acc: 0.9840\n",
      "Epoch 7/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0836 - acc: 0.9840\n",
      "Epoch 8/100\n",
      "1063/1063 [==============================] - 0s 77us/step - loss: 0.0837 - acc: 0.9840\n",
      "Epoch 9/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0822 - acc: 0.9840\n",
      "Epoch 10/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0823 - acc: 0.9840\n",
      "Epoch 11/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0817 - acc: 0.9840\n",
      "Epoch 12/100\n",
      "1063/1063 [==============================] - 0s 77us/step - loss: 0.0812 - acc: 0.9840\n",
      "Epoch 13/100\n",
      "1063/1063 [==============================] - 0s 68us/step - loss: 0.0816 - acc: 0.9840\n",
      "Epoch 14/100\n",
      "1063/1063 [==============================] - 0s 68us/step - loss: 0.0813 - acc: 0.9840\n",
      "Epoch 15/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.0807 - acc: 0.9840\n",
      "Epoch 16/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0808 - acc: 0.9840\n",
      "Epoch 17/100\n",
      "1063/1063 [==============================] - 0s 67us/step - loss: 0.0802 - acc: 0.9840\n",
      "Epoch 18/100\n",
      "1063/1063 [==============================] - 0s 62us/step - loss: 0.0797 - acc: 0.9840\n",
      "Epoch 19/100\n",
      "1063/1063 [==============================] - 0s 61us/step - loss: 0.0787 - acc: 0.9840\n",
      "Epoch 20/100\n",
      "1063/1063 [==============================] - 0s 60us/step - loss: 0.0790 - acc: 0.9840\n",
      "Epoch 21/100\n",
      "1063/1063 [==============================] - 0s 64us/step - loss: 0.0777 - acc: 0.9840\n",
      "Epoch 22/100\n",
      "1063/1063 [==============================] - 0s 58us/step - loss: 0.0784 - acc: 0.9840\n",
      "Epoch 23/100\n",
      "1063/1063 [==============================] - 0s 47us/step - loss: 0.0772 - acc: 0.9840\n",
      "Epoch 24/100\n",
      "1063/1063 [==============================] - 0s 57us/step - loss: 0.0769 - acc: 0.9840\n",
      "Epoch 25/100\n",
      "1063/1063 [==============================] - 0s 58us/step - loss: 0.0755 - acc: 0.9840\n",
      "Epoch 26/100\n",
      "1063/1063 [==============================] - 0s 64us/step - loss: 0.0751 - acc: 0.9840\n",
      "Epoch 27/100\n",
      "1063/1063 [==============================] - 0s 61us/step - loss: 0.0751 - acc: 0.9840\n",
      "Epoch 28/100\n",
      "1063/1063 [==============================] - 0s 53us/step - loss: 0.0747 - acc: 0.9840\n",
      "Epoch 29/100\n",
      "1063/1063 [==============================] - 0s 60us/step - loss: 0.0750 - acc: 0.9840\n",
      "Epoch 30/100\n",
      "1063/1063 [==============================] - 0s 55us/step - loss: 0.0753 - acc: 0.9840\n",
      "Epoch 31/100\n",
      "1063/1063 [==============================] - 0s 59us/step - loss: 0.0726 - acc: 0.9840\n",
      "Epoch 32/100\n",
      "1063/1063 [==============================] - 0s 51us/step - loss: 0.0727 - acc: 0.9840\n",
      "Epoch 33/100\n",
      "1063/1063 [==============================] - 0s 56us/step - loss: 0.0724 - acc: 0.9840\n",
      "Epoch 34/100\n",
      "1063/1063 [==============================] - 0s 59us/step - loss: 0.0705 - acc: 0.9840\n",
      "Epoch 35/100\n",
      "1063/1063 [==============================] - 0s 65us/step - loss: 0.0709 - acc: 0.9840\n",
      "Epoch 36/100\n",
      "1063/1063 [==============================] - 0s 65us/step - loss: 0.0698 - acc: 0.9840\n",
      "Epoch 37/100\n",
      "1063/1063 [==============================] - 0s 64us/step - loss: 0.0696 - acc: 0.9840\n",
      "Epoch 38/100\n",
      "1063/1063 [==============================] - 0s 68us/step - loss: 0.0701 - acc: 0.9840\n",
      "Epoch 39/100\n",
      "1063/1063 [==============================] - 0s 65us/step - loss: 0.0686 - acc: 0.9840\n",
      "Epoch 40/100\n",
      "1063/1063 [==============================] - 0s 56us/step - loss: 0.0707 - acc: 0.9840\n",
      "Epoch 41/100\n",
      "1063/1063 [==============================] - 0s 49us/step - loss: 0.0674 - acc: 0.9840\n",
      "Epoch 42/100\n",
      "1063/1063 [==============================] - 0s 58us/step - loss: 0.0663 - acc: 0.9840\n",
      "Epoch 43/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0664 - acc: 0.9840\n",
      "Epoch 44/100\n",
      "1063/1063 [==============================] - 0s 61us/step - loss: 0.0680 - acc: 0.9840\n",
      "Epoch 45/100\n",
      "1063/1063 [==============================] - 0s 63us/step - loss: 0.0663 - acc: 0.9840\n",
      "Epoch 46/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0650 - acc: 0.9840\n",
      "Epoch 47/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.0651 - acc: 0.9840\n",
      "Epoch 48/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0646 - acc: 0.9840\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1063/1063 [==============================] - 0s 61us/step - loss: 0.0641 - acc: 0.9840\n",
      "Epoch 50/100\n",
      "1063/1063 [==============================] - 0s 60us/step - loss: 0.0643 - acc: 0.9840\n",
      "Epoch 51/100\n",
      "1063/1063 [==============================] - 0s 51us/step - loss: 0.0648 - acc: 0.9840\n",
      "Epoch 52/100\n",
      "1063/1063 [==============================] - 0s 60us/step - loss: 0.0648 - acc: 0.9840\n",
      "Epoch 53/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.0652 - acc: 0.9840\n",
      "Epoch 54/100\n",
      "1063/1063 [==============================] - 0s 66us/step - loss: 0.0627 - acc: 0.9840\n",
      "Epoch 55/100\n",
      "1063/1063 [==============================] - 0s 58us/step - loss: 0.0625 - acc: 0.9840\n",
      "Epoch 56/100\n",
      "1063/1063 [==============================] - 0s 54us/step - loss: 0.0636 - acc: 0.9840\n",
      "Epoch 57/100\n",
      "1063/1063 [==============================] - 0s 53us/step - loss: 0.0622 - acc: 0.9840\n",
      "Epoch 58/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.0635 - acc: 0.9840\n",
      "Epoch 59/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.0617 - acc: 0.9840\n",
      "Epoch 60/100\n",
      "1063/1063 [==============================] - 0s 64us/step - loss: 0.0620 - acc: 0.9840\n",
      "Epoch 61/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0618 - acc: 0.9840\n",
      "Epoch 62/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.0615 - acc: 0.9840\n",
      "Epoch 63/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.0617 - acc: 0.9840\n",
      "Epoch 64/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.0617 - acc: 0.9840\n",
      "Epoch 65/100\n",
      "1063/1063 [==============================] - 0s 78us/step - loss: 0.0623 - acc: 0.9840\n",
      "Epoch 66/100\n",
      "1063/1063 [==============================] - 0s 61us/step - loss: 0.0621 - acc: 0.9840\n",
      "Epoch 67/100\n",
      "1063/1063 [==============================] - 0s 63us/step - loss: 0.0602 - acc: 0.9840\n",
      "Epoch 68/100\n",
      "1063/1063 [==============================] - 0s 56us/step - loss: 0.0612 - acc: 0.9840\n",
      "Epoch 69/100\n",
      "1063/1063 [==============================] - 0s 57us/step - loss: 0.0611 - acc: 0.9840\n",
      "Epoch 70/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.0601 - acc: 0.9840\n",
      "Epoch 71/100\n",
      "1063/1063 [==============================] - 0s 76us/step - loss: 0.0625 - acc: 0.9840\n",
      "Epoch 72/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.0592 - acc: 0.9840\n",
      "Epoch 73/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.0590 - acc: 0.9840\n",
      "Epoch 74/100\n",
      "1063/1063 [==============================] - 0s 67us/step - loss: 0.0587 - acc: 0.9840\n",
      "Epoch 75/100\n",
      "1063/1063 [==============================] - 0s 50us/step - loss: 0.0600 - acc: 0.9840\n",
      "Epoch 76/100\n",
      "1063/1063 [==============================] - 0s 66us/step - loss: 0.0593 - acc: 0.9840\n",
      "Epoch 77/100\n",
      "1063/1063 [==============================] - 0s 55us/step - loss: 0.0627 - acc: 0.9840\n",
      "Epoch 78/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.0586 - acc: 0.9840\n",
      "Epoch 79/100\n",
      "1063/1063 [==============================] - 0s 68us/step - loss: 0.0585 - acc: 0.9840\n",
      "Epoch 80/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.0576 - acc: 0.9840\n",
      "Epoch 81/100\n",
      "1063/1063 [==============================] - 0s 64us/step - loss: 0.0591 - acc: 0.9840\n",
      "Epoch 82/100\n",
      "1063/1063 [==============================] - 0s 66us/step - loss: 0.0575 - acc: 0.9840\n",
      "Epoch 83/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.0583 - acc: 0.9840\n",
      "Epoch 84/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0581 - acc: 0.9840\n",
      "Epoch 85/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.0605 - acc: 0.9840\n",
      "Epoch 86/100\n",
      "1063/1063 [==============================] - 0s 70us/step - loss: 0.0567 - acc: 0.9840\n",
      "Epoch 87/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.0571 - acc: 0.9840\n",
      "Epoch 88/100\n",
      "1063/1063 [==============================] - 0s 77us/step - loss: 0.0572 - acc: 0.9840\n",
      "Epoch 89/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0569 - acc: 0.9840\n",
      "Epoch 90/100\n",
      "1063/1063 [==============================] - 0s 76us/step - loss: 0.0563 - acc: 0.9840\n",
      "Epoch 91/100\n",
      "1063/1063 [==============================] - 0s 67us/step - loss: 0.0555 - acc: 0.9840\n",
      "Epoch 92/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.0570 - acc: 0.9840\n",
      "Epoch 93/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0569 - acc: 0.9840\n",
      "Epoch 94/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0559 - acc: 0.9840\n",
      "Epoch 95/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0544 - acc: 0.9840\n",
      "Epoch 96/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0549 - acc: 0.9840\n",
      "Epoch 97/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0545 - acc: 0.9840\n",
      "Epoch 98/100\n",
      "1063/1063 [==============================] - 0s 76us/step - loss: 0.0555 - acc: 0.9840\n",
      "Epoch 99/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.0543 - acc: 0.9840\n",
      "Epoch 100/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0550 - acc: 0.9840\n",
      "118/118 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "1063/1063 [==============================] - 1s 639us/step - loss: 0.6842 - acc: 0.9200\n",
      "Epoch 2/100\n",
      "1063/1063 [==============================] - 0s 60us/step - loss: 0.5323 - acc: 0.9812\n",
      "Epoch 3/100\n",
      "1063/1063 [==============================] - 0s 67us/step - loss: 0.1225 - acc: 0.9812\n",
      "Epoch 4/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0964 - acc: 0.9812\n",
      "Epoch 5/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.0954 - acc: 0.9812\n",
      "Epoch 6/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0941 - acc: 0.9812\n",
      "Epoch 7/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0944 - acc: 0.9812\n",
      "Epoch 8/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0934 - acc: 0.9812\n",
      "Epoch 9/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0927 - acc: 0.9812\n",
      "Epoch 10/100\n",
      "1063/1063 [==============================] - 0s 70us/step - loss: 0.0934 - acc: 0.9812\n",
      "Epoch 11/100\n",
      "1063/1063 [==============================] - 0s 76us/step - loss: 0.0916 - acc: 0.9812\n",
      "Epoch 12/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0924 - acc: 0.9812\n",
      "Epoch 13/100\n",
      "1063/1063 [==============================] - 0s 66us/step - loss: 0.0899 - acc: 0.9812\n",
      "Epoch 14/100\n",
      "1063/1063 [==============================] - 0s 67us/step - loss: 0.0903 - acc: 0.9812\n",
      "Epoch 15/100\n",
      "1063/1063 [==============================] - 0s 76us/step - loss: 0.0890 - acc: 0.9812\n",
      "Epoch 16/100\n",
      "1063/1063 [==============================] - 0s 67us/step - loss: 0.0884 - acc: 0.9812\n",
      "Epoch 17/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.0883 - acc: 0.9812\n",
      "Epoch 18/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0871 - acc: 0.9812\n",
      "Epoch 19/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.0854 - acc: 0.9812\n",
      "Epoch 20/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.0850 - acc: 0.9812\n",
      "Epoch 21/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0841 - acc: 0.9812\n",
      "Epoch 22/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.0842 - acc: 0.9812\n",
      "Epoch 23/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0818 - acc: 0.9812\n",
      "Epoch 24/100\n",
      "1063/1063 [==============================] - 0s 62us/step - loss: 0.0822 - acc: 0.9812\n",
      "Epoch 25/100\n",
      "1063/1063 [==============================] - 0s 59us/step - loss: 0.0823 - acc: 0.9812\n",
      "Epoch 26/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0784 - acc: 0.9812\n",
      "Epoch 27/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.0792 - acc: 0.9812\n",
      "Epoch 28/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.0770 - acc: 0.9812\n",
      "Epoch 29/100\n",
      "1063/1063 [==============================] - 0s 76us/step - loss: 0.0757 - acc: 0.9812\n",
      "Epoch 30/100\n",
      "1063/1063 [==============================] - 0s 77us/step - loss: 0.0757 - acc: 0.9812\n",
      "Epoch 31/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0757 - acc: 0.9812\n",
      "Epoch 32/100\n",
      "1063/1063 [==============================] - 0s 77us/step - loss: 0.0739 - acc: 0.9812\n",
      "Epoch 33/100\n",
      "1063/1063 [==============================] - 0s 76us/step - loss: 0.0732 - acc: 0.9812\n",
      "Epoch 34/100\n",
      "1063/1063 [==============================] - 0s 78us/step - loss: 0.0733 - acc: 0.9812\n",
      "Epoch 35/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0734 - acc: 0.9812\n",
      "Epoch 36/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0715 - acc: 0.9812\n",
      "Epoch 37/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.0707 - acc: 0.9812\n",
      "Epoch 38/100\n",
      "1063/1063 [==============================] - 0s 77us/step - loss: 0.0706 - acc: 0.9812\n",
      "Epoch 39/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0700 - acc: 0.9812\n",
      "Epoch 40/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0707 - acc: 0.9812\n",
      "Epoch 41/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.0726 - acc: 0.9812\n",
      "Epoch 42/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0704 - acc: 0.9812\n",
      "Epoch 43/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.0710 - acc: 0.9812\n",
      "Epoch 44/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.0700 - acc: 0.9812\n",
      "Epoch 45/100\n",
      "1063/1063 [==============================] - 0s 67us/step - loss: 0.0692 - acc: 0.9812\n",
      "Epoch 46/100\n",
      "1063/1063 [==============================] - 0s 84us/step - loss: 0.0685 - acc: 0.9812\n",
      "Epoch 47/100\n",
      "1063/1063 [==============================] - 0s 78us/step - loss: 0.0686 - acc: 0.9812\n",
      "Epoch 48/100\n",
      "1063/1063 [==============================] - 0s 76us/step - loss: 0.0698 - acc: 0.9812\n",
      "Epoch 49/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0682 - acc: 0.9812\n",
      "Epoch 50/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0676 - acc: 0.9812\n",
      "Epoch 51/100\n",
      "1063/1063 [==============================] - 0s 76us/step - loss: 0.0706 - acc: 0.9812\n",
      "Epoch 52/100\n",
      "1063/1063 [==============================] - 0s 76us/step - loss: 0.0681 - acc: 0.9812\n",
      "Epoch 53/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0670 - acc: 0.9812\n",
      "Epoch 54/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0672 - acc: 0.9812\n",
      "Epoch 55/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0681 - acc: 0.9812\n",
      "Epoch 56/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0666 - acc: 0.9812\n",
      "Epoch 57/100\n",
      "1063/1063 [==============================] - 0s 67us/step - loss: 0.0662 - acc: 0.9812\n",
      "Epoch 58/100\n",
      "1063/1063 [==============================] - 0s 64us/step - loss: 0.0672 - acc: 0.9812\n",
      "Epoch 59/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0673 - acc: 0.9812\n",
      "Epoch 60/100\n",
      "1063/1063 [==============================] - 0s 70us/step - loss: 0.0678 - acc: 0.9812\n",
      "Epoch 61/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0657 - acc: 0.9812\n",
      "Epoch 62/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0701 - acc: 0.9812\n",
      "Epoch 63/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.0649 - acc: 0.9812\n",
      "Epoch 64/100\n",
      "1063/1063 [==============================] - 0s 67us/step - loss: 0.0648 - acc: 0.9812\n",
      "Epoch 65/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0681 - acc: 0.9812\n",
      "Epoch 66/100\n",
      "1063/1063 [==============================] - 0s 79us/step - loss: 0.0658 - acc: 0.9812\n",
      "Epoch 67/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.0661 - acc: 0.9812\n",
      "Epoch 68/100\n",
      "1063/1063 [==============================] - 0s 76us/step - loss: 0.0649 - acc: 0.9812\n",
      "Epoch 69/100\n",
      "1063/1063 [==============================] - 0s 76us/step - loss: 0.0652 - acc: 0.9812\n",
      "Epoch 70/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0641 - acc: 0.9812\n",
      "Epoch 71/100\n",
      "1063/1063 [==============================] - 0s 76us/step - loss: 0.0652 - acc: 0.9812\n",
      "Epoch 72/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.0643 - acc: 0.9812\n",
      "Epoch 73/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0656 - acc: 0.9812\n",
      "Epoch 74/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0638 - acc: 0.9812\n",
      "Epoch 75/100\n",
      "1063/1063 [==============================] - 0s 76us/step - loss: 0.0663 - acc: 0.9812\n",
      "Epoch 76/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0651 - acc: 0.9812\n",
      "Epoch 77/100\n",
      "1063/1063 [==============================] - 0s 68us/step - loss: 0.0640 - acc: 0.9812\n",
      "Epoch 78/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0644 - acc: 0.9812\n",
      "Epoch 79/100\n",
      "1063/1063 [==============================] - 0s 49us/step - loss: 0.0645 - acc: 0.9812\n",
      "Epoch 80/100\n",
      "1063/1063 [==============================] - 0s 60us/step - loss: 0.0629 - acc: 0.9812\n",
      "Epoch 81/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0639 - acc: 0.9812\n",
      "Epoch 82/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0637 - acc: 0.9812\n",
      "Epoch 83/100\n",
      "1063/1063 [==============================] - 0s 60us/step - loss: 0.0634 - acc: 0.9812\n",
      "Epoch 84/100\n",
      "1063/1063 [==============================] - 0s 66us/step - loss: 0.0642 - acc: 0.9812\n",
      "Epoch 85/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0633 - acc: 0.9812\n",
      "Epoch 86/100\n",
      "1063/1063 [==============================] - 0s 68us/step - loss: 0.0640 - acc: 0.9812\n",
      "Epoch 87/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.0640 - acc: 0.9812\n",
      "Epoch 88/100\n",
      "1063/1063 [==============================] - 0s 64us/step - loss: 0.0664 - acc: 0.9812\n",
      "Epoch 89/100\n",
      "1063/1063 [==============================] - 0s 62us/step - loss: 0.0622 - acc: 0.9812\n",
      "Epoch 90/100\n",
      "1063/1063 [==============================] - 0s 67us/step - loss: 0.0621 - acc: 0.9812\n",
      "Epoch 91/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.0627 - acc: 0.9812\n",
      "Epoch 92/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0635 - acc: 0.9812\n",
      "Epoch 93/100\n",
      "1063/1063 [==============================] - 0s 64us/step - loss: 0.0634 - acc: 0.9812\n",
      "Epoch 94/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.0622 - acc: 0.9812\n",
      "Epoch 95/100\n",
      "1063/1063 [==============================] - 0s 68us/step - loss: 0.0628 - acc: 0.9812\n",
      "Epoch 96/100\n",
      "1063/1063 [==============================] - 0s 76us/step - loss: 0.0627 - acc: 0.9812\n",
      "Epoch 97/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0627 - acc: 0.9812\n",
      "Epoch 98/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0639 - acc: 0.9812\n",
      "Epoch 99/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0625 - acc: 0.9812\n",
      "Epoch 100/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0628 - acc: 0.9812\n",
      "118/118 [==============================] - 0s 1ms/step\n",
      "Epoch 1/100\n",
      "1063/1063 [==============================] - 1s 667us/step - loss: 0.6844 - acc: 0.9558\n",
      "Epoch 2/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.5249 - acc: 0.9859\n",
      "Epoch 3/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.0975 - acc: 0.9859\n",
      "Epoch 4/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0776 - acc: 0.9859\n",
      "Epoch 5/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0756 - acc: 0.9859\n",
      "Epoch 6/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0759 - acc: 0.9859\n",
      "Epoch 7/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0768 - acc: 0.9859\n",
      "Epoch 8/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0746 - acc: 0.9859\n",
      "Epoch 9/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.0740 - acc: 0.9859\n",
      "Epoch 10/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.0738 - acc: 0.9859\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0734 - acc: 0.9859\n",
      "Epoch 12/100\n",
      "1063/1063 [==============================] - 0s 68us/step - loss: 0.0727 - acc: 0.9859\n",
      "Epoch 13/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0728 - acc: 0.9859\n",
      "Epoch 14/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0727 - acc: 0.9859\n",
      "Epoch 15/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.0727 - acc: 0.9859\n",
      "Epoch 16/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.0714 - acc: 0.9859\n",
      "Epoch 17/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.0716 - acc: 0.9859\n",
      "Epoch 18/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.0705 - acc: 0.9859\n",
      "Epoch 19/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.0709 - acc: 0.9859\n",
      "Epoch 20/100\n",
      "1063/1063 [==============================] - 0s 68us/step - loss: 0.0698 - acc: 0.9859\n",
      "Epoch 21/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0695 - acc: 0.9859\n",
      "Epoch 22/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0699 - acc: 0.9859\n",
      "Epoch 23/100\n",
      "1063/1063 [==============================] - 0s 76us/step - loss: 0.0683 - acc: 0.9859\n",
      "Epoch 24/100\n",
      "1063/1063 [==============================] - 0s 77us/step - loss: 0.0687 - acc: 0.9859\n",
      "Epoch 25/100\n",
      "1063/1063 [==============================] - 0s 76us/step - loss: 0.0681 - acc: 0.9859\n",
      "Epoch 26/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.0675 - acc: 0.9859\n",
      "Epoch 27/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0664 - acc: 0.9859\n",
      "Epoch 28/100\n",
      "1063/1063 [==============================] - 0s 77us/step - loss: 0.0670 - acc: 0.9859\n",
      "Epoch 29/100\n",
      "1063/1063 [==============================] - 0s 76us/step - loss: 0.0663 - acc: 0.9859\n",
      "Epoch 30/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0646 - acc: 0.9859\n",
      "Epoch 31/100\n",
      "1063/1063 [==============================] - 0s 76us/step - loss: 0.0638 - acc: 0.9859\n",
      "Epoch 32/100\n",
      "1063/1063 [==============================] - 0s 76us/step - loss: 0.0631 - acc: 0.9859\n",
      "Epoch 33/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.0624 - acc: 0.9859\n",
      "Epoch 34/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.0619 - acc: 0.9859\n",
      "Epoch 35/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.0609 - acc: 0.9859\n",
      "Epoch 36/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.0598 - acc: 0.9859\n",
      "Epoch 37/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0592 - acc: 0.9859\n",
      "Epoch 38/100\n",
      "1063/1063 [==============================] - 0s 81us/step - loss: 0.0585 - acc: 0.9859\n",
      "Epoch 39/100\n",
      "1063/1063 [==============================] - 0s 79us/step - loss: 0.0580 - acc: 0.9859\n",
      "Epoch 40/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.0587 - acc: 0.9859\n",
      "Epoch 41/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.0575 - acc: 0.9859\n",
      "Epoch 42/100\n",
      "1063/1063 [==============================] - 0s 77us/step - loss: 0.0568 - acc: 0.9859\n",
      "Epoch 43/100\n",
      "1063/1063 [==============================] - 0s 79us/step - loss: 0.0546 - acc: 0.9859\n",
      "Epoch 44/100\n",
      "1063/1063 [==============================] - 0s 78us/step - loss: 0.0566 - acc: 0.9859\n",
      "Epoch 45/100\n",
      "1063/1063 [==============================] - 0s 76us/step - loss: 0.0555 - acc: 0.9859\n",
      "Epoch 46/100\n",
      "1063/1063 [==============================] - 0s 78us/step - loss: 0.0571 - acc: 0.9859\n",
      "Epoch 47/100\n",
      "1063/1063 [==============================] - 0s 78us/step - loss: 0.0540 - acc: 0.9859\n",
      "Epoch 48/100\n",
      "1063/1063 [==============================] - 0s 77us/step - loss: 0.0537 - acc: 0.9859\n",
      "Epoch 49/100\n",
      "1063/1063 [==============================] - 0s 76us/step - loss: 0.0533 - acc: 0.9859\n",
      "Epoch 50/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.0525 - acc: 0.9859\n",
      "Epoch 51/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0520 - acc: 0.9859\n",
      "Epoch 52/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0529 - acc: 0.9859\n",
      "Epoch 53/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0532 - acc: 0.9859\n",
      "Epoch 54/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0530 - acc: 0.9859\n",
      "Epoch 55/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0519 - acc: 0.9859\n",
      "Epoch 56/100\n",
      "1063/1063 [==============================] - 0s 79us/step - loss: 0.0515 - acc: 0.9859\n",
      "Epoch 57/100\n",
      "1063/1063 [==============================] - 0s 78us/step - loss: 0.0516 - acc: 0.9859\n",
      "Epoch 58/100\n",
      "1063/1063 [==============================] - 0s 76us/step - loss: 0.0516 - acc: 0.9859\n",
      "Epoch 59/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.0527 - acc: 0.9859\n",
      "Epoch 60/100\n",
      "1063/1063 [==============================] - 0s 78us/step - loss: 0.0508 - acc: 0.9859\n",
      "Epoch 61/100\n",
      "1063/1063 [==============================] - 0s 77us/step - loss: 0.0509 - acc: 0.9859\n",
      "Epoch 62/100\n",
      "1063/1063 [==============================] - 0s 82us/step - loss: 0.0496 - acc: 0.9859\n",
      "Epoch 63/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0508 - acc: 0.9859\n",
      "Epoch 64/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0505 - acc: 0.9859\n",
      "Epoch 65/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.0489 - acc: 0.9859\n",
      "Epoch 66/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0492 - acc: 0.9859\n",
      "Epoch 67/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.0487 - acc: 0.9859\n",
      "Epoch 68/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.0490 - acc: 0.9859\n",
      "Epoch 69/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.0491 - acc: 0.9859\n",
      "Epoch 70/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0484 - acc: 0.9859\n",
      "Epoch 71/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0480 - acc: 0.9859\n",
      "Epoch 72/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.0476 - acc: 0.9859\n",
      "Epoch 73/100\n",
      "1063/1063 [==============================] - 0s 69us/step - loss: 0.0471 - acc: 0.9859\n",
      "Epoch 74/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0481 - acc: 0.9859\n",
      "Epoch 75/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0471 - acc: 0.9859\n",
      "Epoch 76/100\n",
      "1063/1063 [==============================] - 0s 70us/step - loss: 0.0477 - acc: 0.9859\n",
      "Epoch 77/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0469 - acc: 0.9859\n",
      "Epoch 78/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.0497 - acc: 0.9859\n",
      "Epoch 79/100\n",
      "1063/1063 [==============================] - 0s 67us/step - loss: 0.0466 - acc: 0.9859\n",
      "Epoch 80/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0485 - acc: 0.9859\n",
      "Epoch 81/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.0460 - acc: 0.9859\n",
      "Epoch 82/100\n",
      "1063/1063 [==============================] - 0s 70us/step - loss: 0.0464 - acc: 0.9859\n",
      "Epoch 83/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0462 - acc: 0.9859\n",
      "Epoch 84/100\n",
      "1063/1063 [==============================] - 0s 76us/step - loss: 0.0470 - acc: 0.9859\n",
      "Epoch 85/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0460 - acc: 0.9859\n",
      "Epoch 86/100\n",
      "1063/1063 [==============================] - 0s 79us/step - loss: 0.0461 - acc: 0.9859\n",
      "Epoch 87/100\n",
      "1063/1063 [==============================] - 0s 77us/step - loss: 0.0454 - acc: 0.9859\n",
      "Epoch 88/100\n",
      "1063/1063 [==============================] - 0s 77us/step - loss: 0.0451 - acc: 0.9859\n",
      "Epoch 89/100\n",
      "1063/1063 [==============================] - 0s 77us/step - loss: 0.0457 - acc: 0.9859\n",
      "Epoch 90/100\n",
      "1063/1063 [==============================] - 0s 77us/step - loss: 0.0456 - acc: 0.9859\n",
      "Epoch 91/100\n",
      "1063/1063 [==============================] - 0s 76us/step - loss: 0.0452 - acc: 0.9859\n",
      "Epoch 92/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.0448 - acc: 0.9859\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.0447 - acc: 0.9859\n",
      "Epoch 94/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.0449 - acc: 0.9859\n",
      "Epoch 95/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.0442 - acc: 0.9859\n",
      "Epoch 96/100\n",
      "1063/1063 [==============================] - 0s 78us/step - loss: 0.0448 - acc: 0.9859\n",
      "Epoch 97/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.0443 - acc: 0.9859\n",
      "Epoch 98/100\n",
      "1063/1063 [==============================] - 0s 65us/step - loss: 0.0514 - acc: 0.9859\n",
      "Epoch 99/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.0478 - acc: 0.9859\n",
      "Epoch 100/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.0446 - acc: 0.9859\n",
      "118/118 [==============================] - 0s 1ms/step\n",
      "Epoch 1/100\n",
      "1063/1063 [==============================] - 1s 714us/step - loss: 0.6855 - acc: 0.9520\n",
      "Epoch 2/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.6695 - acc: 0.9821\n",
      "Epoch 3/100\n",
      "1063/1063 [==============================] - 0s 78us/step - loss: 0.6538 - acc: 0.9821\n",
      "Epoch 4/100\n",
      "1063/1063 [==============================] - 0s 77us/step - loss: 0.6387 - acc: 0.9821\n",
      "Epoch 5/100\n",
      "1063/1063 [==============================] - 0s 78us/step - loss: 0.6238 - acc: 0.9821\n",
      "Epoch 6/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.6095 - acc: 0.9821\n",
      "Epoch 7/100\n",
      "1063/1063 [==============================] - 0s 79us/step - loss: 0.5954 - acc: 0.9821\n",
      "Epoch 8/100\n",
      "1063/1063 [==============================] - 0s 76us/step - loss: 0.5818 - acc: 0.9821\n",
      "Epoch 9/100\n",
      "1063/1063 [==============================] - 0s 76us/step - loss: 0.5686 - acc: 0.9821\n",
      "Epoch 10/100\n",
      "1063/1063 [==============================] - 0s 67us/step - loss: 0.5557 - acc: 0.9821\n",
      "Epoch 11/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.5432 - acc: 0.9821\n",
      "Epoch 12/100\n",
      "1063/1063 [==============================] - 0s 70us/step - loss: 0.5310 - acc: 0.9821\n",
      "Epoch 13/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.5192 - acc: 0.9821\n",
      "Epoch 14/100\n",
      "1063/1063 [==============================] - 0s 76us/step - loss: 0.5077 - acc: 0.9821\n",
      "Epoch 15/100\n",
      "1063/1063 [==============================] - 0s 76us/step - loss: 0.4966 - acc: 0.9821\n",
      "Epoch 16/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.4858 - acc: 0.9821\n",
      "Epoch 17/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.4752 - acc: 0.9821\n",
      "Epoch 18/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.4649 - acc: 0.9821\n",
      "Epoch 19/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.4549 - acc: 0.9821\n",
      "Epoch 20/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.4452 - acc: 0.9821\n",
      "Epoch 21/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.4358 - acc: 0.9821\n",
      "Epoch 22/100\n",
      "1063/1063 [==============================] - 0s 84us/step - loss: 0.4266 - acc: 0.9821\n",
      "Epoch 23/100\n",
      "1063/1063 [==============================] - 0s 77us/step - loss: 0.4177 - acc: 0.9821\n",
      "Epoch 24/100\n",
      "1063/1063 [==============================] - 0s 77us/step - loss: 0.4090 - acc: 0.9821\n",
      "Epoch 25/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.4006 - acc: 0.9821\n",
      "Epoch 26/100\n",
      "1063/1063 [==============================] - 0s 76us/step - loss: 0.3925 - acc: 0.9821\n",
      "Epoch 27/100\n",
      "1063/1063 [==============================] - 0s 79us/step - loss: 0.3845 - acc: 0.9821\n",
      "Epoch 28/100\n",
      "1063/1063 [==============================] - 0s 83us/step - loss: 0.3768 - acc: 0.9821\n",
      "Epoch 29/100\n",
      "1063/1063 [==============================] - 0s 78us/step - loss: 0.3693 - acc: 0.9821\n",
      "Epoch 30/100\n",
      "1063/1063 [==============================] - 0s 77us/step - loss: 0.3620 - acc: 0.9821\n",
      "Epoch 31/100\n",
      "1063/1063 [==============================] - 0s 76us/step - loss: 0.3549 - acc: 0.9821\n",
      "Epoch 32/100\n",
      "1063/1063 [==============================] - 0s 77us/step - loss: 0.3480 - acc: 0.9821\n",
      "Epoch 33/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.3413 - acc: 0.9821\n",
      "Epoch 34/100\n",
      "1063/1063 [==============================] - 0s 77us/step - loss: 0.3348 - acc: 0.9821\n",
      "Epoch 35/100\n",
      "1063/1063 [==============================] - 0s 77us/step - loss: 0.3284 - acc: 0.9821\n",
      "Epoch 36/100\n",
      "1063/1063 [==============================] - 0s 76us/step - loss: 0.3223 - acc: 0.9821\n",
      "Epoch 37/100\n",
      "1063/1063 [==============================] - 0s 76us/step - loss: 0.3163 - acc: 0.9821\n",
      "Epoch 38/100\n",
      "1063/1063 [==============================] - 0s 78us/step - loss: 0.3105 - acc: 0.9821\n",
      "Epoch 39/100\n",
      "1063/1063 [==============================] - 0s 83us/step - loss: 0.3048 - acc: 0.9821\n",
      "Epoch 40/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.2993 - acc: 0.9821\n",
      "Epoch 41/100\n",
      "1063/1063 [==============================] - 0s 77us/step - loss: 0.2940 - acc: 0.9821\n",
      "Epoch 42/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.2887 - acc: 0.9821\n",
      "Epoch 43/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.2837 - acc: 0.9821\n",
      "Epoch 44/100\n",
      "1063/1063 [==============================] - 0s 76us/step - loss: 0.2788 - acc: 0.9821\n",
      "Epoch 45/100\n",
      "1063/1063 [==============================] - 0s 76us/step - loss: 0.2740 - acc: 0.9821\n",
      "Epoch 46/100\n",
      "1063/1063 [==============================] - 0s 76us/step - loss: 0.2694 - acc: 0.9821\n",
      "Epoch 47/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.2649 - acc: 0.9821\n",
      "Epoch 48/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.2605 - acc: 0.9821\n",
      "Epoch 49/100\n",
      "1063/1063 [==============================] - 0s 78us/step - loss: 0.2562 - acc: 0.9821\n",
      "Epoch 50/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.2520 - acc: 0.9821\n",
      "Epoch 51/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.2479 - acc: 0.9821\n",
      "Epoch 52/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.2439 - acc: 0.9821\n",
      "Epoch 53/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.2400 - acc: 0.9821\n",
      "Epoch 54/100\n",
      "1063/1063 [==============================] - 0s 76us/step - loss: 0.2363 - acc: 0.9821\n",
      "Epoch 55/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.2326 - acc: 0.9821\n",
      "Epoch 56/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.2290 - acc: 0.9821\n",
      "Epoch 57/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.2256 - acc: 0.9821\n",
      "Epoch 58/100\n",
      "1063/1063 [==============================] - 0s 79us/step - loss: 0.2222 - acc: 0.9821\n",
      "Epoch 59/100\n",
      "1063/1063 [==============================] - 0s 78us/step - loss: 0.2189 - acc: 0.9821\n",
      "Epoch 60/100\n",
      "1063/1063 [==============================] - 0s 81us/step - loss: 0.2158 - acc: 0.9821\n",
      "Epoch 61/100\n",
      "1063/1063 [==============================] - 0s 76us/step - loss: 0.2126 - acc: 0.9821\n",
      "Epoch 62/100\n",
      "1063/1063 [==============================] - 0s 79us/step - loss: 0.2096 - acc: 0.9821\n",
      "Epoch 63/100\n",
      "1063/1063 [==============================] - 0s 76us/step - loss: 0.2066 - acc: 0.9821\n",
      "Epoch 64/100\n",
      "1063/1063 [==============================] - 0s 76us/step - loss: 0.2037 - acc: 0.9821\n",
      "Epoch 65/100\n",
      "1063/1063 [==============================] - 0s 78us/step - loss: 0.2009 - acc: 0.9821\n",
      "Epoch 66/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.1982 - acc: 0.9821\n",
      "Epoch 67/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.1955 - acc: 0.9821\n",
      "Epoch 68/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.1929 - acc: 0.9821\n",
      "Epoch 69/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.1903 - acc: 0.9821\n",
      "Epoch 70/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.1879 - acc: 0.9821\n",
      "Epoch 71/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.1854 - acc: 0.9821\n",
      "Epoch 72/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.1831 - acc: 0.9821\n",
      "Epoch 73/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.1808 - acc: 0.9821\n",
      "Epoch 74/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.1785 - acc: 0.9821\n",
      "Epoch 75/100\n",
      "1063/1063 [==============================] - 0s 76us/step - loss: 0.1763 - acc: 0.9821\n",
      "Epoch 76/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.1742 - acc: 0.9821\n",
      "Epoch 77/100\n",
      "1063/1063 [==============================] - 0s 70us/step - loss: 0.1721 - acc: 0.9821\n",
      "Epoch 78/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.1700 - acc: 0.9821\n",
      "Epoch 79/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.1681 - acc: 0.9821\n",
      "Epoch 80/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.1661 - acc: 0.9821\n",
      "Epoch 81/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.1642 - acc: 0.9821\n",
      "Epoch 82/100\n",
      "1063/1063 [==============================] - 0s 76us/step - loss: 0.1624 - acc: 0.9821\n",
      "Epoch 83/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.1606 - acc: 0.9821\n",
      "Epoch 84/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.1589 - acc: 0.9821\n",
      "Epoch 85/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.1572 - acc: 0.9821\n",
      "Epoch 86/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.1555 - acc: 0.9821\n",
      "Epoch 87/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.1538 - acc: 0.9821\n",
      "Epoch 88/100\n",
      "1063/1063 [==============================] - 0s 76us/step - loss: 0.1523 - acc: 0.9821\n",
      "Epoch 89/100\n",
      "1063/1063 [==============================] - 0s 78us/step - loss: 0.1508 - acc: 0.9821\n",
      "Epoch 90/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.1493 - acc: 0.9821\n",
      "Epoch 91/100\n",
      "1063/1063 [==============================] - 0s 72us/step - loss: 0.1478 - acc: 0.9821\n",
      "Epoch 92/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.1463 - acc: 0.9821\n",
      "Epoch 93/100\n",
      "1063/1063 [==============================] - 0s 75us/step - loss: 0.1449 - acc: 0.9821\n",
      "Epoch 94/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.1435 - acc: 0.9821\n",
      "Epoch 95/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.1422 - acc: 0.9821\n",
      "Epoch 96/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.1409 - acc: 0.9821\n",
      "Epoch 97/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.1396 - acc: 0.9821\n",
      "Epoch 98/100\n",
      "1063/1063 [==============================] - 0s 71us/step - loss: 0.1383 - acc: 0.9821\n",
      "Epoch 99/100\n",
      "1063/1063 [==============================] - 0s 73us/step - loss: 0.1371 - acc: 0.9821\n",
      "Epoch 100/100\n",
      "1063/1063 [==============================] - 0s 74us/step - loss: 0.1359 - acc: 0.9821\n",
      "118/118 [==============================] - 0s 2ms/step\n",
      "Accuracy mean: 0.983065089837\n",
      "Accuracy variance: 0.0107196711682\n",
      "(' Time ', '93.281', ' seconds')\n"
     ]
    }
   ],
   "source": [
    "# estimators \n",
    "# Evaluating the ANN\n",
    "t0 = time()  \n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential # initialize neural network library\n",
    "from keras.layers import Dense # build our layers library\n",
    "def build_classifier():\n",
    "    classifier = Sequential() # initialize neural network\n",
    "    classifier.add(Dense(units = 16, kernel_initializer = 'uniform', activation = 'relu', input_dim = X_train.shape[1]))\n",
    "    classifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 4, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "classifier = KerasClassifier(build_fn = build_classifier, epochs = 100)\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()\n",
    "print(\"Accuracy mean: \"+ str(mean))\n",
    "print(\"Accuracy variance: \"+ str(variance))\n",
    "tt = time() - t0  \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1062/1062 [==============================] - 1s 537us/step - loss: 0.3818 - acc: 0.9529\n",
      "Epoch 2/100\n",
      "1062/1062 [==============================] - 0s 179us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 3/100\n",
      "1062/1062 [==============================] - 0s 173us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 4/100\n",
      "1062/1062 [==============================] - 0s 203us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 5/100\n",
      "1062/1062 [==============================] - 0s 210us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 6/100\n",
      "1062/1062 [==============================] - 0s 209us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 7/100\n",
      "1062/1062 [==============================] - 0s 183us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 8/100\n",
      "1062/1062 [==============================] - 0s 208us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 9/100\n",
      "1062/1062 [==============================] - 0s 162us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 10/100\n",
      "1062/1062 [==============================] - 0s 212us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 11/100\n",
      "1062/1062 [==============================] - 0s 172us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 12/100\n",
      "1062/1062 [==============================] - 0s 174us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 13/100\n",
      "1062/1062 [==============================] - 0s 185us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 14/100\n",
      "1062/1062 [==============================] - 0s 171us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 15/100\n",
      "1062/1062 [==============================] - 0s 183us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 16/100\n",
      "1062/1062 [==============================] - 0s 178us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 17/100\n",
      "1062/1062 [==============================] - 0s 189us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 18/100\n",
      "1062/1062 [==============================] - 0s 197us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 19/100\n",
      "1062/1062 [==============================] - 0s 222us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 20/100\n",
      "1062/1062 [==============================] - 0s 198us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 21/100\n",
      "1062/1062 [==============================] - 0s 192us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 22/100\n",
      "1062/1062 [==============================] - 0s 206us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 23/100\n",
      "1062/1062 [==============================] - 0s 184us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 24/100\n",
      "1062/1062 [==============================] - 0s 178us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 25/100\n",
      "1062/1062 [==============================] - 0s 161us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 26/100\n",
      "1062/1062 [==============================] - 0s 179us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 27/100\n",
      "1062/1062 [==============================] - 0s 228us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 28/100\n",
      "1062/1062 [==============================] - 0s 202us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 29/100\n",
      "1062/1062 [==============================] - 0s 216us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 30/100\n",
      "1062/1062 [==============================] - 0s 176us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 31/100\n",
      "1062/1062 [==============================] - 0s 219us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 32/100\n",
      "1062/1062 [==============================] - 0s 187us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 33/100\n",
      "1062/1062 [==============================] - 3s 2ms/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 34/100\n",
      "1062/1062 [==============================] - 1s 675us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 35/100\n",
      "1062/1062 [==============================] - 0s 404us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 36/100\n",
      "1062/1062 [==============================] - 0s 274us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 37/100\n",
      "1062/1062 [==============================] - 0s 274us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 38/100\n",
      "1062/1062 [==============================] - 0s 229us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 39/100\n",
      "1062/1062 [==============================] - 0s 229us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 40/100\n",
      "1062/1062 [==============================] - 0s 204us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 41/100\n",
      "1062/1062 [==============================] - 0s 244us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 42/100\n",
      "1062/1062 [==============================] - 0s 220us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 43/100\n",
      "1062/1062 [==============================] - 0s 227us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 44/100\n",
      "1062/1062 [==============================] - 0s 162us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 45/100\n",
      "1062/1062 [==============================] - 0s 203us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 46/100\n",
      "1062/1062 [==============================] - 0s 193us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 47/100\n",
      "1062/1062 [==============================] - 0s 200us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 48/100\n",
      "1062/1062 [==============================] - 0s 212us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 49/100\n",
      "1062/1062 [==============================] - 0s 189us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 50/100\n",
      "1062/1062 [==============================] - 0s 187us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 51/100\n",
      "1062/1062 [==============================] - 0s 189us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 52/100\n",
      "1062/1062 [==============================] - 0s 209us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 53/100\n",
      "1062/1062 [==============================] - 0s 210us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 54/100\n",
      "1062/1062 [==============================] - 0s 153us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 55/100\n",
      "1062/1062 [==============================] - 0s 189us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 56/100\n",
      "1062/1062 [==============================] - 0s 170us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 57/100\n",
      "1062/1062 [==============================] - 0s 176us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 58/100\n",
      "1062/1062 [==============================] - 0s 158us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 59/100\n",
      "1062/1062 [==============================] - 0s 166us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 60/100\n",
      "1062/1062 [==============================] - 0s 186us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 61/100\n",
      "1062/1062 [==============================] - 0s 156us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 62/100\n",
      "1062/1062 [==============================] - 0s 164us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 63/100\n",
      "1062/1062 [==============================] - 0s 326us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 64/100\n",
      "1062/1062 [==============================] - 0s 237us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 65/100\n",
      "1062/1062 [==============================] - 0s 349us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 66/100\n",
      "1062/1062 [==============================] - 0s 273us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 67/100\n",
      "1062/1062 [==============================] - 0s 225us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 68/100\n",
      "1062/1062 [==============================] - 0s 202us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 69/100\n",
      "1062/1062 [==============================] - 0s 232us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 70/100\n",
      "1062/1062 [==============================] - 0s 219us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 71/100\n",
      "1062/1062 [==============================] - 0s 221us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 72/100\n",
      "1062/1062 [==============================] - 0s 214us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 73/100\n",
      "1062/1062 [==============================] - 0s 193us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 74/100\n",
      "1062/1062 [==============================] - 0s 185us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 75/100\n",
      "1062/1062 [==============================] - 0s 183us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 76/100\n",
      "1062/1062 [==============================] - 0s 183us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 77/100\n",
      "1062/1062 [==============================] - 0s 183us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 78/100\n",
      "1062/1062 [==============================] - 0s 164us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 79/100\n",
      "1062/1062 [==============================] - 0s 159us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 80/100\n",
      "1062/1062 [==============================] - 0s 166us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 81/100\n",
      "1062/1062 [==============================] - 0s 178us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1062/1062 [==============================] - 0s 159us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 83/100\n",
      "1062/1062 [==============================] - 0s 177us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 84/100\n",
      "1062/1062 [==============================] - 0s 181us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 85/100\n",
      "1062/1062 [==============================] - 0s 168us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 86/100\n",
      "1062/1062 [==============================] - 0s 170us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 87/100\n",
      "1062/1062 [==============================] - 0s 198us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 88/100\n",
      "1062/1062 [==============================] - 0s 220us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 89/100\n",
      "1062/1062 [==============================] - 0s 168us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 90/100\n",
      "1062/1062 [==============================] - 0s 191us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 91/100\n",
      "1062/1062 [==============================] - 0s 182us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 92/100\n",
      "1062/1062 [==============================] - 0s 180us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 93/100\n",
      "1062/1062 [==============================] - 0s 204us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 94/100\n",
      "1062/1062 [==============================] - 0s 178us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 95/100\n",
      "1062/1062 [==============================] - 0s 233us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 96/100\n",
      "1062/1062 [==============================] - 0s 199us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 97/100\n",
      "1062/1062 [==============================] - 0s 214us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 98/100\n",
      "1062/1062 [==============================] - 0s 173us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 99/100\n",
      "1062/1062 [==============================] - 0s 170us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 100/100\n",
      "1062/1062 [==============================] - 0s 218us/step - loss: 0.2732 - acc: 0.9831\n",
      "119/119 [==============================] - 0s 373us/step\n",
      "Epoch 1/100\n",
      "1063/1063 [==============================] - 1s 531us/step - loss: 0.3211 - acc: 0.9530\n",
      "Epoch 2/100\n",
      "1063/1063 [==============================] - 0s 205us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 3/100\n",
      "1063/1063 [==============================] - 0s 190us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 4/100\n",
      "1063/1063 [==============================] - 0s 177us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 5/100\n",
      "1063/1063 [==============================] - 0s 168us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 6/100\n",
      "1063/1063 [==============================] - 0s 245us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 7/100\n",
      "1063/1063 [==============================] - 0s 206us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 8/100\n",
      "1063/1063 [==============================] - 0s 204us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 9/100\n",
      "1063/1063 [==============================] - 0s 188us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 10/100\n",
      "1063/1063 [==============================] - 0s 201us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 11/100\n",
      "1063/1063 [==============================] - 0s 172us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 12/100\n",
      "1063/1063 [==============================] - 0s 142us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 13/100\n",
      "1063/1063 [==============================] - 0s 167us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 14/100\n",
      "1063/1063 [==============================] - 0s 230us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 15/100\n",
      "1063/1063 [==============================] - 0s 203us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 16/100\n",
      "1063/1063 [==============================] - 0s 190us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 17/100\n",
      "1063/1063 [==============================] - 0s 227us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 18/100\n",
      "1063/1063 [==============================] - 0s 220us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 19/100\n",
      "1063/1063 [==============================] - 0s 196us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 20/100\n",
      "1063/1063 [==============================] - 0s 159us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 21/100\n",
      "1063/1063 [==============================] - 0s 192us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 22/100\n",
      "1063/1063 [==============================] - 0s 225us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 23/100\n",
      "1063/1063 [==============================] - 0s 139us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 24/100\n",
      "1063/1063 [==============================] - 0s 160us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 25/100\n",
      "1063/1063 [==============================] - 0s 186us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 26/100\n",
      "1063/1063 [==============================] - 0s 213us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 27/100\n",
      "1063/1063 [==============================] - 0s 208us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 28/100\n",
      "1063/1063 [==============================] - 0s 212us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 29/100\n",
      "1063/1063 [==============================] - 0s 165us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 30/100\n",
      "1063/1063 [==============================] - 0s 206us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 31/100\n",
      "1063/1063 [==============================] - 0s 193us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 32/100\n",
      "1063/1063 [==============================] - 0s 178us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 33/100\n",
      "1063/1063 [==============================] - 0s 425us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 34/100\n",
      "1063/1063 [==============================] - 0s 287us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 35/100\n",
      "1063/1063 [==============================] - 1s 620us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 36/100\n",
      "1063/1063 [==============================] - 0s 377us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 37/100\n",
      "1063/1063 [==============================] - 0s 238us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 38/100\n",
      "1063/1063 [==============================] - 0s 211us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 39/100\n",
      "1063/1063 [==============================] - 0s 203us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 40/100\n",
      "1063/1063 [==============================] - 0s 190us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 41/100\n",
      "1063/1063 [==============================] - 0s 179us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 42/100\n",
      "1063/1063 [==============================] - 0s 158us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 43/100\n",
      "1063/1063 [==============================] - 0s 178us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 44/100\n",
      "1063/1063 [==============================] - 0s 175us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 45/100\n",
      "1063/1063 [==============================] - 0s 162us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 46/100\n",
      "1063/1063 [==============================] - 0s 165us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 47/100\n",
      "1063/1063 [==============================] - 0s 175us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 48/100\n",
      "1063/1063 [==============================] - 0s 189us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 49/100\n",
      "1063/1063 [==============================] - 0s 171us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 50/100\n",
      "1063/1063 [==============================] - 0s 165us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 51/100\n",
      "1063/1063 [==============================] - 0s 190us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 52/100\n",
      "1063/1063 [==============================] - 0s 192us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 53/100\n",
      "1063/1063 [==============================] - 0s 167us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 54/100\n",
      "1063/1063 [==============================] - 0s 187us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 55/100\n",
      "1063/1063 [==============================] - 0s 213us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 56/100\n",
      "1063/1063 [==============================] - 0s 194us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 57/100\n",
      "1063/1063 [==============================] - 0s 173us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 58/100\n",
      "1063/1063 [==============================] - 0s 183us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 59/100\n",
      "1063/1063 [==============================] - 0s 237us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 60/100\n",
      "1063/1063 [==============================] - 0s 203us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 61/100\n",
      "1063/1063 [==============================] - 0s 243us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1063/1063 [==============================] - 0s 187us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 63/100\n",
      "1063/1063 [==============================] - 0s 209us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 64/100\n",
      "1063/1063 [==============================] - 0s 188us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 65/100\n",
      "1063/1063 [==============================] - 0s 186us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 66/100\n",
      "1063/1063 [==============================] - 0s 179us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 67/100\n",
      "1063/1063 [==============================] - 0s 192us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 68/100\n",
      "1063/1063 [==============================] - 0s 204us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 69/100\n",
      "1063/1063 [==============================] - 0s 175us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 70/100\n",
      "1063/1063 [==============================] - 0s 195us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 71/100\n",
      "1063/1063 [==============================] - 0s 187us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 72/100\n",
      "1063/1063 [==============================] - 0s 221us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 73/100\n",
      "1063/1063 [==============================] - 0s 197us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 74/100\n",
      "1063/1063 [==============================] - 0s 173us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 75/100\n",
      "1063/1063 [==============================] - 0s 177us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 76/100\n",
      "1063/1063 [==============================] - 0s 183us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 77/100\n",
      "1063/1063 [==============================] - 0s 201us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 78/100\n",
      "1063/1063 [==============================] - 0s 208us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 79/100\n",
      "1063/1063 [==============================] - 0s 216us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 80/100\n",
      "1063/1063 [==============================] - 0s 181us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 81/100\n",
      "1063/1063 [==============================] - 0s 232us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 82/100\n",
      "1063/1063 [==============================] - 0s 183us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 83/100\n",
      "1063/1063 [==============================] - 0s 186us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 84/100\n",
      "1063/1063 [==============================] - 0s 230us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 85/100\n",
      "1063/1063 [==============================] - 0s 211us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 86/100\n",
      "1063/1063 [==============================] - 0s 232us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 87/100\n",
      "1063/1063 [==============================] - 0s 190us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 88/100\n",
      "1063/1063 [==============================] - 0s 179us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 89/100\n",
      "1063/1063 [==============================] - 0s 178us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 90/100\n",
      "1063/1063 [==============================] - 0s 283us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 91/100\n",
      "1063/1063 [==============================] - 0s 230us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 92/100\n",
      "1063/1063 [==============================] - 0s 187us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 93/100\n",
      "1063/1063 [==============================] - 0s 171us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 94/100\n",
      "1063/1063 [==============================] - 0s 181us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 95/100\n",
      "1063/1063 [==============================] - 0s 192us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 96/100\n",
      "1063/1063 [==============================] - 0s 198us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 97/100\n",
      "1063/1063 [==============================] - 0s 205us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 98/100\n",
      "1063/1063 [==============================] - 0s 176us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 99/100\n",
      "1063/1063 [==============================] - 0s 193us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 100/100\n",
      "1063/1063 [==============================] - 0s 171us/step - loss: 0.2729 - acc: 0.9831\n",
      "118/118 [==============================] - 0s 433us/step\n",
      "Epoch 1/100\n",
      "1063/1063 [==============================] - 1s 581us/step - loss: 0.2933 - acc: 0.9821\n",
      "Epoch 2/100\n",
      "1063/1063 [==============================] - 0s 205us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 3/100\n",
      "1063/1063 [==============================] - 0s 194us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 4/100\n",
      "1063/1063 [==============================] - 0s 196us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 5/100\n",
      "1063/1063 [==============================] - 0s 180us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 6/100\n",
      "1063/1063 [==============================] - 0s 207us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 7/100\n",
      "1063/1063 [==============================] - 0s 201us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 8/100\n",
      "1063/1063 [==============================] - 0s 230us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 9/100\n",
      "1063/1063 [==============================] - 0s 218us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 10/100\n",
      "1063/1063 [==============================] - 0s 193us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 11/100\n",
      "1063/1063 [==============================] - ETA: 0s - loss: 0.3418 - acc: 0.978 - 0s 187us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 12/100\n",
      "1063/1063 [==============================] - 0s 177us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 13/100\n",
      "1063/1063 [==============================] - 0s 179us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 14/100\n",
      "1063/1063 [==============================] - 0s 193us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 15/100\n",
      "1063/1063 [==============================] - 0s 162us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 16/100\n",
      "1063/1063 [==============================] - 0s 166us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 17/100\n",
      "1063/1063 [==============================] - 0s 203us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 18/100\n",
      "1063/1063 [==============================] - 0s 226us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 19/100\n",
      "1063/1063 [==============================] - 0s 193us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 20/100\n",
      "1063/1063 [==============================] - 0s 181us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 21/100\n",
      "1063/1063 [==============================] - 0s 215us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 22/100\n",
      "1063/1063 [==============================] - 0s 206us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 23/100\n",
      "1063/1063 [==============================] - 0s 189us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 24/100\n",
      "1063/1063 [==============================] - 0s 203us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 25/100\n",
      "1063/1063 [==============================] - 0s 206us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 26/100\n",
      "1063/1063 [==============================] - 0s 208us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 27/100\n",
      "1063/1063 [==============================] - 0s 239us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 28/100\n",
      "1063/1063 [==============================] - 0s 188us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 29/100\n",
      "1063/1063 [==============================] - 0s 166us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 30/100\n",
      "1063/1063 [==============================] - 0s 189us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 31/100\n",
      "1063/1063 [==============================] - 0s 170us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 32/100\n",
      "1063/1063 [==============================] - 0s 165us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 33/100\n",
      "1063/1063 [==============================] - 0s 221us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 34/100\n",
      "1063/1063 [==============================] - 0s 178us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 35/100\n",
      "1063/1063 [==============================] - 0s 220us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 36/100\n",
      "1063/1063 [==============================] - 0s 229us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 37/100\n",
      "1063/1063 [==============================] - 0s 188us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 38/100\n",
      "1063/1063 [==============================] - 0s 281us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 39/100\n",
      "1063/1063 [==============================] - 0s 241us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 40/100\n",
      "1063/1063 [==============================] - 0s 212us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 41/100\n",
      "1063/1063 [==============================] - 0s 213us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1063/1063 [==============================] - 0s 188us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 43/100\n",
      "1063/1063 [==============================] - 0s 252us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 44/100\n",
      "1063/1063 [==============================] - 0s 278us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 45/100\n",
      "1063/1063 [==============================] - 0s 237us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 46/100\n",
      "1063/1063 [==============================] - 0s 195us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 47/100\n",
      "1063/1063 [==============================] - 0s 221us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 48/100\n",
      "1063/1063 [==============================] - 0s 230us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 49/100\n",
      "1063/1063 [==============================] - 0s 206us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 50/100\n",
      "1063/1063 [==============================] - 0s 202us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 51/100\n",
      "1063/1063 [==============================] - 0s 194us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 52/100\n",
      "1063/1063 [==============================] - 0s 149us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 53/100\n",
      "1063/1063 [==============================] - 0s 157us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 54/100\n",
      "1063/1063 [==============================] - 0s 174us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 55/100\n",
      "1063/1063 [==============================] - 0s 200us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 56/100\n",
      "1063/1063 [==============================] - 0s 174us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 57/100\n",
      "1063/1063 [==============================] - 0s 172us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 58/100\n",
      "1063/1063 [==============================] - 0s 236us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 59/100\n",
      "1063/1063 [==============================] - 0s 191us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 60/100\n",
      "1063/1063 [==============================] - 0s 228us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 61/100\n",
      "1063/1063 [==============================] - 0s 195us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 62/100\n",
      "1063/1063 [==============================] - 0s 167us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 63/100\n",
      "1063/1063 [==============================] - 0s 214us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 64/100\n",
      "1063/1063 [==============================] - 0s 228us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 65/100\n",
      "1063/1063 [==============================] - 0s 244us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 66/100\n",
      "1063/1063 [==============================] - 0s 225us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 67/100\n",
      "1063/1063 [==============================] - 0s 230us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 68/100\n",
      "1063/1063 [==============================] - 0s 212us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 69/100\n",
      "1063/1063 [==============================] - 0s 204us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 70/100\n",
      "1063/1063 [==============================] - 0s 237us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 71/100\n",
      "1063/1063 [==============================] - 0s 199us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 72/100\n",
      "1063/1063 [==============================] - 0s 230us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 73/100\n",
      "1063/1063 [==============================] - 0s 191us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 74/100\n",
      "1063/1063 [==============================] - 0s 192us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 75/100\n",
      "1063/1063 [==============================] - 0s 235us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 76/100\n",
      "1063/1063 [==============================] - 0s 216us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 77/100\n",
      "1063/1063 [==============================] - 0s 232us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 78/100\n",
      "1063/1063 [==============================] - 0s 235us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 79/100\n",
      "1063/1063 [==============================] - 0s 248us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 80/100\n",
      "1063/1063 [==============================] - 0s 229us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 81/100\n",
      "1063/1063 [==============================] - 0s 186us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 82/100\n",
      "1063/1063 [==============================] - 0s 184us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 83/100\n",
      "1063/1063 [==============================] - 0s 200us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 84/100\n",
      "1063/1063 [==============================] - 0s 233us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 85/100\n",
      "1063/1063 [==============================] - 0s 181us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 86/100\n",
      "1063/1063 [==============================] - 0s 194us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 87/100\n",
      "1063/1063 [==============================] - 0s 189us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 88/100\n",
      "1063/1063 [==============================] - 0s 195us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 89/100\n",
      "1063/1063 [==============================] - 0s 178us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 90/100\n",
      "1063/1063 [==============================] - 0s 188us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 91/100\n",
      "1063/1063 [==============================] - 0s 170us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 92/100\n",
      "1063/1063 [==============================] - 0s 171us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 93/100\n",
      "1063/1063 [==============================] - 0s 176us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 94/100\n",
      "1063/1063 [==============================] - 0s 164us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 95/100\n",
      "1063/1063 [==============================] - 0s 170us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 96/100\n",
      "1063/1063 [==============================] - 0s 195us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 97/100\n",
      "1063/1063 [==============================] - 0s 270us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 98/100\n",
      "1063/1063 [==============================] - 0s 225us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 99/100\n",
      "1063/1063 [==============================] - 0s 239us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 100/100\n",
      "1063/1063 [==============================] - 0s 186us/step - loss: 0.2881 - acc: 0.9821\n",
      "118/118 [==============================] - 0s 412us/step\n",
      "Epoch 1/100\n",
      "1063/1063 [==============================] - 1s 680us/step - loss: 0.2732 - acc: 0.9831\n",
      "Epoch 2/100\n",
      "1063/1063 [==============================] - 0s 222us/step - loss: 0.2729 - acc: 0.9831TA: 0s - loss: 0.3148 - acc: 0.98\n",
      "Epoch 3/100\n",
      "1063/1063 [==============================] - 0s 211us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 4/100\n",
      "1063/1063 [==============================] - 0s 195us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 5/100\n",
      "1063/1063 [==============================] - 0s 209us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 6/100\n",
      "1063/1063 [==============================] - 0s 198us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 7/100\n",
      "1063/1063 [==============================] - 0s 290us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 8/100\n",
      "1063/1063 [==============================] - 0s 311us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 9/100\n",
      "1063/1063 [==============================] - 0s 219us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 10/100\n",
      "1063/1063 [==============================] - 0s 217us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 11/100\n",
      "1063/1063 [==============================] - 0s 185us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 12/100\n",
      "1063/1063 [==============================] - 0s 186us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 13/100\n",
      "1063/1063 [==============================] - 0s 173us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 14/100\n",
      "1063/1063 [==============================] - 0s 164us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 15/100\n",
      "1063/1063 [==============================] - 0s 220us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 16/100\n",
      "1063/1063 [==============================] - 0s 196us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 17/100\n",
      "1063/1063 [==============================] - 0s 168us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 18/100\n",
      "1063/1063 [==============================] - 0s 214us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 19/100\n",
      "1063/1063 [==============================] - 0s 155us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 20/100\n",
      "1063/1063 [==============================] - 0s 218us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 21/100\n",
      "1063/1063 [==============================] - 0s 183us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1063/1063 [==============================] - 0s 175us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 23/100\n",
      "1063/1063 [==============================] - 0s 183us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 24/100\n",
      "1063/1063 [==============================] - 0s 219us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 25/100\n",
      "1063/1063 [==============================] - 0s 192us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 26/100\n",
      "1063/1063 [==============================] - 0s 189us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 27/100\n",
      "1063/1063 [==============================] - 0s 185us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 28/100\n",
      "1063/1063 [==============================] - 0s 212us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 29/100\n",
      "1063/1063 [==============================] - 0s 210us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 30/100\n",
      "1063/1063 [==============================] - 0s 169us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 31/100\n",
      "1063/1063 [==============================] - 0s 206us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 32/100\n",
      "1063/1063 [==============================] - 0s 191us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 33/100\n",
      "1063/1063 [==============================] - 0s 212us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 34/100\n",
      "1063/1063 [==============================] - 0s 196us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 35/100\n",
      "1063/1063 [==============================] - ETA: 0s - loss: 0.3238 - acc: 0.9799  - 0s 186us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 36/100\n",
      "1063/1063 [==============================] - 0s 151us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 37/100\n",
      "1063/1063 [==============================] - 0s 183us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 38/100\n",
      "1063/1063 [==============================] - 0s 175us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 39/100\n",
      "1063/1063 [==============================] - 0s 169us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 40/100\n",
      "1063/1063 [==============================] - 0s 161us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 41/100\n",
      "1063/1063 [==============================] - 0s 155us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 42/100\n",
      "1063/1063 [==============================] - 0s 219us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 43/100\n",
      "1063/1063 [==============================] - 0s 192us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 44/100\n",
      "1063/1063 [==============================] - 0s 205us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 45/100\n",
      "1063/1063 [==============================] - 0s 184us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 46/100\n",
      "1063/1063 [==============================] - 0s 177us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 47/100\n",
      "1063/1063 [==============================] - 0s 180us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 48/100\n",
      "1063/1063 [==============================] - 0s 170us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 49/100\n",
      "1063/1063 [==============================] - 0s 183us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 50/100\n",
      "1063/1063 [==============================] - 0s 187us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 51/100\n",
      "1063/1063 [==============================] - 0s 170us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 52/100\n",
      "1063/1063 [==============================] - 0s 225us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 53/100\n",
      "1063/1063 [==============================] - 0s 226us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 54/100\n",
      "1063/1063 [==============================] - 0s 240us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 55/100\n",
      "1063/1063 [==============================] - 0s 198us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 56/100\n",
      "1063/1063 [==============================] - 0s 208us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 57/100\n",
      "1063/1063 [==============================] - 0s 162us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 58/100\n",
      "1063/1063 [==============================] - 0s 166us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 59/100\n",
      "1063/1063 [==============================] - 0s 181us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 60/100\n",
      "1063/1063 [==============================] - 0s 184us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 61/100\n",
      "1063/1063 [==============================] - 0s 220us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 62/100\n",
      "1063/1063 [==============================] - 0s 181us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 63/100\n",
      "1063/1063 [==============================] - 0s 267us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 64/100\n",
      "1063/1063 [==============================] - 0s 191us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 65/100\n",
      "1063/1063 [==============================] - 0s 207us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 66/100\n",
      "1063/1063 [==============================] - 0s 208us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 67/100\n",
      "1063/1063 [==============================] - 0s 182us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 68/100\n",
      "1063/1063 [==============================] - 0s 178us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 69/100\n",
      "1063/1063 [==============================] - 0s 192us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 70/100\n",
      "1063/1063 [==============================] - 0s 190us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 71/100\n",
      "1063/1063 [==============================] - 0s 187us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 72/100\n",
      "1063/1063 [==============================] - 0s 191us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 73/100\n",
      "1063/1063 [==============================] - 0s 186us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 74/100\n",
      "1063/1063 [==============================] - 0s 173us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 75/100\n",
      "1063/1063 [==============================] - 0s 203us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 76/100\n",
      "1063/1063 [==============================] - 0s 194us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 77/100\n",
      "1063/1063 [==============================] - 0s 174us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 78/100\n",
      "1063/1063 [==============================] - 0s 174us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 79/100\n",
      "1063/1063 [==============================] - 0s 212us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 80/100\n",
      "1063/1063 [==============================] - 0s 185us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 81/100\n",
      "1063/1063 [==============================] - 0s 171us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 82/100\n",
      "1063/1063 [==============================] - 0s 167us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 83/100\n",
      "1063/1063 [==============================] - 0s 221us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 84/100\n",
      "1063/1063 [==============================] - 0s 154us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 85/100\n",
      "1063/1063 [==============================] - 0s 159us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 86/100\n",
      "1063/1063 [==============================] - 0s 209us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 87/100\n",
      "1063/1063 [==============================] - 0s 185us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 88/100\n",
      "1063/1063 [==============================] - 0s 201us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 89/100\n",
      "1063/1063 [==============================] - 0s 199us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 90/100\n",
      "1063/1063 [==============================] - 0s 148us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 91/100\n",
      "1063/1063 [==============================] - 0s 255us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 92/100\n",
      "1063/1063 [==============================] - 0s 186us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 93/100\n",
      "1063/1063 [==============================] - 0s 175us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 94/100\n",
      "1063/1063 [==============================] - 0s 171us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 95/100\n",
      "1063/1063 [==============================] - 0s 166us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 96/100\n",
      "1063/1063 [==============================] - 0s 175us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 97/100\n",
      "1063/1063 [==============================] - 0s 174us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 98/100\n",
      "1063/1063 [==============================] - 0s 197us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 99/100\n",
      "1063/1063 [==============================] - 0s 179us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 100/100\n",
      "1063/1063 [==============================] - 0s 244us/step - loss: 0.2729 - acc: 0.9831\n",
      "118/118 [==============================] - 0s 583us/step\n",
      "Epoch 1/100\n",
      "1063/1063 [==============================] - 1s 852us/step - loss: 0.3651 - acc: 0.9567\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1063/1063 [==============================] - 0s 239us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 3/100\n",
      "1063/1063 [==============================] - 0s 230us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 4/100\n",
      "1063/1063 [==============================] - 0s 193us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 5/100\n",
      "1063/1063 [==============================] - 0s 188us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 6/100\n",
      "1063/1063 [==============================] - 0s 163us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 7/100\n",
      "1063/1063 [==============================] - 0s 174us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 8/100\n",
      "1063/1063 [==============================] - 0s 177us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 9/100\n",
      "1063/1063 [==============================] - 0s 183us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 10/100\n",
      "1063/1063 [==============================] - 0s 169us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 11/100\n",
      "1063/1063 [==============================] - 0s 183us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 12/100\n",
      "1063/1063 [==============================] - 0s 193us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 13/100\n",
      "1063/1063 [==============================] - 0s 206us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 14/100\n",
      "1063/1063 [==============================] - 0s 200us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 15/100\n",
      "1063/1063 [==============================] - 0s 228us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 16/100\n",
      "1063/1063 [==============================] - 0s 200us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 17/100\n",
      "1063/1063 [==============================] - 0s 226us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 18/100\n",
      "1063/1063 [==============================] - 0s 187us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 19/100\n",
      "1063/1063 [==============================] - 0s 180us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 20/100\n",
      "1063/1063 [==============================] - 0s 200us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 21/100\n",
      "1063/1063 [==============================] - 0s 197us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 22/100\n",
      "1063/1063 [==============================] - 0s 181us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 23/100\n",
      "1063/1063 [==============================] - 0s 198us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 24/100\n",
      "1063/1063 [==============================] - 0s 187us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 25/100\n",
      "1063/1063 [==============================] - 0s 163us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 26/100\n",
      "1063/1063 [==============================] - 0s 185us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 27/100\n",
      "1063/1063 [==============================] - 0s 164us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 28/100\n",
      "1063/1063 [==============================] - 0s 174us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 29/100\n",
      "1063/1063 [==============================] - 0s 194us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 30/100\n",
      "1063/1063 [==============================] - 0s 173us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 31/100\n",
      "1063/1063 [==============================] - 0s 187us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 32/100\n",
      "1063/1063 [==============================] - 0s 199us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 33/100\n",
      "1063/1063 [==============================] - 0s 190us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 34/100\n",
      "1063/1063 [==============================] - 0s 186us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 35/100\n",
      "1063/1063 [==============================] - 0s 173us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 36/100\n",
      "1063/1063 [==============================] - 0s 182us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 37/100\n",
      "1063/1063 [==============================] - 0s 179us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 38/100\n",
      "1063/1063 [==============================] - 0s 244us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 39/100\n",
      "1063/1063 [==============================] - 0s 182us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 40/100\n",
      "1063/1063 [==============================] - 0s 179us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 41/100\n",
      "1063/1063 [==============================] - 0s 186us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 42/100\n",
      "1063/1063 [==============================] - 0s 188us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 43/100\n",
      "1063/1063 [==============================] - 0s 166us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 44/100\n",
      "1063/1063 [==============================] - 0s 169us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 45/100\n",
      "1063/1063 [==============================] - 0s 196us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 46/100\n",
      "1063/1063 [==============================] - 0s 186us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 47/100\n",
      "1063/1063 [==============================] - 0s 171us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 48/100\n",
      "1063/1063 [==============================] - 0s 164us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 49/100\n",
      "1063/1063 [==============================] - 0s 170us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 50/100\n",
      "1063/1063 [==============================] - 0s 213us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 51/100\n",
      "1063/1063 [==============================] - 0s 211us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 52/100\n",
      "1063/1063 [==============================] - 0s 180us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 53/100\n",
      "1063/1063 [==============================] - 0s 189us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 54/100\n",
      "1063/1063 [==============================] - 0s 192us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 55/100\n",
      "1063/1063 [==============================] - 0s 184us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 56/100\n",
      "1063/1063 [==============================] - 0s 198us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 57/100\n",
      "1063/1063 [==============================] - 0s 196us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 58/100\n",
      "1063/1063 [==============================] - 0s 181us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 59/100\n",
      "1063/1063 [==============================] - 0s 219us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 60/100\n",
      "1063/1063 [==============================] - 0s 180us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 61/100\n",
      "1063/1063 [==============================] - 0s 174us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 62/100\n",
      "1063/1063 [==============================] - 0s 178us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 63/100\n",
      "1063/1063 [==============================] - 0s 281us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 64/100\n",
      "1063/1063 [==============================] - 0s 244us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 65/100\n",
      "1063/1063 [==============================] - 0s 205us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 66/100\n",
      "1063/1063 [==============================] - 0s 195us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 67/100\n",
      "1063/1063 [==============================] - 0s 273us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 68/100\n",
      "1063/1063 [==============================] - 0s 260us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 69/100\n",
      "1063/1063 [==============================] - 0s 261us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 70/100\n",
      "1063/1063 [==============================] - 0s 211us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 71/100\n",
      "1063/1063 [==============================] - 0s 243us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 72/100\n",
      "1063/1063 [==============================] - 0s 200us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 73/100\n",
      "1063/1063 [==============================] - 0s 209us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 74/100\n",
      "1063/1063 [==============================] - 0s 163us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 75/100\n",
      "1063/1063 [==============================] - 0s 184us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 76/100\n",
      "1063/1063 [==============================] - 0s 181us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 77/100\n",
      "1063/1063 [==============================] - 0s 185us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 78/100\n",
      "1063/1063 [==============================] - 0s 190us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 79/100\n",
      "1063/1063 [==============================] - 0s 220us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 80/100\n",
      "1063/1063 [==============================] - 0s 247us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 81/100\n",
      "1063/1063 [==============================] - 0s 216us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 82/100\n",
      "1063/1063 [==============================] - 0s 196us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1063/1063 [==============================] - 0s 212us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 84/100\n",
      "1063/1063 [==============================] - 0s 187us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 85/100\n",
      "1063/1063 [==============================] - 0s 284us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 86/100\n",
      "1063/1063 [==============================] - 0s 193us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 87/100\n",
      "1063/1063 [==============================] - 0s 219us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 88/100\n",
      "1063/1063 [==============================] - 0s 221us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 89/100\n",
      "1063/1063 [==============================] - 0s 206us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 90/100\n",
      "1063/1063 [==============================] - 0s 217us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 91/100\n",
      "1063/1063 [==============================] - 0s 194us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 92/100\n",
      "1063/1063 [==============================] - 0s 191us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 93/100\n",
      "1063/1063 [==============================] - 0s 209us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 94/100\n",
      "1063/1063 [==============================] - 0s 219us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 95/100\n",
      "1063/1063 [==============================] - 0s 207us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 96/100\n",
      "1063/1063 [==============================] - 0s 219us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 97/100\n",
      "1063/1063 [==============================] - 0s 211us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 98/100\n",
      "1063/1063 [==============================] - 0s 201us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 99/100\n",
      "1063/1063 [==============================] - 0s 177us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 100/100\n",
      "1063/1063 [==============================] - 0s 190us/step - loss: 0.2729 - acc: 0.9831\n",
      "118/118 [==============================] - 0s 745us/step\n",
      "Epoch 1/100\n",
      "1063/1063 [==============================] - 1s 653us/step - loss: 0.2670 - acc: 0.9831\n",
      "Epoch 2/100\n",
      "1063/1063 [==============================] - 0s 208us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 3/100\n",
      "1063/1063 [==============================] - 0s 179us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 4/100\n",
      "1063/1063 [==============================] - 0s 196us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 5/100\n",
      "1063/1063 [==============================] - 0s 162us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 6/100\n",
      "1063/1063 [==============================] - 0s 173us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 7/100\n",
      "1063/1063 [==============================] - 0s 180us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 8/100\n",
      "1063/1063 [==============================] - 0s 169us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 9/100\n",
      "1063/1063 [==============================] - 0s 190us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 10/100\n",
      "1063/1063 [==============================] - 0s 201us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 11/100\n",
      "1063/1063 [==============================] - 0s 207us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 12/100\n",
      "1063/1063 [==============================] - 0s 186us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 13/100\n",
      "1063/1063 [==============================] - 0s 198us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 14/100\n",
      "1063/1063 [==============================] - 0s 168us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 15/100\n",
      "1063/1063 [==============================] - 0s 179us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 16/100\n",
      "1063/1063 [==============================] - 0s 195us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 17/100\n",
      "1063/1063 [==============================] - 0s 217us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 18/100\n",
      "1063/1063 [==============================] - 0s 207us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 19/100\n",
      "1063/1063 [==============================] - 0s 193us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 20/100\n",
      "1063/1063 [==============================] - 0s 199us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 21/100\n",
      "1063/1063 [==============================] - 0s 211us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 22/100\n",
      "1063/1063 [==============================] - 0s 163us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 23/100\n",
      "1063/1063 [==============================] - 0s 200us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 24/100\n",
      "1063/1063 [==============================] - 0s 196us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 25/100\n",
      "1063/1063 [==============================] - 0s 205us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 26/100\n",
      "1063/1063 [==============================] - 0s 165us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 27/100\n",
      "1063/1063 [==============================] - 0s 139us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 28/100\n",
      "1063/1063 [==============================] - 0s 174us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 29/100\n",
      "1063/1063 [==============================] - 0s 174us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 30/100\n",
      "1063/1063 [==============================] - 0s 189us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 31/100\n",
      "1063/1063 [==============================] - 0s 208us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 32/100\n",
      "1063/1063 [==============================] - 0s 181us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 33/100\n",
      "1063/1063 [==============================] - 0s 177us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 34/100\n",
      "1063/1063 [==============================] - 0s 176us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 35/100\n",
      "1063/1063 [==============================] - 0s 188us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 36/100\n",
      "1063/1063 [==============================] - 0s 198us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 37/100\n",
      "1063/1063 [==============================] - 0s 189us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 38/100\n",
      "1063/1063 [==============================] - 0s 155us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 39/100\n",
      "1063/1063 [==============================] - 0s 153us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 40/100\n",
      "1063/1063 [==============================] - 0s 170us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 41/100\n",
      "1063/1063 [==============================] - 0s 245us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 42/100\n",
      "1063/1063 [==============================] - 0s 209us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 43/100\n",
      "1063/1063 [==============================] - 0s 268us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 44/100\n",
      "1063/1063 [==============================] - 0s 184us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 45/100\n",
      "1063/1063 [==============================] - 0s 191us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 46/100\n",
      "1063/1063 [==============================] - 0s 174us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 47/100\n",
      "1063/1063 [==============================] - 0s 187us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 48/100\n",
      "1063/1063 [==============================] - 0s 222us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 49/100\n",
      "1063/1063 [==============================] - 0s 205us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 50/100\n",
      "1063/1063 [==============================] - 0s 194us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 51/100\n",
      "1063/1063 [==============================] - 0s 213us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 52/100\n",
      "1063/1063 [==============================] - 0s 234us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 53/100\n",
      "1063/1063 [==============================] - 0s 213us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 54/100\n",
      "1063/1063 [==============================] - 0s 175us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 55/100\n",
      "1063/1063 [==============================] - 0s 201us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 56/100\n",
      "1063/1063 [==============================] - 0s 207us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 57/100\n",
      "1063/1063 [==============================] - 0s 171us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 58/100\n",
      "1063/1063 [==============================] - 0s 194us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 59/100\n",
      "1063/1063 [==============================] - 0s 177us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 60/100\n",
      "1063/1063 [==============================] - 0s 222us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 61/100\n",
      "1063/1063 [==============================] - 0s 219us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 62/100\n",
      "1063/1063 [==============================] - 0s 195us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1063/1063 [==============================] - 0s 179us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 64/100\n",
      "1063/1063 [==============================] - 0s 178us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 65/100\n",
      "1063/1063 [==============================] - 0s 225us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 66/100\n",
      "1063/1063 [==============================] - 0s 172us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 67/100\n",
      "1063/1063 [==============================] - 0s 196us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 68/100\n",
      "1063/1063 [==============================] - 0s 177us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 69/100\n",
      "1063/1063 [==============================] - 0s 178us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 70/100\n",
      "1063/1063 [==============================] - 0s 223us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 71/100\n",
      "1063/1063 [==============================] - 0s 167us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 72/100\n",
      "1063/1063 [==============================] - 0s 189us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 73/100\n",
      "1063/1063 [==============================] - 0s 184us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 74/100\n",
      "1063/1063 [==============================] - 0s 193us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 75/100\n",
      "1063/1063 [==============================] - 0s 186us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 76/100\n",
      "1063/1063 [==============================] - 0s 169us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 77/100\n",
      "1063/1063 [==============================] - 0s 193us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 78/100\n",
      "1063/1063 [==============================] - 0s 192us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 79/100\n",
      "1063/1063 [==============================] - 0s 168us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 80/100\n",
      "1063/1063 [==============================] - 0s 157us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 81/100\n",
      "1063/1063 [==============================] - 0s 166us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 82/100\n",
      "1063/1063 [==============================] - 0s 172us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 83/100\n",
      "1063/1063 [==============================] - 0s 163us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 84/100\n",
      "1063/1063 [==============================] - 0s 159us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 85/100\n",
      "1063/1063 [==============================] - 0s 171us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 86/100\n",
      "1063/1063 [==============================] - 0s 190us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 87/100\n",
      "1063/1063 [==============================] - 0s 191us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 88/100\n",
      "1063/1063 [==============================] - 0s 200us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 89/100\n",
      "1063/1063 [==============================] - 0s 206us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 90/100\n",
      "1063/1063 [==============================] - 0s 194us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 91/100\n",
      "1063/1063 [==============================] - 0s 204us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 92/100\n",
      "1063/1063 [==============================] - 0s 176us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 93/100\n",
      "1063/1063 [==============================] - 0s 163us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 94/100\n",
      "1063/1063 [==============================] - 0s 162us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 95/100\n",
      "1063/1063 [==============================] - 0s 187us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 96/100\n",
      "1063/1063 [==============================] - 0s 191us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 97/100\n",
      "1063/1063 [==============================] - 0s 155us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 98/100\n",
      "1063/1063 [==============================] - 0s 210us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 99/100\n",
      "1063/1063 [==============================] - 0s 197us/step - loss: 0.2729 - acc: 0.9831\n",
      "Epoch 100/100\n",
      "1063/1063 [==============================] - 0s 234us/step - loss: 0.2729 - acc: 0.9831\n",
      "118/118 [==============================] - 0s 971us/step\n",
      "Epoch 1/100\n",
      "1063/1063 [==============================] - 1s 668us/step - loss: 0.2777 - acc: 0.9699\n",
      "Epoch 2/100\n",
      "1063/1063 [==============================] - 0s 172us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 3/100\n",
      "1063/1063 [==============================] - 0s 182us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 4/100\n",
      "1063/1063 [==============================] - 0s 204us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 5/100\n",
      "1063/1063 [==============================] - 0s 195us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 6/100\n",
      "1063/1063 [==============================] - 0s 173us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 7/100\n",
      "1063/1063 [==============================] - 0s 170us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 8/100\n",
      "1063/1063 [==============================] - 0s 180us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 9/100\n",
      "1063/1063 [==============================] - 0s 159us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 10/100\n",
      "1063/1063 [==============================] - 0s 176us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 11/100\n",
      "1063/1063 [==============================] - 0s 152us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 12/100\n",
      "1063/1063 [==============================] - 0s 160us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 13/100\n",
      "1063/1063 [==============================] - 0s 176us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 14/100\n",
      "1063/1063 [==============================] - 0s 182us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 15/100\n",
      "1063/1063 [==============================] - 0s 188us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 16/100\n",
      "1063/1063 [==============================] - 0s 183us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 17/100\n",
      "1063/1063 [==============================] - 0s 194us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 18/100\n",
      "1063/1063 [==============================] - 0s 166us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 19/100\n",
      "1063/1063 [==============================] - 0s 198us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 20/100\n",
      "1063/1063 [==============================] - 0s 182us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 21/100\n",
      "1063/1063 [==============================] - 0s 190us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 22/100\n",
      "1063/1063 [==============================] - 0s 171us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 23/100\n",
      "1063/1063 [==============================] - 0s 176us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 24/100\n",
      "1063/1063 [==============================] - 0s 169us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 25/100\n",
      "1063/1063 [==============================] - 0s 172us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 26/100\n",
      "1063/1063 [==============================] - 0s 203us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 27/100\n",
      "1063/1063 [==============================] - 0s 166us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 28/100\n",
      "1063/1063 [==============================] - 0s 173us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 29/100\n",
      "1063/1063 [==============================] - 0s 175us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 30/100\n",
      "1063/1063 [==============================] - 0s 171us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 31/100\n",
      "1063/1063 [==============================] - 0s 222us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 32/100\n",
      "1063/1063 [==============================] - 0s 205us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 33/100\n",
      "1063/1063 [==============================] - 0s 161us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 34/100\n",
      "1063/1063 [==============================] - 0s 148us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 35/100\n",
      "1063/1063 [==============================] - 0s 195us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 36/100\n",
      "1063/1063 [==============================] - 0s 197us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 37/100\n",
      "1063/1063 [==============================] - 0s 173us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 38/100\n",
      "1063/1063 [==============================] - 0s 168us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 39/100\n",
      "1063/1063 [==============================] - 0s 166us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 40/100\n",
      "1063/1063 [==============================] - 0s 213us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 41/100\n",
      "1063/1063 [==============================] - 0s 166us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 42/100\n",
      "1063/1063 [==============================] - 0s 178us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1063/1063 [==============================] - 0s 172us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 44/100\n",
      "1063/1063 [==============================] - 0s 216us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 45/100\n",
      "1063/1063 [==============================] - 0s 191us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 46/100\n",
      "1063/1063 [==============================] - 0s 200us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 47/100\n",
      "1063/1063 [==============================] - 0s 185us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 48/100\n",
      "1063/1063 [==============================] - 0s 220us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 49/100\n",
      "1063/1063 [==============================] - 0s 216us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 50/100\n",
      "1063/1063 [==============================] - 0s 158us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 51/100\n",
      "1063/1063 [==============================] - 0s 168us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 52/100\n",
      "1063/1063 [==============================] - 0s 185us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 53/100\n",
      "1063/1063 [==============================] - 0s 181us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 54/100\n",
      "1063/1063 [==============================] - 0s 240us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 55/100\n",
      "1063/1063 [==============================] - 0s 262us/step - loss: 0.2578 - acc: 0.9840TA: 0s - loss: 0.1752 - acc: 0.98\n",
      "Epoch 56/100\n",
      "1063/1063 [==============================] - 0s 196us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 57/100\n",
      "1063/1063 [==============================] - 0s 239us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 58/100\n",
      "1063/1063 [==============================] - 0s 244us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 59/100\n",
      "1063/1063 [==============================] - 0s 169us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 60/100\n",
      "1063/1063 [==============================] - 0s 149us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 61/100\n",
      "1063/1063 [==============================] - 0s 202us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 62/100\n",
      "1063/1063 [==============================] - 0s 164us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 63/100\n",
      "1063/1063 [==============================] - 0s 163us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 64/100\n",
      "1063/1063 [==============================] - 0s 175us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 65/100\n",
      "1063/1063 [==============================] - 0s 184us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 66/100\n",
      "1063/1063 [==============================] - 0s 222us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 67/100\n",
      "1063/1063 [==============================] - 0s 237us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 68/100\n",
      "1063/1063 [==============================] - 0s 192us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 69/100\n",
      "1063/1063 [==============================] - 0s 153us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 70/100\n",
      "1063/1063 [==============================] - 0s 166us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 71/100\n",
      "1063/1063 [==============================] - 0s 181us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 72/100\n",
      "1063/1063 [==============================] - 0s 162us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 73/100\n",
      "1063/1063 [==============================] - 0s 192us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 74/100\n",
      "1063/1063 [==============================] - 0s 199us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 75/100\n",
      "1063/1063 [==============================] - 0s 267us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 76/100\n",
      "1063/1063 [==============================] - 0s 200us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 77/100\n",
      "1063/1063 [==============================] - 0s 195us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 78/100\n",
      "1063/1063 [==============================] - 0s 168us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 79/100\n",
      "1063/1063 [==============================] - 0s 174us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 80/100\n",
      "1063/1063 [==============================] - 0s 134us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 81/100\n",
      "1063/1063 [==============================] - 0s 178us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 82/100\n",
      "1063/1063 [==============================] - 0s 166us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 83/100\n",
      "1063/1063 [==============================] - 0s 173us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 84/100\n",
      "1063/1063 [==============================] - 0s 197us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 85/100\n",
      "1063/1063 [==============================] - 0s 177us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 86/100\n",
      "1063/1063 [==============================] - 0s 166us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 87/100\n",
      "1063/1063 [==============================] - 0s 181us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 88/100\n",
      "1063/1063 [==============================] - 0s 175us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 89/100\n",
      "1063/1063 [==============================] - 0s 164us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 90/100\n",
      "1063/1063 [==============================] - 0s 204us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 91/100\n",
      "1063/1063 [==============================] - 0s 184us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 92/100\n",
      "1063/1063 [==============================] - 0s 164us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 93/100\n",
      "1063/1063 [==============================] - 0s 187us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 94/100\n",
      "1063/1063 [==============================] - 0s 184us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 95/100\n",
      "1063/1063 [==============================] - 0s 188us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 96/100\n",
      "1063/1063 [==============================] - 0s 181us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 97/100\n",
      "1063/1063 [==============================] - 0s 192us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 98/100\n",
      "1063/1063 [==============================] - 0s 186us/step - loss: 0.2578 - acc: 0.9840\n",
      "Epoch 99/100\n",
      "1063/1063 [==============================] - 0s 214us/step - loss: 0.2578 - acc: 0.9840 0s - loss: 0.2963 - acc: 0.9\n",
      "Epoch 100/100\n",
      "1063/1063 [==============================] - 0s 223us/step - loss: 0.2578 - acc: 0.9840\n",
      "118/118 [==============================] - 0s 1ms/step\n",
      "Epoch 1/100\n",
      "1063/1063 [==============================] - 1s 753us/step - loss: 0.3357 - acc: 0.9520\n",
      "Epoch 2/100\n",
      "1063/1063 [==============================] - ETA: 0s - loss: 0.3126 - acc: 0.980 - 0s 188us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 3/100\n",
      "1063/1063 [==============================] - 0s 184us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 4/100\n",
      "1063/1063 [==============================] - 0s 204us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 5/100\n",
      "1063/1063 [==============================] - 0s 201us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 6/100\n",
      "1063/1063 [==============================] - 0s 167us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 7/100\n",
      "1063/1063 [==============================] - 0s 192us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 8/100\n",
      "1063/1063 [==============================] - 0s 196us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 9/100\n",
      "1063/1063 [==============================] - 0s 187us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 10/100\n",
      "1063/1063 [==============================] - 0s 201us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 11/100\n",
      "1063/1063 [==============================] - 0s 202us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 12/100\n",
      "1063/1063 [==============================] - 0s 224us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 13/100\n",
      "1063/1063 [==============================] - 0s 175us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 14/100\n",
      "1063/1063 [==============================] - 0s 176us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 15/100\n",
      "1063/1063 [==============================] - 0s 194us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 16/100\n",
      "1063/1063 [==============================] - 0s 169us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 17/100\n",
      "1063/1063 [==============================] - 0s 180us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 18/100\n",
      "1063/1063 [==============================] - 0s 175us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 19/100\n",
      "1063/1063 [==============================] - 0s 183us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 20/100\n",
      "1063/1063 [==============================] - 0s 222us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 21/100\n",
      "1063/1063 [==============================] - 0s 208us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1063/1063 [==============================] - 0s 201us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 23/100\n",
      "1063/1063 [==============================] - 0s 191us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 24/100\n",
      "1063/1063 [==============================] - 0s 216us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 25/100\n",
      "1063/1063 [==============================] - 0s 179us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 26/100\n",
      "1063/1063 [==============================] - 0s 203us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 27/100\n",
      "1063/1063 [==============================] - 0s 181us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 28/100\n",
      "1063/1063 [==============================] - 0s 187us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 29/100\n",
      "1063/1063 [==============================] - 0s 199us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 30/100\n",
      "1063/1063 [==============================] - 0s 191us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 31/100\n",
      "1063/1063 [==============================] - 0s 217us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 32/100\n",
      "1063/1063 [==============================] - 0s 185us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 33/100\n",
      "1063/1063 [==============================] - 0s 205us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 34/100\n",
      "1063/1063 [==============================] - 0s 194us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 35/100\n",
      "1063/1063 [==============================] - 0s 207us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 36/100\n",
      "1063/1063 [==============================] - 0s 201us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 37/100\n",
      "1063/1063 [==============================] - 0s 221us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 38/100\n",
      "1063/1063 [==============================] - 0s 194us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 39/100\n",
      "1063/1063 [==============================] - 0s 185us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 40/100\n",
      "1063/1063 [==============================] - 0s 178us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 41/100\n",
      "1063/1063 [==============================] - 0s 191us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 42/100\n",
      "1063/1063 [==============================] - 0s 216us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 43/100\n",
      "1063/1063 [==============================] - 0s 179us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 44/100\n",
      "1063/1063 [==============================] - 0s 232us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 45/100\n",
      "1063/1063 [==============================] - 0s 218us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 46/100\n",
      "1063/1063 [==============================] - 0s 209us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 47/100\n",
      "1063/1063 [==============================] - 0s 187us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 48/100\n",
      "1063/1063 [==============================] - 0s 200us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 49/100\n",
      "1063/1063 [==============================] - 0s 182us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 50/100\n",
      "1063/1063 [==============================] - 0s 176us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 51/100\n",
      "1063/1063 [==============================] - 0s 198us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 52/100\n",
      "1063/1063 [==============================] - 0s 178us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 53/100\n",
      "1063/1063 [==============================] - 0s 221us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 54/100\n",
      "1063/1063 [==============================] - 0s 189us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 55/100\n",
      "1063/1063 [==============================] - 0s 180us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 56/100\n",
      "1063/1063 [==============================] - 0s 191us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 57/100\n",
      "1063/1063 [==============================] - 0s 172us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 58/100\n",
      "1063/1063 [==============================] - 0s 166us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 59/100\n",
      "1063/1063 [==============================] - 0s 180us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 60/100\n",
      "1063/1063 [==============================] - 0s 218us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 61/100\n",
      "1063/1063 [==============================] - 0s 176us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 62/100\n",
      "1063/1063 [==============================] - 0s 183us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 63/100\n",
      "1063/1063 [==============================] - 0s 196us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 64/100\n",
      "1063/1063 [==============================] - 0s 177us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 65/100\n",
      "1063/1063 [==============================] - 0s 175us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 66/100\n",
      "1063/1063 [==============================] - 0s 170us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 67/100\n",
      "1063/1063 [==============================] - 0s 170us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 68/100\n",
      "1063/1063 [==============================] - 0s 222us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 69/100\n",
      "1063/1063 [==============================] - 0s 205us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 70/100\n",
      "1063/1063 [==============================] - 0s 235us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 71/100\n",
      "1063/1063 [==============================] - 0s 199us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 72/100\n",
      "1063/1063 [==============================] - 0s 153us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 73/100\n",
      "1063/1063 [==============================] - 0s 172us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 74/100\n",
      "1063/1063 [==============================] - 0s 186us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 75/100\n",
      "1063/1063 [==============================] - 0s 182us/step - loss: 0.3033 - acc: 0.9812 0s - loss: 0.3118 - acc: 0.98\n",
      "Epoch 76/100\n",
      "1063/1063 [==============================] - 0s 219us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 77/100\n",
      "1063/1063 [==============================] - 0s 169us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 78/100\n",
      "1063/1063 [==============================] - 0s 173us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 79/100\n",
      "1063/1063 [==============================] - 0s 173us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 80/100\n",
      "1063/1063 [==============================] - 0s 176us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 81/100\n",
      "1063/1063 [==============================] - 0s 234us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 82/100\n",
      "1063/1063 [==============================] - 0s 193us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 83/100\n",
      "1063/1063 [==============================] - 0s 201us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 84/100\n",
      "1063/1063 [==============================] - 0s 159us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 85/100\n",
      "1063/1063 [==============================] - 0s 182us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 86/100\n",
      "1063/1063 [==============================] - 0s 182us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 87/100\n",
      "1063/1063 [==============================] - 0s 204us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 88/100\n",
      "1063/1063 [==============================] - 0s 214us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 89/100\n",
      "1063/1063 [==============================] - 0s 224us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 90/100\n",
      "1063/1063 [==============================] - 0s 203us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 91/100\n",
      "1063/1063 [==============================] - 0s 202us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 92/100\n",
      "1063/1063 [==============================] - 0s 200us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 93/100\n",
      "1063/1063 [==============================] - 0s 181us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 94/100\n",
      "1063/1063 [==============================] - 0s 201us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 95/100\n",
      "1063/1063 [==============================] - 0s 214us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 96/100\n",
      "1063/1063 [==============================] - 0s 176us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 97/100\n",
      "1063/1063 [==============================] - 0s 187us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 98/100\n",
      "1063/1063 [==============================] - 0s 165us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 99/100\n",
      "1063/1063 [==============================] - 0s 179us/step - loss: 0.3033 - acc: 0.9812\n",
      "Epoch 100/100\n",
      "1063/1063 [==============================] - 0s 197us/step - loss: 0.3033 - acc: 0.9812\n",
      "118/118 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "1063/1063 [==============================] - 1s 741us/step - loss: 0.4811 - acc: 0.9577\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1063/1063 [==============================] - 0s 186us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 3/100\n",
      "1063/1063 [==============================] - 0s 183us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 4/100\n",
      "1063/1063 [==============================] - 0s 188us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 5/100\n",
      "1063/1063 [==============================] - 0s 217us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 6/100\n",
      "1063/1063 [==============================] - 0s 206us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 7/100\n",
      "1063/1063 [==============================] - 0s 212us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 8/100\n",
      "1063/1063 [==============================] - 0s 184us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 9/100\n",
      "1063/1063 [==============================] - 0s 157us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 10/100\n",
      "1063/1063 [==============================] - 0s 179us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 11/100\n",
      "1063/1063 [==============================] - 0s 202us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 12/100\n",
      "1063/1063 [==============================] - 0s 182us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 13/100\n",
      "1063/1063 [==============================] - 0s 193us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 14/100\n",
      "1063/1063 [==============================] - 0s 191us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 15/100\n",
      "1063/1063 [==============================] - 0s 177us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 16/100\n",
      "1063/1063 [==============================] - 0s 195us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 17/100\n",
      "1063/1063 [==============================] - 0s 189us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 18/100\n",
      "1063/1063 [==============================] - 0s 174us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 19/100\n",
      "1063/1063 [==============================] - 0s 171us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 20/100\n",
      "1063/1063 [==============================] - 0s 213us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 21/100\n",
      "1063/1063 [==============================] - 0s 189us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 22/100\n",
      "1063/1063 [==============================] - 0s 212us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 23/100\n",
      "1063/1063 [==============================] - 0s 207us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 24/100\n",
      "1063/1063 [==============================] - 0s 187us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 25/100\n",
      "1063/1063 [==============================] - 0s 184us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 26/100\n",
      "1063/1063 [==============================] - 0s 162us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 27/100\n",
      "1063/1063 [==============================] - 0s 183us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 28/100\n",
      "1063/1063 [==============================] - 0s 172us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 29/100\n",
      "1063/1063 [==============================] - 0s 179us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 30/100\n",
      "1063/1063 [==============================] - 0s 152us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 31/100\n",
      "1063/1063 [==============================] - 0s 168us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 32/100\n",
      "1063/1063 [==============================] - 0s 187us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 33/100\n",
      "1063/1063 [==============================] - 0s 206us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 34/100\n",
      "1063/1063 [==============================] - 0s 163us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 35/100\n",
      "1063/1063 [==============================] - 0s 173us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 36/100\n",
      "1063/1063 [==============================] - 0s 178us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 37/100\n",
      "1063/1063 [==============================] - 0s 193us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 38/100\n",
      "1063/1063 [==============================] - 0s 169us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 39/100\n",
      "1063/1063 [==============================] - 0s 203us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 40/100\n",
      "1063/1063 [==============================] - 0s 215us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 41/100\n",
      "1063/1063 [==============================] - 0s 199us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 42/100\n",
      "1063/1063 [==============================] - 0s 154us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 43/100\n",
      "1063/1063 [==============================] - 0s 179us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 44/100\n",
      "1063/1063 [==============================] - 0s 175us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 45/100\n",
      "1063/1063 [==============================] - 0s 182us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 46/100\n",
      "1063/1063 [==============================] - 0s 167us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 47/100\n",
      "1063/1063 [==============================] - 0s 200us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 48/100\n",
      "1063/1063 [==============================] - 0s 219us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 49/100\n",
      "1063/1063 [==============================] - 0s 203us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 50/100\n",
      "1063/1063 [==============================] - 0s 197us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 51/100\n",
      "1063/1063 [==============================] - 0s 190us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 52/100\n",
      "1063/1063 [==============================] - 0s 195us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 53/100\n",
      "1063/1063 [==============================] - 0s 204us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 54/100\n",
      "1063/1063 [==============================] - 0s 219us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 55/100\n",
      "1063/1063 [==============================] - 0s 199us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 56/100\n",
      "1063/1063 [==============================] - 0s 218us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 57/100\n",
      "1063/1063 [==============================] - 0s 178us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 58/100\n",
      "1063/1063 [==============================] - 0s 166us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 59/100\n",
      "1063/1063 [==============================] - 0s 181us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 60/100\n",
      "1063/1063 [==============================] - 0s 225us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 61/100\n",
      "1063/1063 [==============================] - 0s 195us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 62/100\n",
      "1063/1063 [==============================] - 0s 164us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 63/100\n",
      "1063/1063 [==============================] - 0s 182us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 64/100\n",
      "1063/1063 [==============================] - 0s 179us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 65/100\n",
      "1063/1063 [==============================] - 0s 181us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 66/100\n",
      "1063/1063 [==============================] - 0s 192us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 67/100\n",
      "1063/1063 [==============================] - 0s 193us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 68/100\n",
      "1063/1063 [==============================] - 0s 169us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 69/100\n",
      "1063/1063 [==============================] - 0s 162us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 70/100\n",
      "1063/1063 [==============================] - 0s 202us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 71/100\n",
      "1063/1063 [==============================] - 0s 200us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 72/100\n",
      "1063/1063 [==============================] - 0s 210us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 73/100\n",
      "1063/1063 [==============================] - 0s 212us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 74/100\n",
      "1063/1063 [==============================] - 0s 189us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 75/100\n",
      "1063/1063 [==============================] - 0s 198us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 76/100\n",
      "1063/1063 [==============================] - 0s 221us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 77/100\n",
      "1063/1063 [==============================] - 0s 221us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 78/100\n",
      "1063/1063 [==============================] - 0s 190us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 79/100\n",
      "1063/1063 [==============================] - 0s 220us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 80/100\n",
      "1063/1063 [==============================] - 0s 189us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 81/100\n",
      "1063/1063 [==============================] - 0s 168us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 82/100\n",
      "1063/1063 [==============================] - 0s 159us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1063/1063 [==============================] - 0s 196us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 84/100\n",
      "1063/1063 [==============================] - 0s 199us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 85/100\n",
      "1063/1063 [==============================] - 0s 184us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 86/100\n",
      "1063/1063 [==============================] - 0s 178us/step - loss: 0.2274 - acc: 0.9859 0s - loss: 0.2267 - acc: 0.98\n",
      "Epoch 87/100\n",
      "1063/1063 [==============================] - 0s 160us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 88/100\n",
      "1063/1063 [==============================] - 0s 203us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 89/100\n",
      "1063/1063 [==============================] - 0s 217us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 90/100\n",
      "1063/1063 [==============================] - 0s 187us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 91/100\n",
      "1063/1063 [==============================] - 0s 191us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 92/100\n",
      "1063/1063 [==============================] - 0s 199us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 93/100\n",
      "1063/1063 [==============================] - 0s 190us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 94/100\n",
      "1063/1063 [==============================] - 0s 178us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 95/100\n",
      "1063/1063 [==============================] - 0s 168us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 96/100\n",
      "1063/1063 [==============================] - 0s 182us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 97/100\n",
      "1063/1063 [==============================] - 0s 177us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 98/100\n",
      "1063/1063 [==============================] - 0s 187us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 99/100\n",
      "1063/1063 [==============================] - 0s 225us/step - loss: 0.2274 - acc: 0.9859\n",
      "Epoch 100/100\n",
      "1063/1063 [==============================] - 0s 198us/step - loss: 0.2274 - acc: 0.9859\n",
      "118/118 [==============================] - 0s 1ms/step\n",
      "Epoch 1/100\n",
      "1063/1063 [==============================] - 1s 1ms/step - loss: 0.3395 - acc: 0.9520\n",
      "Epoch 2/100\n",
      "1063/1063 [==============================] - 0s 238us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 3/100\n",
      "1063/1063 [==============================] - 0s 227us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 4/100\n",
      "1063/1063 [==============================] - 0s 286us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 5/100\n",
      "1063/1063 [==============================] - 0s 183us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 6/100\n",
      "1063/1063 [==============================] - 0s 174us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 7/100\n",
      "1063/1063 [==============================] - 0s 193us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 8/100\n",
      "1063/1063 [==============================] - 0s 224us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 9/100\n",
      "1063/1063 [==============================] - 0s 203us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 10/100\n",
      "1063/1063 [==============================] - 0s 175us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 11/100\n",
      "1063/1063 [==============================] - 0s 184us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 12/100\n",
      "1063/1063 [==============================] - 0s 162us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 13/100\n",
      "1063/1063 [==============================] - 0s 200us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 14/100\n",
      "1063/1063 [==============================] - 0s 169us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 15/100\n",
      "1063/1063 [==============================] - 0s 168us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 16/100\n",
      "1063/1063 [==============================] - 0s 176us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 17/100\n",
      "1063/1063 [==============================] - 0s 195us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 18/100\n",
      "1063/1063 [==============================] - 0s 183us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 19/100\n",
      "1063/1063 [==============================] - 0s 161us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 20/100\n",
      "1063/1063 [==============================] - 0s 182us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 21/100\n",
      "1063/1063 [==============================] - 0s 227us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 22/100\n",
      "1063/1063 [==============================] - 0s 176us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 23/100\n",
      "1063/1063 [==============================] - 0s 181us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 24/100\n",
      "1063/1063 [==============================] - 0s 198us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 25/100\n",
      "1063/1063 [==============================] - 0s 194us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 26/100\n",
      "1063/1063 [==============================] - 0s 197us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 27/100\n",
      "1063/1063 [==============================] - 0s 183us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 28/100\n",
      "1063/1063 [==============================] - 0s 204us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 29/100\n",
      "1063/1063 [==============================] - 0s 165us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 30/100\n",
      "1063/1063 [==============================] - 0s 178us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 31/100\n",
      "1063/1063 [==============================] - 0s 185us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 32/100\n",
      "1063/1063 [==============================] - 0s 206us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 33/100\n",
      "1063/1063 [==============================] - 0s 182us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 34/100\n",
      "1063/1063 [==============================] - 0s 201us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 35/100\n",
      "1063/1063 [==============================] - 0s 191us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 36/100\n",
      "1063/1063 [==============================] - 0s 183us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 37/100\n",
      "1063/1063 [==============================] - 0s 187us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 38/100\n",
      "1063/1063 [==============================] - 0s 177us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 39/100\n",
      "1063/1063 [==============================] - 0s 180us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 40/100\n",
      "1063/1063 [==============================] - 0s 176us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 41/100\n",
      "1063/1063 [==============================] - 0s 185us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 42/100\n",
      "1063/1063 [==============================] - 0s 179us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 43/100\n",
      "1063/1063 [==============================] - 0s 191us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 44/100\n",
      "1063/1063 [==============================] - 0s 223us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 45/100\n",
      "1063/1063 [==============================] - 0s 185us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 46/100\n",
      "1063/1063 [==============================] - 0s 193us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 47/100\n",
      "1063/1063 [==============================] - 0s 196us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 48/100\n",
      "1063/1063 [==============================] - 0s 175us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 49/100\n",
      "1063/1063 [==============================] - 0s 189us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 50/100\n",
      "1063/1063 [==============================] - 0s 239us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 51/100\n",
      "1063/1063 [==============================] - 0s 240us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 52/100\n",
      "1063/1063 [==============================] - 0s 187us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 53/100\n",
      "1063/1063 [==============================] - 0s 208us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 54/100\n",
      "1063/1063 [==============================] - 0s 216us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 55/100\n",
      "1063/1063 [==============================] - 0s 240us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 56/100\n",
      "1063/1063 [==============================] - 0s 201us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 57/100\n",
      "1063/1063 [==============================] - 0s 180us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 58/100\n",
      "1063/1063 [==============================] - 0s 201us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 59/100\n",
      "1063/1063 [==============================] - 0s 224us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 60/100\n",
      "1063/1063 [==============================] - 0s 322us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 61/100\n",
      "1063/1063 [==============================] - 0s 238us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 62/100\n",
      "1063/1063 [==============================] - 0s 194us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1063/1063 [==============================] - 0s 182us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 64/100\n",
      "1063/1063 [==============================] - 0s 198us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 65/100\n",
      "1063/1063 [==============================] - 0s 209us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 66/100\n",
      "1063/1063 [==============================] - 0s 174us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 67/100\n",
      "1063/1063 [==============================] - 0s 179us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 68/100\n",
      "1063/1063 [==============================] - 0s 240us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 69/100\n",
      "1063/1063 [==============================] - 0s 228us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 70/100\n",
      "1063/1063 [==============================] - 0s 192us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 71/100\n",
      "1063/1063 [==============================] - 0s 182us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 72/100\n",
      "1063/1063 [==============================] - 0s 183us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 73/100\n",
      "1063/1063 [==============================] - 0s 218us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 74/100\n",
      "1063/1063 [==============================] - 0s 190us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 75/100\n",
      "1063/1063 [==============================] - 0s 200us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 76/100\n",
      "1063/1063 [==============================] - 0s 219us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 77/100\n",
      "1063/1063 [==============================] - 0s 205us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 78/100\n",
      "1063/1063 [==============================] - 0s 208us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 79/100\n",
      "1063/1063 [==============================] - 0s 172us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 80/100\n",
      "1063/1063 [==============================] - 0s 185us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 81/100\n",
      "1063/1063 [==============================] - 0s 184us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 82/100\n",
      "1063/1063 [==============================] - 0s 193us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 83/100\n",
      "1063/1063 [==============================] - 0s 185us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 84/100\n",
      "1063/1063 [==============================] - 0s 213us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 85/100\n",
      "1063/1063 [==============================] - 0s 209us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 86/100\n",
      "1063/1063 [==============================] - 0s 158us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 87/100\n",
      "1063/1063 [==============================] - 0s 177us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 88/100\n",
      "1063/1063 [==============================] - 0s 157us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 89/100\n",
      "1063/1063 [==============================] - 0s 161us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 90/100\n",
      "1063/1063 [==============================] - 0s 170us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 91/100\n",
      "1063/1063 [==============================] - 0s 214us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 92/100\n",
      "1063/1063 [==============================] - 0s 199us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 93/100\n",
      "1063/1063 [==============================] - 0s 226us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 94/100\n",
      "1063/1063 [==============================] - 0s 215us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 95/100\n",
      "1063/1063 [==============================] - 0s 193us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 96/100\n",
      "1063/1063 [==============================] - 0s 166us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 97/100\n",
      "1063/1063 [==============================] - 0s 238us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 98/100\n",
      "1063/1063 [==============================] - 0s 207us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 99/100\n",
      "1063/1063 [==============================] - 0s 176us/step - loss: 0.2881 - acc: 0.9821\n",
      "Epoch 100/100\n",
      "1063/1063 [==============================] - 0s 175us/step - loss: 0.2881 - acc: 0.9821\n",
      "118/118 [==============================] - 0s 1ms/step\n",
      "Accuracy mean: 0.983065089837\n",
      "Accuracy variance: 0.0107196711682\n",
      "(' Time ', '228.274', ' seconds')\n"
     ]
    }
   ],
   "source": [
    "t0 = time()  \n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential # initialize neural network library\n",
    "from keras.layers import Dense # build our layers library\n",
    "def build_classifier():\n",
    "    classifier = Sequential() # initialize neural network\n",
    "    classifier.add(Dense(units = 1024, kernel_initializer = 'uniform', activation = 'relu', input_dim = X_train.shape[1]))\n",
    "    classifier.add(Dense(units = 512, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    \n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "classifier = KerasClassifier(build_fn = build_classifier, epochs = 100)\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()\n",
    "print(\"Accuracy mean: \"+ str(mean))\n",
    "print(\"Accuracy variance: \"+ str(variance)) \n",
    "tt = time() - t0  \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
